{"id": "nDvgHIBRxQ", "Context": "Evaluating large language models’ mathematical abilities requires definitions and tests that capture real-world user experience, not just isolated problem-solving scores. Existing math benchmarks risk overfitting and inadequately reflect genuine reasoning; a model that truly understands a problem should generalize robustly across diverse task formulations.", "Idea": "Propose MathCheck, a checklist-based evaluation framework for mathematical reasoning that probes task generalization and reasoning robustness, paired with an automatic tool to generate such checklists. The framework spans multiple mathematical task types and robustness tests, with instantiated suites for both textual and multimodal math reasoning, and a design that is extensible to other reasoning domains."}
{"id": "ZsP3YbYeE9", "Context": "Existing iterative prompting and reflection approaches for LM agents suffer from two issues: reflections often become repetitive, producing redundant inputs and restricting effective exploration of the decision space; and they treat each task in isolation, failing to leverage insights from previously solved tasks. The work seeks to address these limitations to improve reasoning and problem-solving efficacy.", "Idea": "Propose DoT (Diversity of Thoughts), a framework that enforces diversity in reflections to explicitly reduce redundancy and broaden decision-space exploration. DoT adds a task-agnostic persistent memory that stores and retrieves knowledge from prior tasks, enabling cross-task reuse. The design is modular, allowing its diverse-reflection and memory components to plug into existing agentic reasoning methods."}
{"id": "I4e82CIDxv", "Context": "Existing circuit discovery often relies on polysemantic units, limiting interpretability and downstream controllability. There is a need for circuits built from fine-grained, human-interpretable features that can reveal unanticipated mechanisms, support targeted interventions for tasks, and be discovered automatically at scale.", "Idea": "Introduce methods to discover and apply sparse feature circuits: causally implicated subnetworks composed of human-interpretable, fine-grained features rather than neurons or heads. Provide an unsupervised, scalable pipeline that automatically discovers behaviors and constructs their corresponding sparse feature circuits. Include a human-in-the-loop application (SHIFT) that steers classifiers by ablating features judged irrelevant to the task."}
{"id": "pHe4P1IVnb", "Context": "As large language models grow more capable, precise human oversight becomes impractical, necessitating alignment methods that operate under weak, noisy supervision. The Weak-to-Strong paradigm considers training a strong model under guidance from weaker supervisors to emulate limited human feedback, motivating approaches that can reliably transfer alignment in this constrained setting.", "Idea": "Introduce WeakS-to-Strong, which replaces a single weak supervisor with an ensemble of weak models to capture variability akin to diverse human opinions. Use a Bayesian scheme to estimate confidence scores that weight supervisory signals and guide generalization. Extend the framework from classification to text generation with richer supervision strategies, and incorporate direct preference optimization to improve the student’s preference learning beyond teacher forcing."}
{"id": "Pj4Aid3XqL", "Context": "Although adding images in a second training phase enables vision-language capabilities, it is unclear how this two-step pipeline compares to integrating images earlier during pretraining in terms of trade-offs between multimodal performance and preservation of text-only skills. The work seeks to clarify how timing of vision token introduction, image–text ratios, and scale influence downstream behavior.", "Idea": "Systematically vary the curriculum by introducing visual tokens at different fractions of pretraining while adjusting image–text mixing ratios and model scale. Use a unified adaptation protocol to isolate how timing and mixture influence multimodal acquisition and retention of text-only competence."}
{"id": "B2Fqu7Y2cd", "Context": "The goal is a single model that can synthesize and transform audio based on free-form text instructions, optionally conditioned on audio inputs. Models trained only on audio cannot infer the underlying instructions because those directives are absent from the signal, motivating data that exposes audio–language relationships. A further challenge is to achieve compositional control over instructions—combining, interpolating, or negating them—beyond what data alone typically enables.", "Idea": "Introduce Fugatto, a unified instruction-following audio model conditioned on natural-language prompts with optional audio conditioning to perform both synthesis and transformation. Propose ComposableART, an inference-time scheme that generalizes classifier-free guidance to compositional guidance, allowing combinations, interpolations, and negations of instructions for flexible control beyond the training distribution."}
{"id": "MWHIIWrWWu", "Context": "Controlling complex biological and robotic systems is difficult due to their high-dimensional state and action spaces. While deep reinforcement learning has demonstrated capability, it is computationally heavy and requires extensive manual tuning, making it impractical for large task collections or rapid deployment.", "Idea": "Introduce a hierarchical model-based approach that combines a sampling-based MPC layer for target posture planning with a morphology-aware proportional controller that coordinates many actuators according to the system’s structure. The method integrates black-box optimization to tune the reward function, reducing manual reward design."}
{"id": "cmYScmfu4Q", "Context": "RLHF commonly depends on reward inference, which introduces issues such as distribution shift, reward overfitting, and misspecification. Although DPO simplifies the pipeline by avoiding reward models, its underlying assumptions limit it to bandit or deterministic MDP regimes and specific preference models. The goal is to design reward-free RLHF methods that work in general stochastic RL and accommodate broader preference models.", "Idea": "Propose two algorithms that eliminate reward inference by estimating local value function differences directly from human preferences and using these estimates to build a zeroth-order approximation of the policy gradient for policy updates. The methods operate in general stochastic MDPs and are compatible with preference models beyond the Bradley–Terry formulation."}
{"id": "6HcnC3pPkp", "Context": "As tree-search-based inference grows in use for mathematical reasoning with LLMs, existing verifiers—built for Best-of-N settings—prove inadequate. They provide only indirect or coarse judgments of partial solutions and tend to undervalue intermediate steps, leading to premature pruning and suboptimal search.", "Idea": "Introduce token-supervised value models that assign each token a probability of eventually yielding the correct final answer. This token-level supervision enables explicit, fine-grained evaluation of partial solutions, allowing the search to preferentially expand promising intermediate steps and down-weight misleading ones."}
{"id": "BAelAyADqn", "Context": "The goal is to predict multiple near-future health or well-being outcomes from in-the-moment behavioral and physiological time series. Existing approaches underperform and often ignore realistic data issues—heterogeneous feature types and high missingness—as well as resource constraints, limiting their applicability in real-world settings.", "Idea": "Introduce MuHBoost, a multi-label boosting framework that integrates advanced LLM prompting with multi-label classification to jointly predict multiple health outcomes from ubiquitous health data. The method is designed to accommodate heterogeneous features, high rates of missing values, and practical resource limitations. Two variants are proposed to mitigate LLM hallucinations when addressing multiple questions concurrently."}
{"id": "svp1EBA6hA", "Context": "Pretrained diffusion models often need additional controllability over generated attributes during downstream fine-tuning. Practitioners may have an offline dataset of inputs with desired control labels and seek a principled way to condition generation on these controls at inference. Existing guidance approaches can be data-inefficient or require training classifiers on intermediate diffusion states.", "Idea": "Introduce CTRL, which formulates conditioning as an offline reinforcement learning problem that optimizes the sampling policy of a pretrained diffusion model. The reward combines a term from a classifier learned on the offline dataset with a KL regularization toward the base diffusion policy, producing a soft-optimal policy. This yields sampling from the conditional distribution that enforces the additional controls at inference."}
{"id": "l2zFn6TIQi", "Context": "The work targets the need to control generative model behavior to mitigate unsafe or undesirable outputs by steering internal activations. Prior efforts demonstrate activation steering, but a general, fine-grained, and modality-agnostic framework that subsumes existing approaches is sought.", "Idea": "Introduce Activation Transport (AcT), a framework that formulates activation steering as an optimal transport problem, learning transport maps that shift internal activation distributions toward or away from target concept distributions. The approach unifies and generalizes prior steering techniques and is designed to be modality-agnostic, enabling precise control over where and how activations are modified during generation."}
{"id": "FpiCLJrSW8", "Context": "RLHF with general-purpose preference data is widely used to align LLMs, but its impact on trustworthiness has not been rigorously evaluated. The study addresses this gap by assessing RLHF-aligned models across five trustworthiness dimensions: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy.", "Idea": "Adapt efficient influence-function-based data attribution to the RLHF setting to trace how specific fine-tuning and preference data affect trustworthiness evaluations. The method computes attribution scores that link alignment data to behavior on individual trustworthiness benchmarks, isolating influential data sources within the RLHF pipeline."}
{"id": "5WEpbilssv", "Context": "High-content perturbation assays generate rich biological readouts but are costly to run and analyze. Existing machine learning methods underutilize the semantic structure of biology and optimize objectives misaligned with downstream analyses, hindering efficient exploration and interpretability. There is a need for structured reasoning over perturbation data addressing tasks such as predicting differential expression and direction changes for unseen perturbations and performing gene set enrichment.", "Idea": "Introduce PerturbQA, a benchmark for structured reasoning over perturbation experiments that formalizes tasks including prediction of differential expression, directionality shifts for unseen perturbations, and gene set enrichment. Additionally, present Summer, a domain-informed LLM framework that summarizes experiment context, retrieves relevant biological knowledge, and composes structured answers."}
{"id": "9OfKxKoYNw", "Context": "Text-guided diffusion editing has become powerful and accessible, raising concerns about unauthorized or harmful edits. Existing adversarial-noise defenses can fail against more sophisticated scenarios, particularly masked editing, highlighting the need for stronger, more reliable protection methods and robustness across challenging setups.", "Idea": "Introduce a defense that crafts adversarial perturbations by optimizing a novel objective focused on the early timesteps of the diffusion process, producing more potent and efficient disruptions of subsequent editing. Augment the perturbation generation with diverse mask configurations to improve robustness against a wide range of masked edits at test time."}
{"id": "oZkqkkvdND", "Context": "VAEs are increasingly used in safety-critical applications, where one needs certified probabilistic guarantees of performance under adversarial attacks. The challenge is to provide such guarantees and corresponding training procedures tailored to the stochastic nature of VAEs.", "Idea": "Introduce CIVET, a certified training approach for VAEs that upper-bounds worst-case error by bounding reconstruction or task-specific error over carefully selected support sets in the latent layer. The method provides a mathematical link between latent-space support-set error and worst-case performance, and implements a training algorithm that enforces these bounds during optimization."}
{"id": "Pujt3ADZgI", "Context": "Reinforcement learning with human feedback is used to align large language models with human preferences, but common reward-based approaches rely on the Bradley–Terry assumption, which can oversimplify preference structure. Estimating expected win rates for individual responses in these pipelines can be computationally and annotation intensive. The goal is to support a more general preference framework while reducing such estimation burdens.", "Idea": "Cast RLHF as a two-player game and introduce an online algorithm, iterative Nash policy optimization, that seeks a Nash policy via self-play with no-regret learning. The approach replaces per-response win-rate estimation with a new loss defined directly over preference data, enabling direct optimization of the policy under general preferences."}
{"id": "9HK2rHNAhd", "Context": "The goal is to reduce KV-cache memory during LLM inference. Existing methods mainly compress by sparsifying tokens according to importance but allocate the same KV budget to every layer, which is suboptimal because layers differ in their sensitivity to inputs. This motivates optimizing the cache across both the sequence and the layer dimensions.", "Idea": "Estimate each attention layer’s importance on-the-fly by computing the cosine similarity between input prompt differences before and after the self-attention operation. Use these importance scores to group layers and assign differentiated KV-cache budgets, then apply sequence-wise KV compression within each layer according to its allocated budget. This yields a joint layer-wise and sequence-wise KV optimization that adapts during inference."}
{"id": "Mfnh1Sqdwf", "Context": "The work addresses predicting gene expression from DNA sequences while overcoming the difficulty of identifying the regulatory elements that control expression. It is motivated by the need to capture causal relationships between DNA, epigenomic signals, and regulatory elements to improve prediction accuracy and interpretability.", "Idea": "Introduce Seq2Exp, a sequence-to-expression network that explicitly discovers and extracts active regulatory elements and models their influence on target genes by jointly leveraging DNA sequence and epigenomic signals. The approach decomposes both modalities conditioned on putative causal elements and uses an information bottleneck parameterized with a Beta distribution to fuse their effects while filtering out non-causal components."}
{"id": "pbre0HKsfE", "Context": "Providing personalized LLM services conflicts with privacy requirements, motivating methods that keep user data encrypted during computation. While HE offers a principled PPML solution, the computational demands and non-HE-friendly operations in transformers impede practical encrypted fine-tuning and inference. The goal is to enable private personalized fine-tuning and efficient encrypted inference for LLMs.", "Idea": "Introduce a transformer architecture redesigned to be HE-friendly, focusing on enabling inference after personalized private fine-tuning. The approach employs LoRA for parameter-efficient personalization and uses Gaussian kernels to replace or approximate non-HE-compatible components, aligning core computations with HE’s arithmetic constraints."}
{"id": "WeJEidTzff", "Context": "The goal is to generate commuting OD flows for cities without historical OD data using readily available urban attributes. Existing studies employ varied techniques, datasets, and metrics, making it difficult to establish a unified standard for comparing model performance.", "Idea": "Introduce a standardized benchmarking framework for commuting OD flow generation that defines unified evaluation protocols and implements a suite of widely used models for consistent, head-to-head comparison. The framework codifies preprocessing and task definitions to ensure methodological parity across diverse urban environments."}
{"id": "kiOxNsrpQy", "Context": "As GNNs become pervasive, there is a need to define and assess faithfulness of explanations and to understand how to achieve it. The coexistence of multiple, non-equivalent faithfulness criteria creates ambiguity about what constitutes a faithful explanation. The study also probes how GNN architecture influences faithfulness and how faithfulness relates to invariance required for out-of-distribution generalization.", "Idea": "Offer a theory-driven examination of faithfulness in GNN explanations that clarifies and contrasts prevalent faithfulness criteria and the properties they capture. Characterize when faithful explanations are informative, identifying limitations for injective regular GNNs and highlighting the role of modular/self-explainable or domain-invariant architectures. Link explanation faithfulness to out-of-distribution invariance by showing that recognizing a domain-invariant subgraph suffices only when the subgraph is faithful."}
{"id": "Kpjvm2mB0K", "Context": "The work considers underdetermined ℓp linear regression problems min ||x||p subject to Ax = b with n ≪ d in a one-pass column-arrival streaming model, where the algorithm sees the columns of A sequentially and must use space far smaller than the stream length. When A is a graph incidence matrix, the setting captures ℓp flow problems such as transshipment (p=1), electrical flows (p=2), and max flow (p=∞). The goals include estimating the regression objective value and, in a stricter task, outputting an approximate solution under tight memory constraints.", "Idea": "Introduce one-pass streaming algorithms that compress the incoming column stream into a small sparsified instance whose objective closely preserves the ℓp regression cost; in graph settings, this yields ℓp flow sparsifiers. Additionally, provide sublinear-space procedures that can output approximate solutions for p > 1 with a tunable accuracy parameter, and a separate approach tailored to p = 1 under stricter approximation trade-offs."}
{"id": "eENHKMTOfW", "Context": "There is a widening gap between industrial labs and smaller practitioners in the ability to fine-tune LLMs due to compute and expertise constraints. The work targets supervised instruction tuning for small open-source LLMs, aiming to clarify effective training configurations and strategies and to provide practical, accessible guidance.", "Idea": "Introduce a standardized framework that systematically enumerates and documents supervised fine-tuning configurations for small LLMs across multiple model families. Incorporate analysis of early training dynamics (e.g., gradient norms and loss trends) to triage runs and simplify hyperparameter choices, and compare phased versus stacked curricula within a unified setup. Provide open-source code and detailed recipes to enable reproducible adoption."}
{"id": "TEkoMEjf7E", "Context": "Generative 3D modeling has advanced but remains ill-posed, leading to challenges in output quality and controllability. Designers often consult existing 3D assets when creating new ones, motivating approaches that can leverage references to improve guidance and generalization.", "Idea": "Phidias is a diffusion-based framework for reference-augmented 3D generation that uses a retrieved or user-supplied 3D model to guide synthesis and supports conditioning from text, images, and 3D inputs. It introduces three mechanisms: a meta-ControlNet to dynamically modulate conditioning strength, dynamic reference routing to handle misalignment between inputs and the reference model, and self-reference augmentations with a progressive curriculum to enable self-supervised training."}
{"id": "EV7FMBZxnx", "Context": "Detecting concealed objects such as in vivo lesions or camouflage often requires specialized imaging setups. Lensless cameras offer compact, flexible alternatives to lens-based systems, but their measurements lack familiar visual semantics, making concealed object detection particularly challenging.", "Idea": "Introduce a region gaze-amplification network (RGANet) that progressively extracts concealed objects from lensless measurements. It incorporates a region gaze module to mine spatial-frequency cues inspired by biological and psychological gaze mechanisms, and a region amplifier to enhance object-region details for stronger localization and delineation."}
{"id": "21rSeWJHPF", "Context": "Unsupervised ranking of graph vertices typically relies on centrality measures such as PageRank. In graphs with strong community structure, these methods can yield unbalanced rankings that overrepresent certain communities, reducing diversity and coverage. The objective is to produce rankings that remain meaningful while distributing prominence more evenly across communities.", "Idea": "Introduce relative centrality, an approach that iteratively applies graph-dependent local normalization to centrality scores, adjusting node importance by neighborhood context to promote balanced rankings while preserving ranking validity. Additionally, formalize sources of imbalance via a multi-core-periphery with communities (MCPC) structure and analyze the behavior of the normalization on this model."}
{"id": "l0gZS0sAlf", "Context": "Training and fine-tuning LLMs on heterogeneous, multi-source instruction data can induce conflicting gradient directions that impede optimization and specialization, harming generalization and downstream performance. Motivated by evidence that task-targeted subset tuning can rival full-dataset tuning, the goal is to better manage task diversity and gradient conflicts during fine-tuning.", "Idea": "ELREA clusters training instructions by their gradient directions to define specialized areas of expertise and trains a LoRA-based expert adapter for each cluster. At inference, it selects and ensembles the most relevant experts by matching the input’s gradient similarity to the training clusters, providing conflict-aware, task-specific adaptation."}
{"id": "mFY0tPDWK8", "Context": "ML-assisted MILP approaches often predict an initial solution and fix a subset of variables to shrink the problem before solving the reduced instance. However, inaccurate predictions can cause infeasibility or degraded solution quality, motivating a principled way to identify which predicted variable values are reliable enough to fix while maintaining feasibility and optimality.", "Idea": "Propose an alternating prediction–correction neural framework that iteratively predicts values for unfixed variables and refines them via a trust-region search to produce a reference solution. It computes an uncertainty-based error upper bound from the predicted and reference solutions to quantify confidence and fixes only high-confidence variables, progressively reducing the problem while preserving optimality."}
{"id": "mYgoNEsUDi", "Context": "Despite recent success, graph diffusion models struggle to holistically capture intrinsic higher-order topology, limiting generalizability and practical adoption for downstream tasks. There is a need to extract salient, multi-resolution topological descriptors over sequences of graphs and incorporate this dynamic information into diffusion frameworks.", "Idea": "Use zigzag persistence to derive latent, multi-scale topological descriptors from sequences of graphs and aggregate them into a computationally efficient summary, zigzag spaghetti (ZS), that captures inherent higher-order properties across resolutions. Establish stability guarantees for ZS and integrate these dynamic topological summaries into graph diffusion models to inform the generative process."}
{"id": "LBl7Hez0fF", "Context": "Hallucinations hinder the deployment of LVLMs and primarily stem from misalignments between visual inputs and generated text. The paper investigates mechanisms unique to LVLMs, highlighting that a frequent cause is the text decoder’s sensitivity to vision inputs, which arises naturally when image encoders and text decoders are pre-trained separately. The motivation is to understand and reduce this failure mode.", "Idea": "Propose Visual and Textual Intervention, a task-agnostic test-time method that steers latent representations during inference to stabilize vision features and thereby reduce decoder-induced hallucinations. The approach jointly intervenes on visual and textual internal states to enhance cross-modal consistency without additional training."}
{"id": "dQ2xiSIYzp", "Context": "The task is to recover a full 3D human representation from a single image, capturing detailed geometry and appearance, including unobserved regions. This is difficult due to occlusions and inherent ambiguities in pose and shape, and practical solutions must generalize to diverse, in-the-wild inputs.", "Idea": "Introduce a single-view generalizable Human Gaussian Model that follows a generate-then-refine pipeline guided by diffusion and human body priors. The method first predicts coarse human Gaussians, renders a back view, and refines this view with a ControlNet; the refined back view and the input image are then used to reconstruct refined Gaussian representations. A dual branch injects SMPL-X priors by propagating features from a volumetric SMPL-X space to image-aligned Gaussians via sparse convolutions and attention, while iteratively refining the SMPL-X estimate."}
{"id": "uHLgDEgiS5", "Context": "Existing influence estimation tools fail when training is sensitive to data ordering, leaving open how to distinguish the impact of the same example at different training stages and how to model influence as a function of the optimization trajectory. The goal is to quantify data influence conditioned on the exact sequence of training interactions without assuming permutation invariance.", "Idea": "Define trajectory-specific leave-one-out influence to measure the effect of removing a data point at a particular training iteration, explicitly conditioning on the observed data order and optimization path. Introduce data value embedding, which summarizes cumulative interactions between training examples and evolving parameters, enabling approximation of trajectory-specific influence via a dot product with a test point’s gradient."}
{"id": "lPJUQsSIxm", "Context": "Fully homomorphic encryption enables running neural network inference on encrypted data to protect both data and model confidentiality, but existing FHE-based deep networks suffer from high computational cost, latency, and limited scalability, hindering practical deployment, particularly for high-resolution, JPEG-encoded images commonly used in remote services.", "Idea": "Introduce a frequency-domain private inference approach that processes images directly as discrete cosine transform coefficients, eliminating unnecessary RGB reconstruction and reducing the number and cost of non-linear operations and homomorphic bootstrapping. The model is designed to be FHE-friendly by structuring computations in the DCT domain and learning to emphasize perceptually salient low-frequency components, thereby mitigating bootstrap-induced error accumulation and improving computational efficiency."}
{"id": "rfdblE10qm", "Context": "Reward modeling for LLM alignment often maps pairwise human preference comparisons to scalar rewards using the Bradley-Terry model. Yet its justification in this setting remains unclear, especially under sparse comparison graphs among prompt–response pairs, prompting a need to clarify when and why BT yields reliable predictive rewards and what properties matter for downstream optimization.", "Idea": "Establish a theoretical foundation by proving convergence rates for BT-based neural reward models using embeddings. Center order consistency—the preservation of correct rankings under monotonic transforms—as the core requirement, show that BT satisfies it, and propose a simple upper-bound objective implementable with standard binary classifiers as an order-consistent alternative to BT."}
{"id": "W2Wkp9MQsF", "Context": "The setting is compressing large neural networks when training data and fine-tuning are unavailable. A key motivation is to reduce model size while preserving internal data statistics, since existing data-free methods can distort activations and suffer from variance collapse or explosion, particularly under high sparsity.", "Idea": "Introduce model folding, a data-free compression method that reduces parameters by merging structurally similar neurons across layers without requiring fine-tuning or access to original data. It preserves internal statistics via k-means clustering and employs data-free mechanisms to prevent variance collapse or explosion during the folding process."}
{"id": "sLKDbuyq99", "Context": "LLM-based multi-agent systems are used for automated planning and task execution, yet they lack mechanisms to adapt workflows during execution. Real-world tasks require plans that can adjust in real time to unforeseen challenges and changing conditions, motivating methods for dynamic workflow adjustment in complex, interdependent subtasks.", "Idea": "Represent the workflow as an activity-on-vertex (AOV) graph and enable LLM agents to continuously refine it by dynamically reallocating subtasks based on historical performance and prior workflow states. Introduce a modular workflow design that evaluates task parallelism and dependency complexity to guide decomposition and coordination. Integrate these elements into a multi-agent framework that updates the workflow structure during execution."}
{"id": "9OJflnNu6C", "Context": "Machine unlearning seeks to remove specific training data from models to mitigate privacy and bias risks. In image-to-image generative models, prior approaches frame unlearning as a single-objective problem that yields a single solution, failing to reflect diverse user preferences over the trade-off between complete unlearning and retained model utility.", "Idea": "Proposes a controllable unlearning framework for image-to-image models that introduces a control coefficient epsilon to tune the trade-off by reformulating unlearning as an epsilon-constrained optimization problem. A gradient-based solver computes unlearning boundaries that define the valid epsilon range, guaranteeing Pareto-optimal solutions within this range, with analyzed convergence under different control functions."}
{"id": "zjeHLSiNv1", "Context": "While aiming to increase model capacity without proportional compute growth, existing approaches like MoE suffer from high inference latency driven by memory access costs. The objective is to reduce inference latency while preserving model performance and to understand the scaling behavior of such architectures.", "Idea": "Introduce UltraMem, which augments a Transformer with a large-scale, ultra-sparse memory layer that provides additional capacity via sparsely accessed memory slots. The mechanism activates only a tiny fraction of memory per token to limit memory traffic and integrate efficiently into the forward pass. The work also formulates and analyzes scaling laws for this memory-augmented architecture."}
{"id": "hgwGi81ndj", "Context": "The study examines whether equipping an agent with an object-centric mapping and operating at higher levels of state and temporal abstraction can make exploration and learning more efficient in challenging RL settings. The motivation is that such abstractions can simplify transition dynamics and make specific future states easier to predict, enabling targeted exploration and goal-directed planning at the abstract level.", "Idea": "Introduce a fully model-based algorithm that learns a discriminative world model over object-level abstract states and attribute dynamics, using hierarchical abstractions for both state and time. The agent plans exploration with a count-based intrinsic reward in the abstract space, then plans to reach any discovered abstract states. Low-level execution is realized by learning object-perturbing policies via reinforcement learning, while the object mapping is obtained through supervised learning."}
{"id": "CI4sCBMXjP", "Context": "There is a need to enhance model adaptability without the data and compute burdens of fine-tuning and without the demonstration curation and token inefficiency of in-context learning. The setting seeks a way to capture and reuse task-specific knowledge in a modular, transferable form that conserves inference tokens and avoids additional training.", "Idea": "Introduce ELICIT, a two-module framework that externalizes in-context learned capabilities as task vectors, maintains a repository of these vectors, and reuses them to condition models. The system retrieves and composes relevant task vectors for a target task and injects them to steer model behavior, enabling adaptation without additional training or extra inference tokens."}
{"id": "hJVdwBpWjt", "Context": "Although multimodal LLMs have advanced general audio tasks, their capabilities remain underexplored for bioacoustics applications such as large-scale vocalization detection, rare species classification, and context/behavior labeling—areas critical for conservation and biodiversity monitoring. The primary motivation is to address limited annotations and the need for models that generalize across unseen taxa and tasks in long, heterogeneous recordings.", "Idea": "Introduce an audio–language foundation model tailored to bioacoustics that aligns acoustic and textual representations to enable open-vocabulary querying and labeling of animal sounds. The approach leverages cross-domain transfer from speech and music to enrich bioacoustic representations through joint multimodal pretraining, facilitating broad generalization without task-specific architectures."}
{"id": "4GSOESJrk6", "Context": "Personalized image generation is valuable for assisting daily tasks, but its evaluation is problematic: automated measures often misalign with human judgments, while human evaluations are slow and costly. A scalable, reliable, and human-aligned assessment approach is needed.", "Idea": "Introduce DreamBench++, a benchmark for evaluating personalized image generation automated by advanced multimodal GPT models. It employs systematically designed prompts to achieve both human alignment and self-alignment via task reinforcement, and provides a comprehensive dataset of diverse images and prompts to support consistent evaluation."}
{"id": "PkpNRmBZ32", "Context": "Raw audio processing tasks such as keyword spotting, speech denoising, and ASR demand efficient sequence models. Existing state-space model (SSM) architectures are often restricted to depthwise-separable configurations and lack systematic computational optimization, limiting design flexibility and training/inference efficiency. There is a need for architectures that flexibly compose SSM blocks to balance model capacity, memory, and compute.", "Idea": "Centaurus is a network family built from generalized SSM blocks whose operations are formulated as tensor contractions during training. It systematically determines the optimal contraction order per block to improve computational efficiency, enabling SSM designs beyond depthwise separable, including group, full, and bottleneck-style patterns. The architecture combines a heterogeneous mixture of these blocks to balance size and resource efficiency, enabling fully state-space models without reliance on nonlinear recurrence, explicit convolutions, or attention."}
{"id": "t8fu5m8R5m", "Context": "Existing anomaly detectors trained only on unlabeled normal data are vulnerable to adversarially crafted anomaly samples at test time, undermining reliability in domains like autonomous driving. Directly applying adversarial training is hindered by the absence of labels and the lack of a principled objective. A desirable objective should induce strong intra- and inter-group perturbations to enlarge the margin between normal and anomalous distributions.", "Idea": "Generate a pseudo-anomaly set from normal samples and use adversarial training with a contrastive loss that jointly enforces intra-group compactness and inter-group separation under perturbations. Address the failure modes of conventional contrastive loss caused by spurious negative pairs by defining reliable opposite pairs. Adversarially push opposite pairs apart to guide inter-group perturbations in the correct direction and enhance robustness."}
{"id": "fGhr39bqZa", "Context": "The work targets causal discovery with latent variables while avoiding reliance on the pure-child assumption, which is deemed practically restrictive and not theoretically necessary. The aim is to identify latent variables and their causal relations under weaker, more flexible conditions.", "Idea": "Introduce homologous surrogates as flexible observed proxies for latent variables that do not require strictly restricted parent sets, unlike pure children. Specify two assumptions on homologous surrogates and derive identifiability results: the weaker condition enables recovery of ancestor relations, while the stronger condition enables exact parent identification. Build an algorithm that exploits these surrogate properties to recover the causal graph."}
{"id": "4ua4wyAQLm", "Context": "Video anomaly detection targets novel actions or events that are absent during training. Prevailing methods emphasize global patterns with redundant details, leading to poor generalization to unseen samples.", "Idea": "Introduce a framework that focuses on extracting and modeling local patterns, using a two-stage image–text alignment and cross-modality attention to obtain spatial cues and form recomposable, semantically focused representations. A State Machine Module leverages earlier high-resolution textual tokens to guide precise captioning for later low-resolution observations, injecting temporal structure. Temporal motion estimation is integrated to complement spatial cues, enabling detection of anomalies with novel spatial layouts or distinctive dynamics."}
{"id": "xPxHQHDH2u", "Context": "Novel view synthesis has advanced with neural radiance fields and 3D Gaussian splatting, but reconstructing reflective objects remains difficult. There is no practical solution that delivers real-time, high-quality rendering while modeling inter-reflections, motivating a unified approach that also covers non-reflective scenes and enables applications like relighting and editing.", "Idea": "Introduce a Reflective Gaussian splatting framework that augments Gaussian splatting with physically based deferred rendering, using a split-sum formulation to inject pixel-level material properties into the rendering equation. Define a Gaussian-grounded inter-reflection function within the splatting paradigm, and improve geometry and shading through material-aware normal propagation, an initial per-Gaussian shading stage, and the inclusion of 2D Gaussian primitives."}
{"id": "i3e92uSZCp", "Context": "The goal is to obtain a repertoire of semantically diverse skills that are useful for downstream tasks, beyond mere distinguishability or broad state coverage. Prior work has not directly targeted semantic diversity, leaving a gap in producing behaviors that align with human-understandable categories and are straightforward to specify and organize.", "Idea": "Introduce a language-guided skill discovery framework that explicitly maximizes semantic diversity among learned skills. The system takes natural language prompts to constrain the search to a desired semantic subspace, and uses language-derived guidance to drive the agent toward semantically distinct regions within that subspace, yielding a set of interpretable, distinct skills."}
{"id": "ws5phQki00", "Context": "Online political discussion platforms need robust stance detection, yet collecting sufficient labeled data across many debate topics is challenging. While LLMs have renewed interest in stance detection, their direct use in production is risky due to inconsistent outputs, biases, and adversarial vulnerabilities.", "Idea": "Generate stance-labeled synthetic data for specific debate questions by prompting an LLM in a secure offline setting and use it to fine-tune a conventional, dependable stance classifier for deployment. Leverage the synthetic set as a reference to identify informative unlabeled instances via model uncertainty and fine-tune further on these selected samples. Keep LLM usage offline for data generation and selection, while deploying the traditional model online."}
{"id": "t8KLjiFNwn", "Context": "State Space Models with selective mechanisms offer strong sequential modeling capabilities but incur high computational and bandwidth costs, making deployment on resource-constrained mobile devices difficult. There is a need to retain the benefits of the selective mechanism while reducing inference complexity and memory traffic for mobile hardware.", "Idea": "Introduce an end-to-end sparse learning framework co-designed with an architecture-aware compiler for mobile execution. The approach defines C4n kernel sparsity, pruning n elements from every four contiguous weights, and provides a compiler-based acceleration pipeline with C4n-specific optimizations and layout transformation elimination to efficiently realize this fine-grained pattern. The framework produces models tailored to target sparsity or latency budgets and uses information from pruned weights to compensate the remaining parameters."}
{"id": "Bp0HBaMNRl", "Context": "The problem is to discover causal structures with latent variables from observational data in settings where relationships may be non-linear and hierarchical. Existing methods rely on constraint-based, iterative discrete searches that do not scale well and often impose linearity or invertibility assumptions, reducing practicality. There is a need for approaches that handle non-linear latent hierarchical models under weaker assumptions.", "Idea": "Establish new identifiability conditions for non-linear latent hierarchical causal models that relax prior assumptions about determinism in latent variables and the form of exogenous noise. Using these theoretical insights, introduce a differentiable causal discovery algorithm that estimates model structure via gradient-based optimization. The method encodes hierarchical latent structure within a continuous, learnable parameterization to recover causal dependencies under the relaxed assumptions."}
{"id": "2IoFFexvuw", "Context": "Reinforcement learning has been effective for fine-tuning diffusion-based generators, but aligning continuous-time flow-based generative models to arbitrary user-defined rewards remains difficult due to policy collapse from overoptimization and the high cost of computing likelihoods in continuous flows.", "Idea": "Propose ORW-CFM-W2, an RL fine-tuning framework that integrates online reward-weighted conditional flow matching to optimize against arbitrary reward functions without requiring reward gradients or filtered datasets. The method adds Wasserstein-2 distance regularization with a tractable upper bound to maintain diversity and balance exploration and exploitation during policy optimization in flow models."}
{"id": "izjNI5bcOV", "Context": "Weather understanding involves heterogeneous data modalities and a wide range of tasks that are critical to human activity. Current data-driven approaches are typically specialized for a single task and scenario, and their reliance on limited real observations constrains scalability and overall performance, motivating a unified approach that can manage multiple complex tasks and modalities within one model.", "Idea": "Introduce a generalist weather foundation model that unifies representations and definitions across diverse weather understanding tasks. The approach designs weather-specific prompt formats to accommodate single, multi, and temporal modalities, and trains the unified model via a visual prompting, question–answering paradigm to enable task-agnostic inference."}
{"id": "5IWJBStfU7", "Context": "The work addresses whether, for a fixed model behavior and under MI’s stated criteria, explanations are guaranteed to be unique. It frames this question through the lens of identifiability and examines it for both where-then-what and what-then-where strategies within mechanistic interpretability.", "Idea": "Introduce a formal notion of identifiability for mechanistic interpretability and a taxonomy of explanation strategies (where-then-what vs. what-then-where) grounded in circuits, activation subspaces, and causal alignment. Develop a systematic procedure to probe identifiability by exhaustively enumerating candidate explanations in tractable settings. Articulate acceptance criteria for explanations—ranging from pragmatic predictive/manipulability standards to stricter unicity requirements—and situate them within a multi-criterion inner interpretability framework."}
{"id": "z8PcUSKXXN", "Context": "Generalizable image denoising aims to handle diverse and unseen noise types. A masked-training approach using a SwinIR backbone trained only on Gaussian noise can transfer to other noise distributions but often yields over-smoothed outputs and requires sensitive mask ratio tuning, complicating adoption. There is a need for a simpler, more efficient denoiser that generalizes without such hyperparameter burdens.", "Idea": "Introduce RNINet, a streamlined encoder–decoder denoiser. First train a plain model on individual noise types to reveal that feature statistics (e.g., mean and variance) shift with noise conditions, then add a noise injection block that injects random perturbations into feature statistics to induce robustness and generalization to unseen noise. This design simplifies the architecture compared to masked-training pipelines while promoting noise-agnostic feature learning."}
{"id": "yitH9xAHQs", "Context": "LLMs benefit from diverse, high-quality task-specific data, but prevailing data-generation pipelines rely on human annotations or predefined templates to steer synthesis. This manual dependence constrains coverage and can miss critical edge cases and novel scenarios, motivating automated approaches that surface model weaknesses in areas such as safety, honesty, and math.", "Idea": "ReverseGen introduces a dedicated proposer model trained to craft queries that cause a target LLM to produce unsatisfactory responses. These failure-inducing queries are then used to assemble training data that fine-tunes the target model to remediate the identified weaknesses, in a framework designed to be applicable across different model scales."}
{"id": "PUnD86UEK5", "Context": "Adam often outperforms SGD when training language models, but this advantage lacks a clear theoretical explanation. Prior non-convex convergence analyses for both Adam and SGD yield similar minimax-optimal rates, typically derived under standard ℓ2-smoothness assumptions.", "Idea": "Propose that Adam’s edge arises from leveraging favorable ℓ∞ geometry and develop a convergence analysis under ℓ∞-smoothness rather than the usual ℓ2 framework. Extend this analysis to blockwise Adam by introducing corresponding blockwise smoothness assumptions."}
{"id": "pPQPQ7Yd58", "Context": "The work examines the geometry of the visual representation space that links a vision encoder to an action decoder in behavior-cloned, image-based control. Motivated by neural collapse in image classification, it investigates whether representations naturally form clusters aligned with action semantics in discrete control and with control-oriented structure (e.g., relative pose orthants) in continuous control.", "Idea": "Pretrain the vision encoder with a neural collapse–inspired regularization that encourages control-oriented clustering of visual features, such as grouping by relative pose orthants. After pretraining, fine-tune the entire policy end-to-end with the action decoder so the controller exploits these structured embeddings, particularly in data-limited behavior cloning."}
{"id": "6qUUgw9bAZ", "Context": "Computationally intensive decoding techniques such as search, reranking, and self-critique can improve language model outputs in domains like code generation, numerical reasoning, and dialogue. However, these procedures are typically applied uniformly across inputs despite varying difficulty, motivating adaptive allocation of decoding computation under a budget to devote more resources to harder queries.", "Idea": "Propose a learning-based computation allocation framework that, given an input and a compute budget, predicts the reward distribution and uses it to direct additional decoding effort to instances expected to benefit most. The approach is instantiated as (1) an adaptive best-of-k scheme that selects how many samples to generate for reranking, and (2) a routing mechanism that chooses between a more expensive, accurate decoding procedure and a cheaper, less capable one on a per-query basis."}
{"id": "hXm0Wu2U9K", "Context": "Offline alignment methods that optimize language models using reward models or preferences frequently suffer overoptimization, where the policy overfits to reward model errors and deviates from truly preferred responses. Although KL regularization is standard to reduce distribution shift, it remains insufficient, motivating a theoretical examination that reveals KL’s weakness and raises the question of whether an efficient algorithm can be made robust to overoptimization.", "Idea": "Introduce chi^2-Preference Optimization (χPO), a minimal modification of DPO that replaces the logarithmic link function to induce chi-square–based regularization. This change implements a pessimistic update rule that more strongly penalizes uncertain, out-of-distribution behavior than KL-based formulations, thereby aiming to curb overoptimization within an offline alignment setting."}
{"id": "d8hYXbxX71", "Context": "Policymakers must design welfare interventions that balance short- and long-term objectives. Two prevailing paradigms—Rawlsian policies that prioritize the worst-off and utilitarian policies that maximize immediate aggregate welfare—are often seen as conflicting, and evaluations commonly emphasize short-run outcomes despite potential long-run effects.", "Idea": "Formalize welfare policy as a sequential decision process in which individuals’ welfare levels stochastically decay over time and interventions can prevent or mitigate this decay. Within this framework, conduct a theoretical comparison of Rawlsian and utilitarian allocation rules over extended horizons, deriving precise conditions that delineate when each paradigm is preferable."}
{"id": "G0dksFayVq", "Context": "LLM judges are increasingly used to assess and improve models, yet their own reliability is underexamined. As models produce more sophisticated outputs, stronger judges are needed, but existing benchmarks focus on human preference alignment and inadequately cover cases where crowd preferences do not reflect objective correctness.", "Idea": "Introduce an objective evaluation framework for LLM judges that prioritizes factual and logical correctness over subjective preference alignment. Build a benchmark of challenging response pairs across diverse domains via a pipeline that converts difficult problems into paired answers labeled by correctness-derived preferences."}
{"id": "vJkktqyU8B", "Context": "Vision Transformer adapters achieve strong accuracy but suffer from degraded inference speed due to inefficient memory access patterns, notably from standard normalization and frequent tensor reshaping. There is a need to improve memory efficiency and reduce memory time to make ViT adapters more practical, particularly for dense prediction tasks.", "Idea": "Introduce META, a memory-efficient ViT adapter that shares a single layer normalization between the self-attention and feed-forward sublayers to reduce normalization overhead, and adopts cross-shaped self-attention to lessen reshaping operations. The adapter is further augmented with a lightweight convolutional branch to inject local inductive biases, and is organized in a cascaded design to produce diverse head features, enriching feature representations."}
{"id": "SiH7DwNKZZ", "Context": "Transformers have become the default general-purpose backbones for computer vision, despite originating in language modeling. Recent advances in scalable LSTM variants that mitigate long-range dependency and parallelization limitations motivate revisiting recurrent architectures as competitive vision backbones.", "Idea": "Introduce Vision-LSTM (ViL), which adapts xLSTM building blocks to process sequences of image patch tokens. ViL stacks xLSTM layers with alternating scan directions: odd blocks traverse tokens from top to bottom, and even blocks from bottom to top, yielding complementary directional context over the spatial sequence."}
{"id": "9NfHbWKqMF", "Context": "3D Gaussian Splatting enables high-fidelity, real-time novel view synthesis but degrades markedly when test viewpoints deviate from training cameras, limiting free-viewpoint rendering and navigation. A systematic evaluation across synthetic and real settings shows that existing approaches—despite regularization and data-driven priors—struggle to generalize under out-of-distribution camera poses.", "Idea": "Introduce SplatFormer, a point transformer that operates directly on Gaussian splats to refine an initially optimized 3DGS in a single forward pass. Given a 3DGS learned from limited views, it updates the splat set to reduce artifacts expected under OOD viewpoints. The method applies point transformers directly to 3DGS and eschews multi-scene training constraints by processing the single-scene splat set end-to-end."}
{"id": "84WmbzikPP", "Context": "The goal is to infer a molecule’s full 3D atomic structure from its molecular formula and precisely measured moments of inertia, as obtainable from rotational spectroscopy. Existing conditional generative models only weakly enforce these measurements, failing to exploit their high precision, motivating approaches that strictly satisfy the physical constraints during generation.", "Idea": "Characterize the set of n-atom point clouds with fixed moments of inertia as an embedding within the Stiefel manifold St(n,4), enabling constraint-respecting modeling. Develop a flow-based generative model, Stiefel Flow Matching, that operates on this manifold to enforce exact moment constraints during synthesis. Further, obtain simpler and shorter flows by approximating equivariant optimal transport on the Stiefel manifold."}
{"id": "9FqARW7dwB", "Context": "Standard residual connection designs suffer from a seesaw between maintaining gradients and preventing representation collapse. The work seeks an alternative connectivity scheme for deep models, motivated by challenges observed during pretraining of large language models and in vision architectures.", "Idea": "Introduce hyper-connections as a drop-in replacement for residual links that parameterize and modulate cross-depth feature interactions. The mechanism lets the network learn the strength of connections between layers and dynamically rearrange effective layer order or pathways, creating adaptive depth-wise connectivity."}
{"id": "ho4mNiwr2n", "Context": "The work addresses the need to train clean models directly from poisoned datasets while overcoming limitations of existing anti-backdoor methods that struggle to recover correct labels for backdoored samples and generalize poorly to large pre-trained models due to non-end-to-end training. The motivation is to develop a defense compatible with prevalent large pre-trained architectures that can robustly handle poisoned inputs.", "Idea": "Introduce an end-to-end anti-backdoor training method, Mind Control through Causal Inference (MCCI), that conditions the model on both the image and an explicit attack indicator to disentangle semantic content from trigger effects. By learning to separate these factors, the model’s perceived attack status becomes controllable; supplying a non-attack indicator at inference coerces the model to treat inputs as clean, neutralizing triggers and yielding correct predictions on poisoned samples."}
{"id": "WwmtcGr4lP", "Context": "Cancer treatment is complicated by heterogeneous, individualized mutational landscapes and limited patient drug response data. Prior methods transfer knowledge from labeled cell line datasets by learning shared, domain-invariant representations, but this underrepresents patient-specific characteristics that strongly affect response. There is a need to augment limited patient data while preserving patient-domain properties.", "Idea": "Propose a generative, attention-based framework that directly augments patient genomic profiles and integrates these augmented samples into a predictive model for drug response. The method explicitly models patient-domain characteristics during generation to retain patient-specific signals, coupling the generator with an attention-driven predictor that captures interactions among genomic alterations."}
{"id": "d8cnezVcaW", "Context": "DPO has become a common method for RLHF-based fine-tuning of large language models, but it does not explicitly capture the diversity of human preferences across prompts. This motivates an approach that accounts for preference dispersion within the preference-optimization pipeline and can integrate with established methods.", "Idea": "Introduce MallowsPO, a preference-optimization framework inspired by Mallows ranking theory. It defines a dispersion index that quantifies per-prompt preference variability and integrates this signal into the DPO objective to calibrate updates; existing DPO formulations emerge as special cases under specific dispersion settings. The resulting formulation functions as a plug-in compatible with offline preference optimization methods."}
{"id": "MGKDBuyv4p", "Context": "The work targets the problem of training-data memorization in language models that can lead to verbatim disclosure of sensitive information. It is motivated by the need for practical, efficient mitigation techniques that curb memorization without imposing prohibitive costs and that can be developed and deployed for production-scale models.", "Idea": "Develop a comprehensive suite of memorization-mitigation approaches spanning regularizer-based, fine-tuning-based, and machine unlearning-based techniques, including several newly proposed unlearning methods. Introduce TinyMem, a set of small, computationally efficient language models to accelerate the design and evaluation of mitigation algorithms. Propose BalancedSubnet, an unlearning method intended to localize and excise memorized information from model weights prior to inference."}
{"id": "vmulbBDCan", "Context": "Despite EMCCD’s sensitivity advantages, residual noise degrades imaging quality, particularly in fluorescence microscopy. Prior EMCCD noise studies focus on theoretical statistics and have not been integrated with modern physics-based modeling to drive deep learning denoisers, and existing models for ordinary sensors are not directly applicable to EMCCD. There is a need for a practical, EMCCD-specific, experimentally calibrated noise model to enable effective denoising.", "Idea": "Develop a systematic calibration procedure for EMCCD cameras that empirically estimates the statistical characteristics of observable noise components to instantiate an accurate physics-based noise model. Leverage the calibrated model to synthesize realistic training data and train a contemporary neural denoiser, yielding an EMCCD-adaptive denoising pipeline."}
{"id": "iXCeQ2m6vT", "Context": "AI systems struggle to infer visual relations, especially for unseen objects, whereas humans easily perform such judgments. Theories of active vision suggest that actions used to fixate informative regions and the associated spatial signals help structure relational understanding. Motivated by this gap, the work seeks mechanisms that leverage action-derived spatial information to represent relations between different parts of an image beyond immediate pixel content.", "Idea": "Introduce a Glimpse-based Active Perception mechanism that sequentially selects the most salient image regions for high-resolution processing. The model integrates the coordinates of glimpse locations with the visual content around them to construct relational representations across image parts. By coupling action-derived spatial signals with local features, it encodes relations that extend beyond what is available from static, uniform processing."}
{"id": "FoF5RaA3ug", "Context": "Although soft labels have improved dataset distillation, fully exploiting the information contained in these labels remains underexplored. A comprehensive comparison of soft-label losses shows that models trained on synthetic datasets are highly sensitive to the chosen loss, motivating the need for a broadly reliable objective. The work also highlights the overlooked challenge of achieving generalization across different optimizers.", "Idea": "Propose GIFT, a plug-and-play module that refines teacher-generated soft labels and employs a cosine similarity–based loss to leverage the entire label distribution during distillation. The method standardizes soft-label utilization and can be integrated into existing dataset distillation pipelines."}
{"id": "R4h5PXzUuU", "Context": "Despite rapid adoption, the trustworthiness of foundation models—particularly the OoDD capability of LVLMs—remains underexplored, raising safety concerns for deployment. There is a need to characterize how LVLMs convey confidence through their generated language and to strengthen their robustness to out-of-distribution inputs.", "Idea": "Introduce Reflexive Guidance (ReGuide), a self-guided prompting method that elicits image-adaptive concept suggestions from the LVLM and uses them to structure subsequent reasoning and decisions. By leveraging the model’s own generated, context-specific concepts during inference, ReGuide enhances the model’s ability to discern in- vs. out-of-distribution inputs without modifying model parameters."}
{"id": "gU4ZgQNsOC", "Context": "Pretraining LLMs relies on massive, heterogeneous corpora, yet standard training treats all samples uniformly, ignoring their varying informativeness over time. Existing data reweighting approaches operate at coarse group levels and lack dynamic, instance-level adaptivity, motivating methods that prioritize examples based on their evolving relevance during training.", "Idea": "Introduce algorithms for dynamic, instance-level reweighting that update each sample’s training weight online as a function of its current loss, enabling the model to emphasize informative examples while deprioritizing redundant or uninformative data. Provide a theoretical framework that analyzes how loss-based reweighting influences the convergence of gradient-based optimization, yielding a formal characterization of its effect on convergence bounds."}
{"id": "f7KxfUrRSb", "Context": "Aligning LMs to human preferences is a central challenge. Prior work on weak-to-strong generalization suggests a stronger model can outperform a weaker supervisor trained on limited signals. The authors explore whether alignment behavior learned by a weaker model can be transferred to a stronger model and potentially be amplified.", "Idea": "Introduce Weak-to-Strong Preference Optimization (WSPO), which transfers alignment by learning the distributional change induced when a weak model is aligned and using that change as a target for a stronger model. The method models the pre- vs. post-alignment shift of the weak teacher and optimizes the strong student to reproduce an analogous shift in its own policy, thereby inheriting and amplifying the teacher’s alignment behavior."}
{"id": "oU3tpaR8fm", "Context": "Retrieval-augmented generation allows large language models to consult external knowledge, and expanding context windows encourages supplying more retrieved passages under the assumption that higher recall improves outputs. Empirically, however, increasing the number of passages can first help and then harm generation quality, motivating an investigation into why larger retrieval sets degrade performance and how to make long-context RAG robust.", "Idea": "Introduce methods to counteract degradation from large retrieval sets in long-context RAG. Present a training-free retrieval reordering strategy that prioritizes more useful evidence, and develop training-based approaches: implicit fine-tuning of the LLM for RAG behavior and a RAG-oriented fine-tuning procedure that incorporates intermediate reasoning signals."}
{"id": "iylpeTI0Ql", "Context": "The work targets zero-shot test-time adaptation for VLMs when target streams contain OOD (noisy) samples. Existing TTA methods degrade in this setting because unfiltered noisy data dominates updates and because using a single adapting classifier for both ID classification and noise detection undermines both capabilities.", "Idea": "Decouple ID classification from noise detection by freezing the classifier (and backbone) and training a dedicated detector. Introduce an Adaptive Noise Detector that uses the frozen model’s outputs as pseudo-labels to learn to identify noisy samples. During adaptation on clean streams, inject Gaussian noise to regularize the detector and reduce false positives on clean inputs."}
{"id": "4rEI2JdHH6", "Context": "Neural networks can exhibit grokking: they initially memorize training data and only after prolonged training abruptly transition to good generalization, undermining predictability and efficiency. The objective is to achieve immediate generalization during training and avoid delayed transitions.", "Idea": "Propose GrokTransfer, a two-stage embedding transfer approach. A smaller, weaker model is first trained to attain nontrivial test performance; its learned input embedding is then extracted and used to initialize the target, stronger model’s embedding, biasing optimization toward generalizing representations from the start."}
{"id": "vQhn4wrQ6j", "Context": "The work targets enabling mathematical reasoning in non-English languages when in-language math instruction data is unavailable. The motivation is to transfer math abilities learned in English into target languages by leveraging existing language competence, overcoming data scarcity in multilingual settings.", "Idea": "Starting from a shared pretrained model, train two experts: one on English math instructions and another on generic instructions in the target language. Construct a merged model by swapping the top and bottom transformer layers of the math expert with the corresponding layers from the language expert, thereby composing language proficiency with math reasoning. The layer-selection strategy is guided by an analysis of which layers undergo the most salient parameter changes during each expert’s fine-tuning."}
{"id": "uREg3OHjLL", "Context": "The study examines how the expressive power of ReLU networks scales with depth by focusing on the exact representation of the function F_n = max(0, x1, ..., xn). Prior work conjectured a logarithmic-in-n depth lower bound and confirmed it for integer-weight networks; this work investigates the case of practically relevant rational weights.", "Idea": "Establish depth lower bounds for representing F_n when all weights are rational numbers constrained to specific numeral systems. It proves that decimal-fraction weights require at least ceil(log_3(n+1)) hidden layers, and more generally, N-ary fraction weights require at least Ω(ln n / ln ln N) layers, thereby extending integer-weight lower bounds to rational settings and revealing base-dependent limitations."}
{"id": "vr1QdCNJmN", "Context": "The work targets the problem of defining meaningful, structure-aware divergences for discrete objects, where continuous-space Bregman constructions are not directly applicable. Prior discrete formulations based on submodular generators can be too restrictive for capturing diverse structural relationships. The motivation is to obtain more flexible, higher-capacity divergences for comparing discrete data in settings like clustering and set retrieval.", "Idea": "Introduce a discrete Bregman divergence whose generator need not be submodular or supermodular by modeling it as a difference of submodular functions, yielding a difference-of-submodular Bregman divergence. Provide a learnable instantiation using permutation-invariant neural networks to parameterize the generator over sets. This design enlarges the space of expressible discrete divergences while respecting permutation invariance of set inputs."}
{"id": "2e4ECh0ikn", "Context": "Recent audio foundation models promise richer conversational abilities, yet there is no comprehensive evaluation of their capacity to conduct natural, interactive turn-taking without excessive overlap or long silences. The work seeks to determine whether these models—and spoken dialogue systems built on them—can understand, predict, and execute turn-taking behaviors necessary for smooth multi-turn interaction.", "Idea": "Introduce an evaluation protocol that assesses a system’s turn-taking by using a supervised judge model trained to predict human turn-taking events. The judge compares a system’s conversational timing behaviors—such as when to speak, yield, or backchannel—against learned human norms, providing a systematic measure of turn-taking competence."}
{"id": "QG31By6S6w", "Context": "Medical vision–language pretraining has advanced zero-shot disease recognition, but transferring image-level knowledge to pixel-level 3D lesion segmentation remains challenging. The heterogeneity of pathological appearances and the need to align fine-grained, previously unseen lesion features with disease-related text hinder effective zero-shot segmentation.", "Idea": "Malenia proposes a multi-scale lesion-level mask–attribute alignment framework for 3D zero-shot segmentation, aligning segmentation mask representations with associated elemental attributes to connect unseen lesion features with transferable disease knowledge. It further introduces a Cross-Modal Knowledge Injection module that enriches visual and textual representations with complementary information to guide accurate mask generation."}
{"id": "X9OfMNNepI", "Context": "The study investigates whether LLMs can autonomously discover novel and valid chemistry research hypotheses when provided only a background research question. It posits that many chemistry hypotheses arise from combining a background with several literature-derived inspirations, leading to three sub-questions: retrieving suitable inspirations, generating hypotheses from background plus inspirations, and ranking the resulting hypotheses. To examine this, the authors create a benchmark from recent high-impact chemistry papers, each split by experts into background, inspirations, and hypothesis, and define a rediscovery task using only the background and a literature corpus while restricting LLM training data to pre-2024.", "Idea": "Introduce an LLM-based multi-agent framework that operationalizes the background–inspirations–hypothesis assumption. The system proceeds in three stages: retrieve candidate inspiration papers from the corpus given a background question; synthesize candidate hypotheses conditioned on the background and retrieved inspirations; and critique and rank the hypotheses to prioritize the most promising proposals."}
{"id": "keu6sxrPWn", "Context": "Increasingly capable LLMs are difficult to trust because they may produce subtle, safety-bypassing errors. Deployers must balance safety with the desire to leverage these models’ capabilities across many tasks. The work formalizes this need as a diffuse risk management problem that aims to manage average-case safety and usefulness over extended deployments with untrusted models.", "Idea": "Introduce a two-level protocol framework for deploying untrusted models. At the micro level, design per-task protocols in which a trusted but less capable model harnesses and monitors the untrusted model. At the macro level, maintain an adaptive estimate of the untrusted model’s risk and use it to select among micro-protocols over time to balance safety and utility across the task sequence."}
{"id": "2ZK8zyIt7o", "Context": "As prompts become longer, current CLIP-style encoders cannot faithfully encode all content, and diffusion models struggle to align outputs to lengthy descriptions. The problem is to enable robust long-text conditioning and improve alignment training signals without amplifying overfitting from preference models.", "Idea": "Introduce LongAlign, combining a segment-level text encoding scheme that splits long prompts into manageable segments processed separately by a pretrained encoder and then fused to condition the generator, bypassing input-length limits. Develop a decomposed CLIP-based preference model that separates scores into text-relevant and text-irrelevant components and applies reweighting during fine-tuning to prioritize alignment and curb overfitting."}
{"id": "RaR3ETzyKp", "Context": "Diffusion and rectified flow generative models trained on the same data can produce similar outputs when given the same input noise, suggesting sample-specific preferable noises. Visualizations reveal that trajectories connecting preferable noises to samples are better organized with fewer crossings than those from random noises, and observed crossings in low-dimensional projections imply small inter-path distances in high-dimensional space. This motivates increasing inter-path distances among noise–sample trajectories to facilitate faster, more stable training.", "Idea": "Propose Distance-Aware Noise-Sample Matching (DANSM), which assigns noises to samples to explicitly enlarge inter-path distances during training. The approach builds on rectified flow models to compute inter-path distances via a closed-form expression, and further simplifies optimization by deriving a relationship to path length and using path length as a surrogate objective."}
{"id": "e8qXTxMgPg", "Context": "The work investigates dimensionality reduction for s-sparse vectors beyond worst-case analysis. It examines average-case norm preservation in ℓp spaces, considering settings like oblivious linear maps and smooth encoder–decoder schemes, and asks what dimensionality is fundamentally necessary. Motivated by structural assumptions that may permit stronger guarantees, it then focuses on datasets of non-negative s-sparse vectors to explore whether pairwise distance preservation can be achieved in significantly lower dimensions and to clarify which assumptions are essential.", "Idea": "Develop sharp average-case lower bounds for norm-preserving embeddings of sparse vectors, covering oblivious linear maps and a broad class of smooth encoder–decoder schemes, and show a separation when arbitrary (potentially non-smooth) post-processing is allowed. Introduce a non-linear embedding tailored to non-negative sparse data that preserves all pairwise ℓp distances with p-independent target dimension and includes a specialized construction for the ℓ∞ case, alongside separation arguments proving the necessity of both non-linearity and non-negativity."}
{"id": "Wvi8c0tgvt", "Context": "Realistic blur datasets lack sufficient diversity in scenes and motion patterns, and collecting broader data with dual-camera systems is costly and complex. While data augmentation is attractive, prevailing techniques model blur using 2D non-uniform kernels that ignore inherently 3D camera/object motion, leading to unrealistic blur synthesis.", "Idea": "Propose a 3D-aware blur synthesizer that estimates 3D camera positions over the motion-blur interval, generates the corresponding intermediate scene images, and aggregates them to form a realistic blur image. The 3D transformation is factorized into a 2D image-plane transform plus a projected 3D residual component predicted by a neural network, enabling 3D-consistent blur without explicit depth measurements. The synthesizer offers controllable augmentation by adjusting blur magnitude, direction, and scene content."}
{"id": "c4OGMNyzPT", "Context": "Existing LVLM evaluations centered on VQA and captioning fail to capture the breadth of LVLM capabilities, inadequately testing detailed visual perception, being vulnerable to data contamination, and neglecting multi-turn reasoning. A more comprehensive, structured evaluation is needed to assess perception, reasoning, and decision-making in interactive settings.", "Idea": "Propose LVLM-Playground, a game-based evaluation framework that places LVLMs in structured environments to systematically elicit and measure cognitive and reasoning abilities. The framework comprises a suite of games targeting four tasks—Perceiving, Question Answering, Rule Following, and End-to-End Playing—each crafted to assess specific capabilities such as visual perception, reasoning, and decision-making."}
{"id": "bc3sUsS6ck", "Context": "Large language models possess broad pretrained knowledge but require adaptation to new contexts, tasks, or domains. Existing approaches either fine-tune the model, incurring substantial training cost, or rely on prompting, which increases inference-time overhead and context length. There is a need for a method that can quickly inject situational or user-specific information into a model with minimal compute.", "Idea": "Introduce GenerativeAdapter, which augments a frozen language model with a lightweight generator that converts test-time context into parameter-efficient adapters via a single forward pass, effectively writing the context into the model’s parameters. The generator is trained self-supervised and is designed to be general-purpose, enabling on-the-fly adaptation across diverse language processing scenarios without modifying the base model."}
{"id": "rpouyo09V0", "Context": "While LLMs excel at code generation, existing benchmarks inadequately represent the diversity and quality of feedback present in real interactive workflows, limiting evaluation of models’ ability to leverage multi-turn signals.", "Idea": "Introduce a reproducible interactive benchmarking environment that simulates multiple code-editing scenarios by systematically combining three feedback types: compilation feedback, execution feedback with controllable test coverage, and verbal feedback with adjustable expertise. Complement this with a fast, static benchmark that replays pre-generated feedback logs to enable low-cost, consistent evaluation without on-the-fly verbal feedback generation."}
{"id": "0mtz0pet1z", "Context": "The work studies causal effects tied to time-to-treatment initiation in settings like preventive medicine and chronic disease management. Existing analyses typically focus on discrete decisions about when to treat and their dependence on patient characteristics. Here, the goal is to assess the causal impact of incrementally modifying the intensity governing when treatment is initiated.", "Idea": "Introduce an incremental intervention framework that perturbs the time-varying intensity of treatment initiation and defines the corresponding causal effect. Establish identification of this effect without relying on the usual positivity assumption, and develop an estimation approach based on inverse probability weighting."}
{"id": "u3TL0qxLWf", "Context": "Large language models deliver strong NLP performance but are costly to deploy due to high runtime overhead, particularly from memory-bandwidth–bound inference. There is demand for post-training compression to curb memory traffic, yet many existing methods require calibration data and can struggle to generalize across tasks.", "Idea": "Introduce SeedLM, a post-training weight compression scheme that encodes each weight block using a compact seed and coefficients: at inference, a pseudo-random generator (via an LFSR) deterministically produces a basis matrix from the seed, which is linearly combined with stored coefficients to reconstruct the weights. This regenerates weights on-the-fly to reduce memory access by trading additional compute and operates without calibration data."}
{"id": "4O0v4s3IzY", "Context": "There is ongoing debate about whether scaling yields robust reasoning in LLMs and whether iterative self-critique reliably improves solutions. The work sets out to systematically evaluate iterative prompting for reasoning and planning and to scrutinize the assumption that verification should be easier than generation in the LLM regime.", "Idea": "Introduce a principled evaluation framework that contrasts self-critique loops with pipelines that integrate an external correct verifier to check and guide candidate solutions. Analyze whether the substantive content of critiques drives improvement and perform ablations to identify which components of augmented prompting pipelines are necessary."}
{"id": "P4XmKjXTrM", "Context": "Reproducibility in machine learning for healthcare is hampered by the inaccessibility of datasets, pipelines, and even task or cohort definitions, which limits sharing, iteration, and interpretability of results on EHR data. There is a need to define and reproduce cohorts and tasks on event-stream EHRs in a way that is portable and consistent across data environments.", "Idea": "Introduce an automatic cohort extraction system for event-stream EHRs that centers on a declarative, domain-specific configuration language to encode clinical concepts and inclusion/exclusion criteria independently of any particular schema. Pair this with an execution pipeline that compiles these specifications into predicates over event streams and automatically extracts patient records that satisfy them, supporting exact and conceptual reproducibility via standardized, portable definitions."}
{"id": "SgymXhOEA5", "Context": "The work examines how camera bias in ReID models behaves under distribution shifts to unseen domains and finds it becomes more pronounced. Existing camera-aware approaches are largely tied to training-domain cameras, motivating methods that debias at test time without retraining. The authors also observe that unsupervised ReID remains strongly biased toward camera labels, motivating strategies to mitigate bias in pseudo-label-driven training.", "Idea": "Introduce a test-time debiasing approach that revisits feature normalization on embedding vectors to suppress camera-related variance, and extend it to target finer bias factors such as low-level image properties and body angle. Provide an analysis explaining why normalization reduces camera bias and how to apply it broadly across scenarios. Additionally, propose simple training strategies for unsupervised ReID that lessen the influence of camera-biased pseudo labels during learning."}
