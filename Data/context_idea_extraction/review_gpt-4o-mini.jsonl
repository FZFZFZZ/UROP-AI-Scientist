{"id": "nDvgHIBRxQ", "Context": "Evaluating the mathematical reasoning abilities of large language models (LLMs) is critical, as current benchmarks primarily focus on problem-solving skills. This limited approach risks model overfitting and fails to accurately measure true mathematical reasoning capabilities, highlighting the need for a more comprehensive evaluation that reflects user experiences and robustness across diverse tasks.", "Idea": "We introduce MathCheck, a checklist designed to assess task generalization and reasoning robustness in LLMs. It encompasses various mathematical reasoning tasks and robustness tests, enabling a thorough evaluation of mathematical abilities and model behavior."}
{"id": "ZsP3YbYeE9", "Context": "Current methods for building agents using Language Models (LMs) often involve iterative prompting and reflection on outputs to achieve desired tasks. However, these approaches face limitations such as restricted exploration of the decision space due to repetitive reflections and an inability to leverage insights from previously solved tasks.", "Idea": "We propose DoT (Diversity of Thoughts), a framework that explicitly reduces redundant reflections to enhance decision-space exploration and incorporates a task-agnostic memory component for knowledge retrieval from previously solved tasks."}
{"id": "I4e82CIDxv", "Context": "Existing methods for interpreting language model behaviors often rely on complex units, such as attention heads or neurons, which can hinder their applicability in practical scenarios. These approaches may not provide clear insights into the underlying mechanisms of neural networks, limiting their effectiveness in downstream applications.", "Idea": "We propose sparse feature circuits, which are human-interpretable subnetworks that enhance the understanding of language model behaviors. Additionally, we introduce SHIFT, a method that improves classifier generalization by ablating features judged irrelevant by humans."}
{"id": "pHe4P1IVnb", "Context": "As large language models evolve, aligning these complex systems with human values and preferences becomes more challenging. Traditional alignment techniques may falter as human supervision weakens, highlighting the need for innovative approaches to leverage the capabilities of stronger models.", "Idea": "This work presents WeakS-to-Strong, an extension of the Weak-to-Strong framework that employs an ensemble of weak models to reflect variability in human opinions. It utilizes a Bayesian approach for confidence score estimation and incorporates direct preference optimization to improve the student model's learning in text classification and generation tasks."}
{"id": "Pj4Aid3XqL", "Context": "Pre-trained large language models (LLMs) have shown effectiveness in vision-language tasks when further trained with image data. However, the impact of introducing images after initial training compared to vision-language models (VLMs) that incorporate images earlier remains uncertain, raising questions about the optimal integration of image and text data during model training.", "Idea": "We propose to explore the effects of introducing vision tokens at different stages of pre-training. This approach aims to identify the optimal timing for integrating image data to enhance performance on vision-language tasks while maintaining capabilities on text-only tasks."}
{"id": "B2Fqu7Y2cd", "Context": "Audio synthesis and transformation models often struggle to interpret free-form text instructions, especially when trained solely on audio data, which lacks inherent instructional context. While large language models can infer instructions from text, they do not effectively translate to audio tasks. Additionally, achieving compositional abilities in audio generation, such as combining or negating instructions, is a significant challenge.", "Idea": "We propose a specialized dataset generation approach that optimizes the relationship between audio and language, and introduce ComposableART, an inference-time technique that extends classifier-free guidance to enable flexible composition of instructions for customizable audio outputs."}
{"id": "MWHIIWrWWu", "Context": "Controlling high-dimensional nonlinear systems, particularly in biological and robotic applications, presents significant challenges due to the complexity of large state and action spaces. Although deep reinforcement learning has shown promise in these areas, its computational demands and time requirements make it impractical for managing extensive task collections that necessitate considerable manual tuning.", "Idea": "We introduce Model Predictive Control with Morphology-aware Proportional Control (MPC$^2$), a hierarchical model-based learning algorithm for zero-shot and near-real-time control of complex dynamical systems. MPC$^2$ combines a sampling-based model predictive controller for target posture planning with a morphology-aware proportional controller to improve actuator coordination."}
{"id": "cmYScmfu4Q", "Context": "Reward inference is a crucial step in the Reinforcement Learning from Human Feedback (RLHF) process for fine-tuning Large Language Models (LLMs). However, RLHF faces challenges such as distribution shift, reward model overfitting, and problem misspecification. Existing methods like Direct Preference Optimization (DPO) simplify the pipeline but are limited to bandit settings or deterministic MDPs.", "Idea": "This paper presents two RLHF algorithms that do not rely on reward inference, extending applicability to general reinforcement learning problems. The algorithms estimate local value function differences from human preferences and approximate the policy gradient using a zeroth-order gradient approximator."}
{"id": "6HcnC3pPkp", "Context": "The rapid advancement of test-time compute search strategies has highlighted the need for robust verifiers to enhance the mathematical problem-solving capabilities of large language models (LLMs). Current inference strategies rely on verifiers designed for Best-of-N search, which are sub-optimal for tree search techniques. These verifiers provide only indirect assessments of partial solutions, leading to the premature pruning of potentially promising intermediate steps.", "Idea": "We propose token-supervised value models (TVMs), a new class of verifiers that assign a probability to each token, reflecting the likelihood of reaching the correct final answer. This token-level supervision enables TVMs to directly evaluate partial solutions, effectively distinguishing between promising and incorrect intermediate steps during tree search."}
{"id": "BAelAyADqn", "Context": "Longitudinal human behavior modeling is increasingly important for applications such as patient monitoring and lifestyle recommendations, particularly for at-risk individuals. This field utilizes health data collected from devices like smartphones and smartwatches to develop predictive models for health outcomes based on individual behavior time series. However, existing models often struggle with accuracy and fail to account for the complexities of ubiquitous health data, including diverse feature types and high rates of missing values.", "Idea": "We propose MuHBoost, a multi-label boosting method that leverages advanced techniques in large language model prompting and multi-label classification to jointly predict multiple health outcomes. We also introduce two variants of MuHBoost to address hallucination issues in LLMs, enhancing predictive performance."}
{"id": "svp1EBA6hA", "Context": "Diffusion models are effective generative models capable of generating samples with specific characteristics. However, there is often a need for enhanced control during downstream fine-tuning processes, treating these models as pre-trained entities.", "Idea": "We introduce CTRL, a method that employs reinforcement learning to add controls using an offline dataset of inputs and labels. This method formulates the task as an RL problem, using KL divergence against pre-trained models as reward functions to generate soft-optimal policies for conditional sampling."}
{"id": "l2zFn6TIQi", "Context": "The increasing capabilities of large generative models and their widespread deployment have raised concerns about their reliability, safety, and potential misuse. This has led to efforts to control model generation by steering activations to influence the emergence of specific concepts or behaviors in the output.", "Idea": "We introduce Activation Transport (AcT), a framework guided by optimal transport theory that enables precise steering of model activations. AcT is modality-agnostic and provides fine-grained control over model behavior with negligible computational overhead."}
{"id": "FpiCLJrSW8", "Context": "The trustworthiness of Large Language Models (LLMs) is a critical factor, focusing on the reliability, safety, and ethical alignment of their outputs. While Reinforcement Learning From Human Feedback (RLHF) is commonly used to align LLMs with human preferences, its effect on model trustworthiness has not been rigorously evaluated. This study investigates the performance of models aligned with general-purpose preference data across five trustworthiness dimensions: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy.", "Idea": "We propose to adapt efficient influence function based data attribution methods to the RLHF setting to better understand the influence of fine-tuning data on individual trustworthiness benchmarks. This method aims to provide estimated attribution scores that can inform more nuanced model alignment strategies."}
{"id": "5WEpbilssv", "Context": "High-content perturbation experiments enable detailed investigation of biomolecular systems, yet their high experimental and analysis costs hinder broader application. Existing machine learning methods for exploring perturbation spaces often overlook the complex biological semantics and misalign with the needs of subsequent biological analyses.", "Idea": "We propose PerturbQA, a benchmark for structured reasoning over perturbation experiments that addresses open problems in perturbation modeling. Additionally, we introduce Summer, a domain-informed LLM framework designed to effectively tackle these challenges."}
{"id": "9OfKxKoYNw", "Context": "Recent advances in diffusion models have revolutionized text-guided image manipulation, enabling the creation of realistic images from simple textual prompts. However, this progress raises concerns about potential misuse, particularly in generating misleading or harmful content. Current defense strategies that apply adversarial noise to disrupt model performance are ineffective against sophisticated editing techniques, such as those using masks.", "Idea": "We propose DiffusionGuard, a robust defense method that generates targeted adversarial noise during the early stages of the diffusion process to counter unauthorized edits. Additionally, we introduce a mask-augmentation technique to enhance robustness against various masks during testing."}
{"id": "oZkqkkvdND", "Context": "Variational Autoencoders (VAEs) are increasingly utilized in safety-critical applications where performance under adversarial attacks is a concern. Ensuring certified probabilistic guarantees in such scenarios is essential for maintaining reliability and safety.", "Idea": "We propose a novel method called CIVET for the certified training of VAEs, which bounds worst-case VAE error by focusing on carefully chosen support sets at the latent layer. This method is implemented through a new training algorithm that utilizes this insight."}
{"id": "Pujt3ADZgI", "Context": "Reinforcement Learning with Human Feedback (RLHF) has been instrumental in aligning large language models with human preferences. However, existing RLHF methods primarily rely on reward-based approaches that follow the Bradley-Terry model assumption, which may not adequately represent the complexities of human preferences.", "Idea": "We propose a novel online algorithm called iterative Nash policy optimization (INPO) that formulates the RLHF problem as a two-player game. This method enables the policy to learn through no-regret learning, approximating the Nash policy while eliminating the need for estimating expected win rates, thereby reducing computational and annotation costs."}
{"id": "9HK2rHNAhd", "Context": "Optimizing the Key-Value (KV) cache of Large Language Models (LLMs) is essential for reducing inference costs. Existing KV-cache compression algorithms often focus on sparsifying token sequences based on token importance but treat all layers equally, leading to suboptimal performance.", "Idea": "We propose a method that optimizes KV-cache allocation by identifying the importance of attention layers and dynamically adjusting the KV budget for each layer. This method integrates sequence-wise algorithms to compress the KV-cache according to the specific budget assigned to each layer."}
{"id": "Mfnh1Sqdwf", "Context": "Predicting gene expressions from DNA sequences involves identifying the regulatory elements that influence these expressions. Accurately capturing the relationships between epigenomic signals, DNA sequences, and their regulatory elements is crucial for effective prediction.", "Idea": "We introduce Seq2Exp, a Sequence to Expression network that discovers and extracts regulatory elements driving gene expression. This method decomposes epigenomic signals and DNA sequences conditioned on causal regulatory elements, applying an information bottleneck with the Beta distribution to combine their effects while filtering out non-causal components."}
{"id": "pbre0HKsfE", "Context": "Large language models (LLMs) are increasingly used to provide personalized responses based on user interactions, raising significant privacy concerns. Homomorphic encryption (HE) offers a potential solution for privacy-preserving machine learning (PPML), but the computational demands of transformer architectures complicate the integration of HE with LLMs.", "Idea": "We propose a modified HE-friendly transformer architecture that emphasizes inference following personalized fine-tuning. Our approach utilizes LoRA fine-tuning and Gaussian kernels to achieve substantial computational speedups while maintaining performance comparable to plaintext models."}
{"id": "WeJEidTzff", "Context": "Commuting Origin-Destination (OD) flows are essential for urban planning and transportation, providing insights into population dynamics between residential and employment areas. The high cost of data collection has led researchers to develop physical and computational models that generate commuting OD flows using available urban attributes, such as sociodemographics and points of interest. However, the diversity of techniques and datasets used in existing works has created challenges in establishing a unified standard for comparing model performance.", "Idea": "We introduce a large-scale dataset containing commuting OD flows for 3,333 areas across various urban environments in the United States, along with a benchmark for widely used models in this domain. This approach aims to enhance the comparability and understanding of different models for commuting OD flow generation."}
{"id": "kiOxNsrpQy", "Context": "As Graph Neural Networks (GNNs) become more pervasive, the need for reliable tools to explain their predictions is critical. A core aspect of these explanations is their faithfulness, which refers to how accurately they reflect the GNN's reasoning process. However, the existence of various faithfulness metrics raises questions about the true nature of faithfulness and how to achieve it.", "Idea": "We demonstrate that existing faithfulness metrics are not interchangeable and can systematically ignore important properties of explanations. Furthermore, we show that optimizing for faithfulness is not always a sensible design goal, particularly for injective regular GNN architectures, and we investigate the relationship between architectural choices and faithfulness."}
{"id": "eENHKMTOfW", "Context": "The rise of large language models (LLMs) has created a significant disparity between well-resourced industrial research labs and individual developers or small organizations. While industrial labs can effectively fine-tune LLMs due to their computational resources and expert teams, smaller entities face barriers in exploring the experimental landscape due to limited resources.", "Idea": "This paper presents a comprehensive study on supervised fine-tuning of small-sized LLMs (3B to 7B parameters) using instruction-tuning datasets across diverse knowledge domains. It investigates various training configurations and strategies, offering detailed documentation and insights that challenge established training practices."}
{"id": "TEkoMEjf7E", "Context": "Generative 3D modeling has advanced significantly, yet it remains constrained by its ill-posed nature, leading to challenges in quality and controllability. Designers typically refer to existing 3D models when creating new ones, indicating a gap in current generative methods that fail to effectively incorporate such references.", "Idea": "We propose Phidias, a novel generative model that employs diffusion for reference-augmented 3D generation. This approach leverages a retrieved or user-provided 3D reference model to guide the generation process, thereby improving quality, generalization, and controllability."}
{"id": "EV7FMBZxnx", "Context": "Detecting concealed objects, such as in vivo lesions or camouflage, presents significant challenges that require specialized imaging systems. Lensless cameras are compact and flexible alternatives to traditional bulky lens systems, but their lack of lenses results in measurements that do not convey visual semantics, complicating concealed object detection (COD).", "Idea": "We propose a region gaze-amplification network (RGANet) that progressively exploits concealed objects from lensless imaging measurements. It features a region gaze module to mine spatial-frequency cues and a region amplifier to enhance object region details."}
{"id": "21rSeWJHPF", "Context": "Ranking vertices in a graph is a fundamental task in computer science, but traditional ranking algorithms can produce unbalanced results when the graph contains underlying communities. This unbalanced ranking can lead to a loss of information, polarized opinions, and reduced diversity, especially in unsupervised ranking where centrality measures like PageRank may also fail to provide balanced outcomes.", "Idea": "We introduce a method called relative centrality, which employs an iterative graph-dependent local normalization of centrality scores to enhance balanced rankings while maintaining the validity of the ranking. This approach specifically addresses the unbalancedness in centrality measures within graphs structured as multi-core-periphery with communities."}
{"id": "l0gZS0sAlf", "Context": "The training and fine-tuning of large language models (LLMs) often involve diverse textual data from multiple sources, leading to conflicting gradient directions that hinder optimization and specialization. This can negatively impact model generalization across tasks, resulting in diminished performance in downstream applications. Recent studies indicate that fine-tuning LLMs on carefully curated, task-specific subsets of data can achieve performance levels comparable to or exceeding those obtained from using the entire dataset.", "Idea": "We propose the Ensembles of Low-Rank Expert Adapters (ELREA) framework, which clusters training instructions based on their gradient directions to reduce conflicts during optimization. Expert adapters are trained on these clusters using low-rank adaptation (LoRA) techniques, ensuring efficient training and model scalability."}
{"id": "mFY0tPDWK8", "Context": "Leveraging machine learning to predict initial solutions for mixed-integer linear programming has gained popularity, as it allows for reducing problem dimensions by fixing a subset of variables. However, directly fixing variable values can result in low-quality or infeasible solutions if the predicted values are inaccurate.", "Idea": "We propose the Apollo-MILP framework, which alternates between predicting values for unfixed variables and correcting them to enhance the solution. This method introduces a novel Uncertainty-based Error upper BOund to assess the reliability of predicted values, ensuring that only those with high confidence are fixed."}
{"id": "mYgoNEsUDi", "Context": "Diffusion models have recently emerged as a powerful tool for generative artificial intelligence on graphs, with applications in drug design and knowledge discovery. However, existing graph diffusion models are limited in their ability to capture intrinsic higher-order topological properties, hindering their generalizability and effectiveness in downstream tasks.", "Idea": "We introduce a computationally efficient topological summary called zigzag spaghetti (ZS) that extracts latent salient topological graph descriptors across multiple resolutions. This method integrates dynamic topological information into graph diffusion models, addressing the limitations of current approaches."}
{"id": "LBl7Hez0fF", "Context": "Hallucination is a significant challenge for the effective deployment of large vision-language models (LVLMs) in various applications. This issue is distinct from that in large language models (LLMs) and often stems from misalignments between visual inputs and textual outputs. The unique structure of LVLMs, particularly the separate pre-training of image encoders and text decoders, contributes to this phenomenon.", "Idea": "We introduce Visual and Textual Intervention (VTI), a technique designed to reduce hallucinations by steering latent space representations during inference. This task-agnostic intervention enhances the stability of vision features and can be applied to any problem without additional training costs."}
{"id": "dQ2xiSIYzp", "Context": "Learning 3D human Gaussians from a single image is challenging, particularly in accurately recovering detailed appearance and geometry, including unobserved regions. Existing methods often struggle to generate realistic human poses and shapes, especially with inaccurate initial estimations.", "Idea": "We introduce a single-view generalizable Human Gaussian Model (HGM) that employs a generate-then-refine pipeline, guided by human body priors and diffusion priors. Our model utilizes a ControlNet to refine rendered images and incorporates a dual branch approach with the SMPL-X model to enhance human Gaussian reconstructions."}
{"id": "uHLgDEgiS5", "Context": "Traditional methods for estimating data influence, such as influence functions, assume that learning algorithms are permutation-invariant with respect to training data. However, modern training paradigms, particularly for foundation models, utilize stochastic algorithms and multi-stage curricula that are sensitive to data ordering, leading to a mismatch that limits the effectiveness of these methods. This raises critical questions about how to differentiate the influence of data at various training stages and how to capture the dependence of data influence on the optimization trajectory.", "Idea": "We formalize trajectory-specific leave-one-out (LOO) influence, which quantifies the impact of removing a data point from a specific iteration during training. To efficiently approximate this influence, we propose data value embedding, a technique that captures cumulative interactions between data and model parameters."}
{"id": "lPJUQsSIxm", "Context": "The integration of fully homomorphic encryption (FHE) with machine learning presents significant potential for ensuring the privacy of sensitive data during inference. While FHE allows computations on encrypted data, existing implementations for deep neural networks face challenges related to computational cost, latency, and scalability, limiting their practical deployment.", "Idea": "This paper introduces DCT-CryptoNets, a novel approach that operates in the frequency domain to reduce the computational burden of non-linear activations and homomorphic bootstrap operations during private inference. By utilizing the discrete cosine transform (DCT), this method enhances efficiency and scalability for encrypted predictions in image classification tasks."}
{"id": "rfdblE10qm", "Context": "The Bradley-Terry (BT) model is commonly used in reward modeling for aligning Large Language Models (LLMs), but its underlying rationale is unclear. Originally developed for multi-player stochastic game matching, its effectiveness in converting pairwise response comparisons into reward values is questioned, especially given the limited and sparse comparisons of prompt-response pairs.", "Idea": "We propose a simple upper-bound algorithm as an alternative order-consistent reward modeling objective, compatible with standard binary classifiers. This method focuses on maintaining order consistency in reward modeling."}
{"id": "W2Wkp9MQsF", "Context": "Model compression techniques are crucial for deploying large-scale neural networks in resource-constrained environments. Traditional methods often require access to training data and fine-tuning, which can be impractical. Additionally, existing approaches may struggle to preserve data statistics during compression, leading to performance degradation.", "Idea": "We introduce model folding, a data-free model compression technique that merges structurally similar neurons across layers to reduce model size without fine-tuning. This approach leverages k-means clustering to maintain data statistics and employs novel techniques to prevent variance collapse or explosion."}
{"id": "sLKDbuyq99", "Context": "Multi-agent frameworks utilizing large language models (LLMs) have shown promise in automated planning and task execution. However, effectively adjusting agent workflows during execution remains underexplored, particularly in real-world scenarios where initial plans must adapt to unforeseen challenges and changing conditions.", "Idea": "We propose defining workflows as an activity-on-vertex (AOV) graph, which allows LLM agents to continuously refine workflows through dynamic subtask allocation adjustments based on historical performance. We also emphasize modularity in workflow design to enhance performance by evaluating parallelism and dependency complexity."}
{"id": "9OJflnNu6C", "Context": "Generative models have advanced significantly but raise concerns regarding privacy breaches and biases in training data. Machine unlearning has emerged as a solution to remove specific training data from models. However, existing methods often treat machine unlearning as a single objective optimization problem, neglecting the diverse user expectations for balancing unlearning and model utility.", "Idea": "We propose a controllable unlearning framework that utilizes a control coefficient to manage the trade-off between complete unlearning and model utility. This framework reformulates the unlearning problem into a constrained optimization problem, ensuring that solutions are Pareto optimal within defined boundaries."}
{"id": "zjeHLSiNv1", "Context": "Transformer models exhibit performance that is logarithmically related to their number of parameters and computational complexity. Techniques like Mixture of Experts (MoE) attempt to decouple parameter count from computational demands but face challenges during inference due to high memory access costs.", "Idea": "We introduce UltraMem, which incorporates a large-scale, ultra-sparse memory layer to address these challenges. This architecture reduces inference latency while maintaining model performance and shows favorable scaling properties compared to MoE."}
{"id": "hgwGi81ndj", "Context": "Reinforcement learning often faces challenges in exploration, particularly in complex environments where agents must learn to navigate and interact with various items and their attributes. Traditional methods may struggle with efficiently predicting future states and managing item interactions, leading to suboptimal learning outcomes.", "Idea": "We propose a fully model-based algorithm that leverages an object-centric mapping to establish a hierarchical representation of items and their attributes. This method enhances exploration efficiency by utilizing a discriminative world model and planning based on abstract states with intrinsic rewards."}
{"id": "CI4sCBMXjP", "Context": "Enhancing the adaptive capabilities of large language models is a critical pursuit in research and application. Traditional fine-tuning methods require substantial data and computational resources, while in-context learning is limited by the need for appropriate demonstrations and efficient token usage.", "Idea": "We propose ELICIT, a framework consisting of two modules designed to store and reuse task vectors, enhancing the adaptive capabilities of models without additional training or inference tokens."}
{"id": "hJVdwBpWjt", "Context": "Large language models (LLMs) have demonstrated state-of-the-art performance in various auditory tasks, but their potential in bioacoustics, including detecting animal vocalizations and classifying rare species, is underutilized. This gap is critical for conservation and biodiversity monitoring, compounded by a scarcity of annotated data.", "Idea": "We present NatureLM-audio, the first audio-language foundation model specifically designed for bioacoustics, trained on a dataset of curated text-audio pairs from bioacoustics, speech, and music. This model utilizes learned representations from these domains to improve performance in bioacoustics tasks."}
{"id": "4GSOESJrk6", "Context": "Personalized image generation has the potential to enhance human productivity and creativity. However, existing evaluation methods either misalign with human judgment or rely on time-consuming human evaluations.", "Idea": "We introduce DreamBench++, a benchmark that automates human-aligned evaluations for multimodal GPT models. It employs systematically designed prompts to achieve both human and self-alignment, supported by a comprehensive dataset of diverse images and prompts."}
{"id": "PkpNRmBZ32", "Context": "Traditional neural network architectures for audio processing tasks often rely on convolutional layers and recurrent structures, which can limit flexibility and efficiency. Depthwise-separable configurations are common, but they may not fully exploit the potential of state-space models (SSMs) for training efficiency and design versatility.", "Idea": "We propose Centaurus, a network architecture that employs generalized state-space model blocks with systematically optimized tensor contractions. This design enables a heterogeneous mixture of classical convolutional block types, improving performance and computational efficiency without using traditional convolutional or recurrent mechanisms."}
{"id": "t8fu5m8R5m", "Context": "Anomaly Detection (AD) has made significant strides, yet existing methods struggle with robustness against adversarial attacks, undermining their reliability in critical applications like autonomous driving. This challenge arises from the AD framework, which relies on a limited set of unlabeled normal samples for training, leaving detectors vulnerable to adversarial anomalies during testing. Additionally, adversarial training encounters difficulties in formulating an effective objective function without access to labeled data.", "Idea": "We propose generating a pseudo-anomaly group from normal samples and employing adversarial training with contrastive loss as an effective objective function. This method enhances both inter- and intra-group perturbations and addresses the issue of spurious negative pairs by defining opposite pairs and pulling them apart to improve robustness."}
{"id": "fGhr39bqZa", "Context": "Causal discovery with latent variables is a significant challenge, particularly due to the prevalent assumption that these variables have pure children. This assumption can be restrictive in practice and is not strictly necessary in theory, which limits the effectiveness of existing methods.", "Idea": "We introduce homologous surrogates, which permit more flexible parent relationships in causal discovery. By establishing two assumptions regarding homologous surrogates, we derive theoretical results that facilitate both partial and full recovery of causal graphs, leading to a novel algorithm for causal graph recovery."}
{"id": "4ua4wyAQLm", "Context": "Video anomaly detection (VAD) aims to identify novel actions or events that are unseen during training. Existing VAD techniques often focus on global patterns, leading to redundancy and challenges in generalizing to unseen samples.", "Idea": "We propose a framework that identifies local patterns that generalize to novel samples by modeling their dynamics. This involves a two-stage process of image-text alignment and cross-modality attention, complemented by a State Machine Module that incorporates temporal clues."}
{"id": "xPxHQHDH2u", "Context": "Novel view synthesis has advanced with NeRF- and 3DGS-based methods, yet reflective object reconstruction remains challenging. Existing solutions fail to provide real-time, high-quality rendering while accommodating inter-reflection, highlighting a gap in current methodologies.", "Idea": "We introduce the Reflective Gaussian splatting (Ref-Gaussian) framework, featuring a physically based deferred rendering component and a Gaussian-grounded inter-reflection mechanism. This framework enhances geometry modeling and effectively addresses both reflective and non-reflective scenes."}
{"id": "i3e92uSZCp", "Context": "Skill discovery methods enable agents to learn diverse behaviors without explicit rewards. A key challenge is obtaining a semantically diverse repertoire of skills, which is crucial for effectiveness in downstream tasks. While some approaches focus on distinguishing skills or increasing state coverage, the direct pursuit of semantic diversity in skills remains underexplored.", "Idea": "We introduce Language Guided Skill Discovery (LGSD), a framework that maximizes the semantic diversity of skills by using user prompts to guide the search for semantically distinctive skills. This method leverages the semantic knowledge of large language models to help agents explore diverse states within a desired subspace."}
{"id": "ws5phQki00", "Context": "Stance detection is crucial for enhancing online political discussions, particularly for content moderation and topic summarization. However, the reliance on transformer-based models necessitates large datasets, which are challenging to collect due to the diverse range of debate topics. Additionally, deploying large language models (LLMs) faces issues such as inconsistent outputs, biases, and vulnerability to adversarial attacks.", "Idea": "We propose leveraging LLM-generated synthetic data to improve stance detection by utilizing traditional models for online deployment. This approach involves generating synthetic data for specific debate questions and fine-tuning stance detection models with both synthetic data and the most informative samples from an unlabelled dataset."}
{"id": "Bp0HBaMNRl", "Context": "Discovering causal structures with latent variables from observational data is a fundamental challenge. Existing methods often rely on constraint-based approaches and discrete searches, which limit scalability for large numbers of variables. These methods frequently assume linearity or invertibility, restricting their applicability in real-world scenarios.", "Idea": "We present a novel differentiable causal discovery algorithm that estimates the structure of non-linear latent hierarchical causal models, relaxing previous assumptions about the deterministic nature of latent variables and exogenous noise. This method is the first to address non-linear latent hierarchical models in causal discovery."}
{"id": "2IoFFexvuw", "Context": "Recent advancements in reinforcement learning (RL) have achieved success in fine-tuning generative models, particularly diffusion-based ones. However, challenges persist in aligning continuous flow-based generative models with user-defined reward functions, including policy collapse from overoptimization and high computational costs of likelihoods in continuous-time flows.", "Idea": "We propose a method called Online Reward-Weighted Conditional Flow Matching with Wasserstein-2 Regularization (ORW-CFM-W2), which integrates RL into the flow matching framework. This approach employs an online reward-weighting mechanism to prioritize high-reward regions while using Wasserstein-2 distance regularization to prevent policy collapse and maintain diversity."}
{"id": "izjNI5bcOV", "Context": "The Earth's weather system is complex, involving various data modalities and tasks that are crucial for human life. Current data-driven models typically focus on individual weather understanding tasks, such as forecasting, but do not integrate multiple tasks into a single framework. This limitation, along with reliance on a narrow set of real observations, restricts the overall performance of these models.", "Idea": "We introduce WeatherGFM, a generalist foundation model that unifies diverse weather understanding tasks. It employs a unified representation for various tasks and utilizes weather prompt formats to manage different data modalities, leveraging a visual prompting question-answering approach for training."}
{"id": "5IWJBStfU7", "Context": "As AI systems are increasingly deployed in high-stakes applications, ensuring their interpretability is essential. Mechanistic Interpretability (MI) aims to reverse-engineer neural networks by extracting human-understandable algorithms embedded within their structures to explain their behavior. A fundamental question arises regarding the uniqueness of explanations provided by MI for a given behavior, drawing an analogy with identifiability in statistics.", "Idea": "We propose two strategies for generating MI explanations: the 'where-then-what' approach, which identifies a circuit within the network that replicates behavior before deriving its interpretation, and the 'what-then-where' approach, which begins with candidate explanatory algorithms and searches for their implementation in the activation subspaces of the neural model."}
{"id": "z8PcUSKXXN", "Context": "Recent advancements in generalizable deep image denoising have led to robust noise-handling models. The current state-of-the-art, Masked Training (MT), is trained on Gaussian noise but often produces over-smoothed images and faces challenges in mask ratio optimization, complicating integration with other methodologies.", "Idea": "This paper introduces RNINet, a novel architecture based on a streamlined encoder-decoder framework. It features a noise injection block that enhances generalization across unseen noise types, addressing the architectural complexity of existing methods."}
{"id": "yitH9xAHQs", "Context": "Large language models (LLMs) have shown remarkable performance improvements when trained on diverse, high-quality task-specific data. However, existing methods often depend on human-annotated data or predefined templates, which can limit the variety of generated data and may overlook critical edge cases or novel scenarios that challenge the model.", "Idea": "We propose ReverseGen, an approach that automatically generates training samples to expose the weaknesses of LLMs. It employs a dedicated proposer to create failure-inducing queries that elicit unsatisfactory responses, thereby constructing training data that addresses the models' shortcomings."}
{"id": "pPQPQ7Yd58", "Context": "This study investigates the geometry of the visual representation space in image-based control pipelines learned from behavior cloning. It highlights the emergence of clustering patterns in visual representations, drawing inspiration from the phenomenon of neural collapse observed in image classification.", "Idea": "Leverage the identified law of clustering in visual representations as an algorithmic tool to enhance test-time performance. This approach involves pretraining the vision encoder with neural collapse as a regularization technique to encourage control-oriented clustering of visual features, followed by finetuning with the action decoder."}
{"id": "6qUUgw9bAZ", "Context": "Decoding procedures in language models, such as search and reranking, are computationally intensive and can enhance output quality across tasks like code generation, numerical reasoning, and dialog. Existing methods apply a uniform decoding approach to all inputs, which can lead to inefficient resource allocation.", "Idea": "We propose an adaptive computation allocation method that predicts the reward distribution for each input and adjusts the decoding resources accordingly, using more computation for complex queries and less for simpler ones."}
{"id": "d8hYXbxX71", "Context": "Policymakers face the complex challenge of improving social welfare across multiple time horizons, where short-term evaluations may not accurately reflect long-term benefits. The conventional view posits a conflict between Rawlsian policies, which focus on aiding those in greatest need, and utilitarian policies, which aim to maximize immediate welfare gains. This dichotomy complicates the assessment of policy effectiveness, as short-term suboptimal policies may yield significant long-term advantages.", "Idea": "We propose a sequential decision-making framework to analyze the long-term dynamics of Rawlsian and utilitarian policies, showing that Rawlsian interventions can the proposed approach utilitarian ones in the long run under certain conditions. This framework highlights the necessity of considering long-term effects in the evaluation of welfare policies."}
{"id": "G0dksFayVq", "Context": "LLM-based judges are increasingly used as a scalable alternative to human evaluators for assessing and improving models. However, their reliability is often overlooked, particularly as LLMs advance and produce more complex outputs. Existing benchmarks primarily focus on judges' alignment with human preferences, which may not adequately evaluate their performance on tasks requiring factual and logical accuracy.", "Idea": "We propose a novel evaluation framework to objectively assess LLM-based judges, introducing JudgeBench, a benchmark that evaluates judges on challenging response pairs across knowledge, reasoning, math, and coding. This framework utilizes a pipeline to convert difficult datasets into pairs with preference labels reflecting objective correctness."}
{"id": "vJkktqyU8B", "Context": "Current Vision Transformer (ViT) adapter methods have achieved promising accuracy but face challenges related to inference speed due to inefficient memory access operations, such as standard normalization and frequent reshaping. These inefficiencies can hinder overall model performance, especially in tasks requiring rapid processing.", "Idea": "We propose META, a memory-efficient ViT adapter that improves memory efficiency by sharing layer normalization between self-attention and feed-forward network layers. It also features a lightweight convolutional branch to enhance local inductive biases and is designed in a cascaded manner to compute diverse head features."}
{"id": "SiH7DwNKZZ", "Context": "Transformers have become a popular choice as backbone architectures in computer vision, despite being originally designed for natural language processing. The Long Short-Term Memory (LSTM) architecture has advanced with the introduction of the xLSTM, which addresses limitations of traditional LSTMs through exponential gating and a parallelizable memory structure.", "Idea": "We propose Vision-LSTM (ViL), which adapts the xLSTM architecture for computer vision tasks. ViL consists of a stack of xLSTM blocks that process patch tokens in alternating top-to-bottom and bottom-to-top sequences."}
{"id": "9NfHbWKqMF", "Context": "3D Gaussian Splatting (3DGS) has recently advanced photorealistic reconstruction, providing high visual fidelity and real-time performance. However, rendering quality significantly deteriorates for test views that differ from the camera angles used during training, posing a challenge for immersive free-viewpoint rendering and navigation. A comprehensive evaluation reveals that many existing methods struggle to generalize effectively to out-of-distribution (OOD) test camera scenarios.", "Idea": "We introduce SplatFormer, a point transformer model designed for Gaussian splats. It refines an initial 3DGS set optimized under limited training views in a single forward pass, effectively removing artifacts in OOD test views."}
{"id": "84WmbzikPP", "Context": "Molecular structure elucidation is essential for understanding chemical phenomena, with applications in identifying molecules in natural products, lab syntheses, forensic samples, and the interstellar medium. Predicting a molecule's 3D structure from its molecular formula and moments of inertia is challenging, particularly due to existing generative models that inadequately utilize the precision of experimental measurements.", "Idea": "We propose Stiefel Flow Matching as a generative model for predicting 3D molecular structures under exact moment constraints. This method utilizes the Stiefel manifold to enhance the accuracy and efficiency of structure elucidation."}
{"id": "9FqARW7dwB", "Context": "Residual connections are commonly used in neural networks but often face challenges such as gradient vanishing and representation collapse, which can impair model performance in complex tasks like language processing and computer vision. This highlights the need for alternative methods to effectively mitigate these issues.", "Idea": "We introduce hyper-connections, a method that enables networks to dynamically adjust the strength of connections between features at different depths and rearrange layers. This approach serves as an effective alternative to residual connections."}
{"id": "ho4mNiwr2n", "Context": "Anti-backdoor learning is a crucial defense strategy against backdoor attacks, which involve training models on poisoned datasets. Existing methods often fail to recover backdoored samples to their correct labels and do not generalize well to large pre-trained models due to their lack of end-to-end training.", "Idea": "We introduce an end-to-end method called Mind Control through Causal Inference (MCCI) that leverages both images and their associated attack indicators to train clean models directly from poisoned datasets. This method enables controlled perception of inputs, allowing the model to classify poisoned samples correctly."}
{"id": "WwmtcGr4lP", "Context": "Effective cancer treatment is challenging due to the individualized responses of patients, driven by diverse mutations in their genomes. The limited availability of patient response data hinders the development of personalized treatment recommendation models based on clinical genomic sequencing. Existing methods utilize larger pre-clinical datasets through transfer learning but often fail to capture patient-specific characteristics that influence drug responses.", "Idea": "We propose GANDALF, a generative attention-based data augmentation and predictive modeling framework that directly enhances patient genomic data while accounting for domain-specific characteristics. This approach aims to improve the modeling of patient-specific traits, addressing the shortcomings of prior methods."}
{"id": "d8cnezVcaW", "Context": "Direct Preference Optimization (DPO) has gained traction as a method to enhance reinforcement learning from human feedback (RLHF) for fine-tuning large language models (LLMs). However, DPO has a notable limitation in its inability to effectively capture the diversity of human preferences.", "Idea": "We propose a new approach called MallowsPO, which incorporates a dispersion index to characterize the variability in human preferences. This approach unifies existing DPO models and improves their performance."}
{"id": "MGKDBuyv4p", "Context": "Language models can memorize information from their training data, leading to the regurgitation of sensitive or private data during inference. This poses significant risks in applications where data confidentiality is crucial, making the challenge of mitigating memorization increasingly important.", "Idea": "We propose various methods to mitigate memorization, including three regularizer-based, three fine-tuning-based, and eleven machine unlearning-based approaches, with five novel unlearning methods introduced. Additionally, we introduce TinyMem, a suite of small, efficient language models for the rapid development and evaluation of these memorization-mitigation techniques."}
{"id": "vmulbBDCan", "Context": "Electron-multiplying charge-coupled devices (EMCCDs) are crucial for sensitive imaging in low-light conditions across fields such as astronomy, material science, and biology. Despite their advanced designs to enhance target signals and reduce read-out circuit noise, the images produced still contain noise that can affect experimental outcomes, particularly in fluorescence microscopy. Previous research on EMCCD noise models has focused on theoretical statistical characteristics, lacking integration with advancements in computational photography that utilize physics-based noise models for deep learning.", "Idea": "We propose a systematic approach to calibrate physics-based noise models for EMCCD cameras, enabling accurate estimation of noise components. This calibration will generate authentic training samples for advanced neural networks, improving denoising techniques for EMCCD images."}
{"id": "iXCeQ2m6vT", "Context": "Human understanding of visual relations, especially with previously unseen objects, significantly outperforms that of AI systems. While humans can easily discern whether two objects are visually the same or different, AI struggles with this task. Active vision theories suggest that learning visual relations is linked to actions taken to focus on objects through eye movements.", "Idea": "We propose a system called Glimpse-based Active Perception (GAP) that sequentially glimpses the most salient regions of an image and processes them at high resolution. This system leverages the locations from the glimpsing actions and the surrounding visual content to represent relations between different parts of the image."}
{"id": "FoF5RaA3ug", "Context": "Recent advancements in dataset distillation have highlighted the advantages of using soft labels generated by pre-trained teacher models. However, the optimal utilization of these labels, particularly regarding loss functions, remains underexplored, impacting model performance on synthetic datasets.", "Idea": "We introduce GIFT, a straightforward approach that integrates soft label refinement with a cosine similarity-based loss function to fully utilize label information in dataset distillation. This method aims to provide a universal loss function that improves model training across various dataset scales."}
{"id": "R4h5PXzUuU", "Context": "The rise of foundation models trained on extensive internet-scale data has led to their widespread adoption across various application domains. However, the trustworthiness of these models, particularly their out-of-distribution detection (OoDD) capabilities, remains largely unexamined, raising concerns about their safe and reliable deployment.", "Idea": "We propose a self-guided prompting approach called Reflexive Guidance (ReGuide) to enhance the OoDD capabilities of large vision-language models (LVLMs). This method leverages self-generated image-adaptive concept suggestions."}
{"id": "gU4ZgQNsOC", "Context": "Pretraining large language models (LLMs) on vast and heterogeneous datasets is crucial for achieving state-of-the-art performance across diverse downstream tasks. Current training paradigms treat all samples equally, overlooking the importance of individual samples throughout the training process. Existing reweighting strategies focus on group-level data importance, failing to leverage fine-grained instance-level information and not adapting dynamically to individual sample importance as training progresses.", "Idea": "We introduce novel algorithms for dynamic, instance-level data reweighting aimed at improving the efficiency and effectiveness of LLM pretraining. Our methods adjust the weight of each training sample based on its loss value in an online fashion, allowing the model to focus on more informative samples while deprioritizing redundant or uninformative data."}
{"id": "f7KxfUrRSb", "Context": "Aligning language models with human preferences is a key research area aimed at enhancing their ability to meet diverse user needs. The concept of weak-to-strong generalization, where a stronger model is fine-tuned using outputs from a weaker model, presents an opportunity for improving model alignment.", "Idea": "We propose a method called Weak-to-Strong Preference Optimization (WSPO), which achieves strong model alignment by learning the distribution differences before and after the alignment of the weak model. This method effectively transfers the alignment behavior from weaker models to stronger ones."}
{"id": "oU3tpaR8fm", "Context": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to utilize external knowledge sources, which is increasingly important as these models can process longer input sequences. This suggests that a larger retrieval set could enhance the quality of generated outputs. However, empirical findings show that the quality of output may initially improve with more retrieved passages but can decline due to the impact of detrimental 'hard negatives'.", "Idea": "To mitigate the challenges posed by hard negatives and enhance the robustness of long-context LLM-based RAG, we propose both training-free and training-based approaches. These include retrieval reordering as a training-free optimization and RAG-specific fine-tuning methods that incorporate intermediate reasoning."}
{"id": "iylpeTI0Ql", "Context": "Test-time adaptation (TTA) addresses distribution shifts between source and target data by relying solely on target data during testing. In open-world scenarios, models often encounter noisy samples outside the in-distribution label space, which can adversely affect performance. Existing TTA methods experience significant declines in effectiveness when faced with these noisy samples.", "Idea": "We introduce a framework called Zero-Shot Noisy Test-time Adaptation (ZS-NTTA) that decouples the classifier and noise detector, enabling the development of a dedicated noise detector while keeping the classifier frozen. This framework features the Adaptive Noise Detector (AdaND), which leverages outputs from the frozen model as pseudo-labels to effectively detect noisy samples."}
{"id": "4rEI2JdHH6", "Context": "The phenomenon of 'grokking' in neural networks involves an initial phase of memorization followed by a sudden shift to effective generalization after extended training. This delayed generalization can hinder the predictability and efficiency of models, making direct and prompt generalization desirable.", "Idea": "This paper introduces GrokTransfer, a method to accelerate grokking by utilizing the significance of data embedding. It trains a weaker model to a non-optimal performance and then uses its learned input embedding to initialize a stronger model, facilitating direct generalization without delay."}
{"id": "vQhn4wrQ6j", "Context": "Fine-tuning Large Language Models (LLMs) for specific tasks in non-English languages is challenging due to the lack of task-specific data. Existing model merging techniques, like model souping, do not adequately address the needs of mathematical reasoning in these scenarios, resulting in limited performance.", "Idea": "We introduce a model merging methodology that improves math performance in target languages by fine-tuning distinct 'experts' on math instruction data in English and generic instruction data in the target language, followed by a layer swapping technique to facilitate cross-lingual transfer."}
{"id": "vr1QdCNJmN", "Context": "Bregman divergence is widely used in continuous spaces for comparing vectors or functions, but extending this concept to discrete spaces presents significant challenges. Previous work has explored Bregman divergences in discrete domains using submodular functions as generating functions, but these approaches have limitations that require further exploration.", "Idea": "We propose a generalization of the Bregman divergence framework for discrete spaces that accommodates generating functions beyond submodular and supermodular forms, resulting in the difference-of-submodular Bregman divergence. We also introduce a learnable version of this divergence utilizing permutation-invariant neural networks."}
{"id": "2e4ECh0ikn", "Context": "Recent advancements in audio foundation models (FMs) have the potential to enhance conversational modeling. However, there has been limited evaluation of these models' capabilities in facilitating natural and interactive conversations, particularly in managing turn-taking without excessive overlap or silence.", "Idea": "We propose a novel evaluation protocol to assess the turn-taking capabilities of spoken dialog systems, using a supervised model trained to predict turn-taking events in human conversations. This protocol will facilitate a comprehensive user study of existing systems and identify areas for improvement."}
{"id": "QG31By6S6w", "Context": "Recent advancements in medical vision-language pre-training models have significantly improved zero-shot disease recognition. However, transferring knowledge from image-level tasks to pixel-level tasks, particularly for lesion segmentation in 3D CT scans, remains challenging due to the complexity and variability of pathological visual characteristics, which complicate the alignment of fine-grained lesion features with disease-related textual representations.", "Idea": "We propose Malenia, a multi-scale lesion-level mask-attribute alignment framework for 3D zero-shot lesion segmentation. This framework enhances compatibility between mask representations and their associated attributes, linking visual features of unseen lesions with knowledge from previously seen ones, and includes a Cross-Modal Knowledge Injection module to improve feature guidance."}
{"id": "X9OfMNNepI", "Context": "Scientific discovery is vital for human advancement, and recent developments indicate that large language models (LLMs) could facilitate this process. However, it remains unclear if LLMs can autonomously generate novel and valid hypotheses in chemistry based on a research question.", "Idea": "We propose a multi-agent framework that decomposes the hypothesis discovery process into three stages: retrieving inspirations from a background question, generating hypotheses from those inspirations, and ranking the hypotheses for quality. This approach utilizes a comprehensive corpus of chemistry literature to rediscover hypotheses that closely align with established ones."}
{"id": "keu6sxrPWn", "Context": "As large language models (LLMs) become more powerful, concerns about their trustworthiness have increased. These models may align with human intentions or exhibit 'subversive misalignment,' leading to subtle errors that could compromise safety. The challenge in deploying these models lies in balancing safety with the desire to leverage their capabilities, as individual errors could accumulate to create significant risks.", "Idea": "We introduce the 'Diffuse Risk Management' problem, which aims to balance safety and usefulness in deploying untrusted models across multiple tasks. Our method features a two-level framework comprising micro-protocols that utilize trusted models to monitor untrusted ones and a macro-protocol that adaptively selects between these micro-protocols based on the estimated risk of the untrusted model."}
{"id": "2ZK8zyIt7o", "Context": "The rapid advancement of text-to-image diffusion models has enabled unprecedented image generation from text. However, as text inputs grow longer, existing encoding methods like CLIP face limitations, making it challenging to align generated images with these longer texts.", "Idea": "We propose LongAlign, which features a segment-level encoding method that processes long texts by dividing them into segments, and a decomposed preference optimization method for effective alignment training. This approach reweights components of preference scores to mitigate overfitting and enhance alignment."}
{"id": "RaR3ETzyKp", "Context": "Recent research indicates that different diffusion methods and architectures trained on the same dataset yield similar results for the same input noise, suggesting the presence of preferable noises for specific samples. Visualizations of noise-sample pairs show that paths connecting these preferable noises to their corresponding samples are more organized and have fewer crossings than random paths.", "Idea": "We propose the Distance-Aware Noise-Sample Matching (DANSM) method to increase the inter-path distance, thereby accelerating model training. This method utilizes rectified flow models to calculate inter-path distances with a closed-form formula and simplifies optimization by establishing a relationship between inter-path distance and path length."}
{"id": "Wvi8c0tgvt", "Context": "Existing realistic blur datasets provide insufficient variety in scenes and blur patterns, limiting effective training. Expanding data diversity is time-consuming, particularly with complex dual-camera systems. Current data augmentation methods typically estimate motions from a 2D perspective, resulting in unrealistic motion patterns that overlook the 3D nature of camera and object movements.", "Idea": "We propose a 3D-aware blur synthesizer that generates diverse and realistic blur images for data augmentation by estimating 3D camera positions during motion blur intervals. This approach enables controllable blur augmentation by modifying blur magnitude, direction, and scenes."}
{"id": "c4OGMNyzPT", "Context": "Large Vision Language Models (LVLMs) have shown significant potential in understanding and reasoning about visual and textual information. However, current evaluation methods, primarily reliant on benchmarks like Visual Question Answering and image captioning, are inadequate as they do not fully capture the diverse capabilities of LVLMs. These methods face challenges such as insufficient assessment of detailed visual perception, data contamination, and a lack of emphasis on multi-turn reasoning.", "Idea": "We propose LVLM-Playground, a game-based evaluation framework designed to comprehensively assess LVLMs' cognitive and reasoning skills in structured environments. This framework employs a series of games to evaluate LVLMs on four core tasks: Perceiving, Question Answering, Rule Following, and End-to-End Playing, each targeting specific abilities."}
{"id": "bc3sUsS6ck", "Context": "Large language models (LLMs) are pretrained on vast amounts of data, acquiring significant knowledge. However, adapting these models to new contexts, tasks, or domains often requires fine-tuning, which is costly, or prompting, which can increase inference overhead.", "Idea": "We propose GenerativeAdapter, an adaptation method that encodes test-time context into language model parameters with a single forward pass. It employs a lightweight adapter generator, trained via self-supervised learning, to produce parameter-efficient adapters applicable across various language processing scenarios."}
{"id": "rpouyo09V0", "Context": "Large language models (LLMs) have become essential tools for code generation, particularly in interactive settings. However, existing benchmarks fail to capture the diverse feedback encountered in multi-turn interactions, limiting the evaluation of LLMs in these contexts.", "Idea": "We present a set of novel benchmarks that model the quality of feedback for code generation LLMs, including CONVCODEWORLD, which simulates distinct interactive scenarios with various feedback types, and CONVCODEBENCH, a static benchmark that employs pre-generated feedback logs."}
{"id": "0mtz0pet1z", "Context": "In preventive medicine, the timing of treatment initiation is crucial, particularly in disease screening and vaccination. Traditional causal inference methods have focused on the timing of treatment and its effects, but there is a gap in understanding the incremental causal effects associated with varying the timing of treatment initiation.", "Idea": "We propose a method to identify the incremental causal effect of time to treatment initialization without relying on the positivity assumption. This includes an estimation framework that utilizes inverse probability weighting."}
{"id": "u3TL0qxLWf", "Context": "Large Language Models (LLMs) have transformed natural language processing, but their deployment is challenged by high runtime costs, limiting accessibility and usability across applications.", "Idea": "We introduce SeedLM, a post-training compression method that employs seeds from a pseudo-random generator to encode and compress model weights. This method generates a random matrix during inference for efficient weight reconstruction, while being data-free and generalizing well across diverse tasks."}
{"id": "4O0v4s3IzY", "Context": "There is ongoing debate regarding the reasoning capabilities of Large Language Models (LLMs), particularly due to counterexamples that challenge the belief that reasoning improves with scale. Many assert that LLMs can enhance their solutions through self-critique, based on the assumption that verifying correctness is less complex than generating answers, which raises questions about their actual reasoning abilities.", "Idea": "This paper systematically investigates the effectiveness of iterative prompting for reasoning and planning in LLMs, focusing on GPT-4. It examines the roles of self-critique and external verification in influencing performance across various domains."}
{"id": "P4XmKjXTrM", "Context": "Reproducibility is a major issue in machine learning applications within healthcare, primarily due to the private nature of datasets, model pipelines, and task definitions. This lack of transparency creates barriers to sharing and understanding results derived from electronic health record (EHR) datasets, complicating research and development.", "Idea": "We propose the Automatic Cohort Extraction System (ACES), a library that simplifies the development of machine learning tasks and cohorts in healthcare while enhancing reproducibility. ACES includes a domain-specific configuration language for defining criteria and a pipeline for automatically extracting relevant patient records from real-world data."}
{"id": "SgymXhOEA5", "Context": "Person re-identification (ReID) models encounter significant challenges due to camera bias, which affects their performance across different domains. Previous methods to address this bias have largely focused on training within specific domains, leaving a gap in understanding model performance in unseen domains. Our investigation shows that camera bias becomes more pronounced with shifts in data distribution, underscoring the need for effective debiasing methods.", "Idea": "We propose revisiting feature normalization on embedding vectors as a debiasing method for unseen domain data. This approach effectively reduces bias and is applicable to various factors, including low-level image properties and body angles, while demonstrating generalizability across different models and benchmarks."}
