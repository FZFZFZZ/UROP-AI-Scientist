{"id": "nDvgHIBRxQ", "Context": "Mathematical reasoning is a hallmark capability of large language models, yet comprehensively defining and evaluating this ability—especially in ways that reflect real-world user experience—remains challenging. Prevailing benchmarks focus narrowly on fixed problem formats, creating overfitting risks and failing to capture genuine reasoning competence, including robustness and task generalization.", "Idea": "MathCheck is a checklist-based evaluation framework that tests task generalization and reasoning robustness in mathematical settings, supported by an automatic tool for efficient checklist generation. It spans multiple reasoning tasks and robustness tests and is instantiated as MathCheck-GSM for mathematical textual reasoning and MathCheck-GEO for multi-modal reasoning, serving as upgraded versions of GSM8k, GeoQA, UniGeo, and Geometry3K."}
{"id": "ZsP3YbYeE9", "Context": "Language-model-based agents are often built by iteratively prompting, reflecting on outputs, and refining prompts until a task is completed. However, they frequently produce repetitive reflections that limit decision-space exploration and treat each task in isolation, failing to reuse knowledge from previously solved tasks.", "Idea": "Diversity of Thoughts (DoT) is a framework that explicitly reduces redundant reflections to enhance decision-space exploration. It adds a task-agnostic memory component that stores and retrieves knowledge from previously solved tasks. DoT is modular, and its diverse reflection module can integrate with existing reasoning methods."}
{"id": "I4e82CIDxv", "Context": "Prior mechanistic interpretability circuits rely on coarse, polysemantic units (attention heads or neurons) that are difficult to interpret and ill-suited for precise explanations or downstream use, motivating fine-grained, human-interpretable structures that support causal analysis and scale across behaviors.", "Idea": "We present methods to discover and apply sparse feature circuits, defined as causally implicated subnetworks built from fine-grained, human-interpretable features. We also introduce SHIFT, which ablates human-judged task-irrelevant features to modify a classifier, and an unsupervised, scalable pipeline to discover circuits for automatically discovered model behaviors."}
{"id": "pHe4P1IVnb", "Context": "As large language models become more capable, aligning them is difficult when only weak human supervision is available. Weak-to-Strong frames this setting by having a weaker supervisor guide a stronger model. Challenges include variability in human judgments and the added complexity of supervising open-ended text generation compared to classification.", "Idea": "Extend Weak-to-Strong to WeakS-to-Strong by supervising a strong student model with an ensemble of weak models that simulate diverse opinions. Estimate confidence scores via a Bayesian approach to guide generalization, and broaden the framework from text classification to text generation with more advanced supervision strategies. Apply direct preference optimization to improve the student's preference learning beyond teacher forcing."}
{"id": "Pj4Aid3XqL", "Context": "Pre-trained LLMs can be adapted to vision-language tasks by adding image data in a later training phase, but the trade-offs versus integrating images earlier during pre-training remain unclear.", "Idea": "Pre-train with mixed image–text data while systematically varying when vision tokens are introduced, alongside the image–text ratio and model scale. This design enables direct comparison between early and late introduction of vision tokens."}
{"id": "B2Fqu7Y2cd", "Context": "Building systems that synthesize or transform audio from free-form text with optional audio inputs is challenging. Unlike text corpora used to train language models, audio-only data does not include the instructions that generated it, making instruction-following hard to learn. Moreover, attaining compositional behaviors such as combining, interpolating, or negating instructions purely from data is nontrivial.", "Idea": "Introduce Fugatto, a versatile audio synthesis and transformation model that follows free-form text instructions with optional audio inputs. Propose a specialized dataset generation approach that yields diverse instruction–audio pairs to align language with sound. At inference, present ComposableART, extending classifier-free guidance to compositional guidance to combine, interpolate, and negate instructions."}
{"id": "MWHIIWrWWu", "Context": "Controlling high-dimensional nonlinear systems in biological and robotic settings is challenging due to large state and action spaces. Although deep reinforcement learning has achieved successes in these domains, it is computationally intensive, time-consuming, and requires substantial manual tuning, making it impractical for large collections of tasks.", "Idea": "Model Predictive Control with Morphology-aware Proportional Control (MPC^2) is a hierarchical model-based learning algorithm that combines a sampling-based model predictive controller for target posture planning with a morphology-aware proportional controller for actuator coordination in high-dimensional dynamical systems. It also employs black-box optimization to tune the reward function."}
{"id": "cmYScmfu4Q", "Context": "In RLHF for fine-tuning large language models, reward inference from human preferences is an intermediate step but suffers from distribution shift, reward model overfitting, and misspecification. Direct methods like DPO simplify the pipeline but rely on a closed-form link between the optimal policy and the reward, restricting them to bandit settings or deterministic MDPs; general stochastic RL and broader preference models remain unaddressed.", "Idea": "We propose two RLHF algorithms that eliminate reward inference and apply to general RL beyond bandits and deterministic MDPs, accommodating preference models beyond the Bradley-Terry model. They estimate local value-function differences from human preferences and use a zeroth-order gradient estimator to approximate policy gradients for direct policy improvement."}
{"id": "6HcnC3pPkp", "Context": "As test-time compute search strategies advance to improve large language models’ mathematical problem solving, robust verifiers are critical. Existing verifiers—built for Best-of-N search—are ill-suited for tree search, offering only indirect assessments of partial solutions and undervaluing promising intermediate steps, leading to premature pruning.", "Idea": "We propose token-supervised value models (TVMs), verifiers that assign each token a probability reflecting the likelihood of reaching the correct final answer. This token-level supervision enables direct, explicit evaluation of partial solutions, effectively distinguishing between promising and incorrect intermediate steps during tree search at test time."}
{"id": "BAelAyADqn", "Context": "Longitudinal human behavior modeling uses ubiquitous device data to predict short-term health and well-being outcomes from time series of individual behaviors. Many existing models on ubiquitous health data lack adequate accuracy and overlook realistic challenges—heterogeneous feature types, high missingness, and constraints on computing power, time, and cost—limiting practical applicability.", "Idea": "MuHBoost is a multi-label boosting method that leverages large language model prompting alongside multi-label classification to jointly predict multiple health and well-being outcomes from ubiquitous health data. To mitigate LLM hallucinations when answering multiple questions simultaneously, two variants adjust the prompting and prediction scheme."}
{"id": "svp1EBA6hA", "Context": "Diffusion models enable precise control over generated samples, but downstream applications often need to add new controls when fine-tuning large pre-trained models. In practice, controls are introduced from offline input–label data, while existing guidance-based techniques can be sample-inefficient, complicate dataset construction, and require training classifiers on intermediate diffusion states.", "Idea": "CTRL conditions pre-trained diffusion models via a reinforcement-learning formulation. It uses a reward that combines a learned classifier for the desired controls with a KL regularization toward the pre-trained model, optimizing a soft-optimal policy. This policy enables sampling from the conditional distribution with the additional controls during inference."}
{"id": "l2zFn6TIQi", "Context": "The growing capabilities and deployment of large generative models have heightened concerns about reliability, safety, and misuse. There is a need to control which concepts and behaviors arise during generation.", "Idea": "Activation Transport (AcT) is a general, modality-agnostic framework that steers internal model activations using optimal transport, generalizing prior activation-steering methods. It controls the emergence of specific concepts or behaviors during generation."}
{"id": "FpiCLJrSW8", "Context": "Ensuring LLM outputs are reliable, safe, and ethically aligned is as critical as cognitive performance. Although RLHF is widely used to align models with human preferences, its effect on trustworthiness has not been rigorously evaluated. There is a need to assess trustworthiness across toxicity, stereotypical bias, machine ethics, truthfulness, and privacy.", "Idea": "Adapt efficient influence-function-based data attribution methods to the RLHF setting to quantify how elements of the fine-tuning data influence individual trustworthiness benchmarks. The approach produces per-example attribution scores to explain data contributions within RLHF."}
{"id": "5WEpbilssv", "Context": "High-content perturbation experiments probe biomolecular systems at high resolution but are costly to run and analyze. While machine learning could guide exploration and insight extraction, prevailing methods neglect the semantic richness of biology and optimize objectives misaligned with downstream biological analyses. Existing evaluations emphasize static knowledge rather than open reasoning challenges in perturbation modeling: predicting differential expression and change of direction for unseen perturbations, and gene set enrichment.", "Idea": "We introduce PerturbQA, a benchmark for structured reasoning over perturbation experiments that targets tasks such as predicting differential expression and change of direction for unseen perturbations and performing gene set enrichment. We also present Summer, a simple, domain-informed LLM framework that summarizes context, retrieves relevant knowledge, and answers queries in this setting."}
{"id": "9OfKxKoYNw", "Context": "Text-guided diffusion models enable realistic image edits from simple prompts, raising concerns about misuse for misleading or harmful content. Existing defenses that add imperceptible adversarial noise often fail against sophisticated manipulations such as mask-based editing, highlighting the need for stronger protection against unauthorized edits.", "Idea": "DiffusionGuard generates adversarial noise using a novel objective that targets the early stage of the diffusion process to more effectively disrupt editing. It further applies a mask-augmentation technique to improve robustness across diverse edit masks and setups."}
{"id": "oZkqkkvdND", "Context": "Variational Autoencoders are increasingly deployed in safety-critical applications where adversarial attacks pose risks. These settings require certified probabilistic guarantees on performance under input perturbations, yet providing such guarantees for generative models like VAEs remains challenging.", "Idea": "CIVET is a method for certified training of VAEs that derives worst-case error bounds by constraining errors on carefully chosen support sets at the latent layer. It provides a training algorithm that applies this principle during learning."}
{"id": "Pujt3ADZgI", "Context": "Reinforcement Learning with Human Feedback (RLHF) aligns large language models with human preferences, but prevalent reward-based approaches follow the Bradley-Terry (BT) model assumption, which may not capture complex preferences. These methods often require estimating expected win rates for individual responses, incurring high computational or annotation costs.", "Idea": "Reframe RLHF under a general preference framework from a game-theoretic perspective by modeling it as a two-player game and proposing an online algorithm, iterative Nash policy optimization (INPO). INPO has the policy play against itself via no-regret learning to approximate a Nash policy and replaces per-response win-rate estimation with a loss directly minimized over the preference dataset."}
{"id": "9HK2rHNAhd", "Context": "Optimizing the key-value (KV) cache is critical for reducing the memory footprint and cost of LLM inference. Existing KV-cache compression methods mainly sparsify token sequences based on token importance but typically allocate equal KV budgets across layers, overlooking that layers differ in sensitivity to input tokens.", "Idea": "Introduce a layer-aware KV-cache compression framework that jointly optimizes layer-wise and sequence-wise dimensions. During inference, estimate each attention layer’s importance by computing cosine similarity between representations immediately before and after its self-attention, then group layers and allocate KV budgets on the fly. With these tailored per-layer budgets, apply sequence-wise compression within each layer to compress the KV cache."}
{"id": "Mfnh1Sqdwf", "Context": "Predicting gene expression from DNA sequences is challenging because the regulatory elements that control expression are difficult to identify. A central problem is determining which elements are active and disentangling their regulatory effects from non-informative patterns in epigenomic signals.", "Idea": "Seq2Exp is a Sequence to Expression network that discovers and extracts active regulatory elements driving target gene expression. It captures causal relationships among DNA sequences, epigenomic signals, and regulatory elements by conditioning on active elements, decomposing sequence and signal accordingly, and applying an information bottleneck with a Beta distribution to fuse their effects while filtering non-causal components."}
{"id": "pbre0HKsfE", "Context": "Large language models provide personalized responses based on user interactions, raising serious privacy concerns. Homomorphic encryption enables computation over encrypted data, but the computational intensity of transformers makes applying HE to LLMs challenging, especially for inference after personalized (private) fine-tuning.", "Idea": "Introduce an HE-friendly transformer architecture designed for encrypted inference following personalized (private) fine-tuning. The method integrates LoRA-based fine-tuning with Gaussian kernels to lower computational cost and arithmetic depth under homomorphic encryption."}
{"id": "WeJEidTzff", "Context": "Commuting origin–destination (OD) flows characterize where people live and work, informing urban planning and transportation. Because direct data collection is costly, researchers infer OD flows from readily available urban attributes. However, prior studies rely on disparate datasets and evaluation metrics, preventing fair comparison and a unified standard.", "Idea": "Introduce a unified benchmark for commuting OD flow generation that standardizes evaluation protocols and metrics. This framework enables consistent, comparable assessment across methods."}
{"id": "kiOxNsrpQy", "Context": "Graph Neural Networks are increasingly deployed in practice, creating a need for tools that can explain their predictions. Faithfulness—accurately reflecting the model’s reasoning—is central, yet multiple competing metrics exist and the field lacks a clear understanding of what faithfulness means and how to achieve it.", "Idea": "We provide a theoretical analysis that compares faithfulness metrics for GNN explanations, clarifying their assumptions and the properties they capture. We characterize how architectural choices (injective regular vs. modular, including self-explainable and domain-invariant designs) determine when faithful explanations are informative, and formalize the link between faithfulness, domain-invariant subgraphs, and out-of-distribution generalization."}
{"id": "Kpjvm2mB0K", "Context": "Study one-pass streaming for underdetermined ℓp linear regression of the form min ||x||p subject to Ax=b with A ∈ R^{n×d}, n ≪ d, in the column-arrival model. When A is a graph incidence matrix, this corresponds to edge-insertion streams and captures ℓp flows, including transshipment (p=1), electrical flows (p=2), and max flow (p=∞). The goals are to estimate the regression cost or to output an approximate solution using space much smaller than the stream length d.", "Idea": "Design streaming algorithms that compress the instance into a sparse subset of columns that approximately preserves the ℓp objective, yielding ℓp flow sparsifiers in graphs. Develop space-efficient solution-recovery schemes that maintain compact summaries with adjustable approximation–space trade-offs for p>1, and a coarse-approximation approach for p=1."}
{"id": "eENHKMTOfW", "Context": "Large language models have magnified resource disparities: well-resourced industrial labs can fine-tune models effectively, while individual developers and small organizations lack the compute, expertise, and infrastructure to explore the extensive fine-tuning configuration space.", "Idea": "Present a comprehensive, openly documented study of supervised fine-tuning for small LLMs (3B–7B). Systematically vary and document training configurations and strategies—such as batch size, learning rate, warmup steps, learning rate schedules, and phased versus stacked training—across several open-source pre-trained models, with all code and configurations released."}
{"id": "TEkoMEjf7E", "Context": "Despite recent progress, generative 3D modeling remains ill-posed, limiting quality, controllability, and generalization.", "Idea": "Phidias is a diffusion-based framework for reference-augmented 3D generation that, given an input image, uses a retrieved or user-provided 3D model to guide generation. It incorporates a meta-ControlNet to dynamically modulate conditioning strength, dynamic reference routing to mitigate misalignment between the input image and the 3D reference, and self-reference augmentations for self-supervised training with a progressive curriculum. The framework supports text, image, and 3D conditioning."}
{"id": "EV7FMBZxnx", "Context": "Concealed object detection, such as identifying in vivo lesions or camouflage, often requires specialized imaging systems. Lensless cameras offer a compact, flexible alternative, but their measurements lack visual semantics, making detection challenging. The area also lacks a dedicated benchmark for lensless concealed object detection.", "Idea": "Propose a Region Gaze-Amplification Network (RGANet) that progressively exploits concealed objects directly from lensless imaging measurements. It integrates a Region Gaze Module (RGM) to mine spatial-frequency cues informed by biological and psychological mechanisms and a Region Amplifier (RA) to amplify details within object regions."}
{"id": "21rSeWJHPF", "Context": "Ranking vertices in graphs is fundamental, but when graphs have community structure, traditional algorithms—including unsupervised rankings based on centrality measures like PageRank—often produce unbalanced rankings that overrepresent some communities, leading to loss of information, polarized opinions, and reduced diversity.", "Idea": "Relative centrality is an unsupervised ranking approach that iteratively applies graph-dependent local normalization to centrality scores to promote balancedness while maintaining ranking validity. The paper also proposes a multi-core-periphery with communities (MCPC) structure to characterize and analyze when standard centrality measures become unbalanced."}
{"id": "l0gZS0sAlf", "Context": "Training and fine-tuning large language models on heterogeneous, multi-source text can induce conflicting gradient directions that hinder optimization and specialization, undermining generalization across tasks and reducing downstream performance. Prior work suggests that fine-tuning on carefully selected, task-specific subsets can match or surpass using the full dataset.", "Idea": "ELREA clusters training instructions by gradient direction to delineate areas of expertise and mitigate optimization conflicts. It trains a LoRA-based expert adapter for each cluster and, at inference, combines predictions from the most relevant experts based on the input’s gradient similarity to the clusters."}
{"id": "mFY0tPDWK8", "Context": "Machine learning is used to predict initial solutions for mixed-integer linear programming (MILP) by fixing a subset of variables and solving the reduced problem. However, inaccurate predictions can degrade solution quality or make the reduced problem infeasible, creating the challenge of reliably identifying which predicted variable values are safe to fix.", "Idea": "We propose an alternating prediction–correction neural solving framework (Apollo-MILP) that iteratively predicts values for unfixed variables and applies a trust-region search to obtain a corrected reference solution. By combining the predicted and reference solutions, it computes an Uncertainty-based Error upper BOund (UEBO) to assess per-variable confidence and fixes only those with high confidence in subsequent iterations."}
{"id": "mYgoNEsUDi", "Context": "Diffusion models have become prominent for generative AI on graphs, with applications from drug design to knowledge discovery. However, existing graph diffusion models struggle to holistically capture intrinsic higher-order topological properties across resolutions, limiting their generalizability and usefulness for downstream tasks.", "Idea": "Leverage zigzag persistence to extract latent topological descriptors at multiple resolutions. Introduce a computationally efficient topological summary, zigzag spaghetti (ZS), that captures dynamic higher-order structure over sequences of graphs with stability guarantees, and integrate these summaries into graph diffusion models."}
{"id": "LBl7Hez0fF", "Context": "Hallucination hampers the deployment of large vision-language models; unlike in LLMs, it often stems from misalignment between visual inputs and textual outputs and from text decoders’ sensitivity to vision inputs caused by separately pre-trained image encoders and text decoders.", "Idea": "Visual and Textual Intervention (VTI) is a task-agnostic, test-time technique that steers latent representations during inference to stabilize vision features. It jointly adjusts visual and textual latent spaces to moderate the text decoder’s sensitivity to visual inputs."}
{"id": "dQ2xiSIYzp", "Context": "Reconstructing detailed 3D human appearance and geometry from a single image is challenging, especially for unobserved regions. Single-view settings risk implausible poses and shapes, and approaches often rely on body priors whose initial estimates can be inaccurate.", "Idea": "Introduce a single-view generalizable Human Gaussian Model (HGM) with a generate-then-refine pipeline guided by a human body prior and a diffusion prior. It renders a back view from coarse human Gaussians, refines it with a ControlNet, then reconstructs refined human Gaussians from the refined view and the input image. A SMPL-X-based dual branch propagates image features from the SMPL-X volume to the image Gaussians via sparse convolutions and attention, while gradually refining the SMPL-X estimate."}
{"id": "uHLgDEgiS5", "Context": "Traditional data influence estimation methods, such as influence functions, assume permutation-invariant training. Modern foundation-model training with stochastic, non-convergent, multi-stage curricula is order-sensitive, breaking this assumption and leaving unresolved how to attribute an example’s influence at different training stages and how to capture dependence on the optimization trajectory.", "Idea": "Formalize trajectory-specific leave-one-out (LOO) influence to measure the effect of removing a data point at a particular training iteration while conditioning on the exact data order and optimization path. Propose data value embedding, a per-example training embedding that aggregates interactions with the evolving model parameters, enabling approximation of trajectory-specific LOO via a dot product with the gradient of the given test data."}
{"id": "lPJUQsSIxm", "Context": "Fully homomorphic encryption enables private machine learning inference on encrypted data, preserving data and model confidentiality. However, FHE-based deep neural networks suffer from high computational cost, latency, and limited scalability, hindering practical deployment.", "Idea": "DCT-CryptoNets performs neural network computation directly in the frequency domain using the discrete cosine transform. By operating on DCT coefficients and focusing on perceptually salient low-frequency information, it reduces costly non-linear activations and homomorphic bootstrap operations. The design aligns with JPEG-encoded image storage and transmission common in remote services."}
{"id": "rfdblE10qm", "Context": "In LLM alignment, reward models are often learned from pairwise preference annotations, with the Bradley–Terry model widely used to map comparisons into scalar rewards. Yet its suitability in this setting lacks clear theoretical justification, especially when only a limited and sparsely connected set of prompt–response comparisons is available.", "Idea": "We establish convergence rates for Bradley–Terry reward models parameterized by embedding-based neural networks and identify order consistency as the key requirement for reward modeling, showing that BT satisfies it. We then introduce a simple upper-bound objective, compatible with off-the-shelf binary classifiers, as an alternative order-consistent reward modeling approach."}
{"id": "W2Wkp9MQsF", "Context": "Large-scale neural networks are costly to store and deploy, especially in resource-constrained environments. Many compression techniques require access to training data or fine-tuning, and data-free methods can distort internal statistics, causing variance collapse or explosion.", "Idea": "Model folding is a data-free compression technique that merges structurally similar neurons across layers to reduce model size without requiring training data or fine-tuning. It preserves data statistics via k-means clustering and uses novel data-free mechanisms to prevent variance collapse or explosion."}
{"id": "sLKDbuyq99", "Context": "LLM-based multi-agent systems can plan and execute complex tasks, but existing methods provide limited support for adapting workflows during execution. In real-world settings, plans must adjust in real time to unforeseen challenges and changing conditions.", "Idea": "Model the workflow as an activity-on-vertex (AOV) graph that LLM agents refine in real time through dynamic subtask reallocation based on historical performance and prior AOVs. Design modular workflows by evaluating parallelism and dependency complexity to structure subtasks and coordinate concurrency."}
{"id": "9OJflnNu6C", "Context": "Generative models raise privacy and bias concerns, motivating removal of specific training data from trained models. In Image-to-Image (I2I) generative models, most existing unlearning approaches are single-objective and yield a single solution, overlooking diverse user preferences for the trade-off between complete unlearning and model utility.", "Idea": "Propose a controllable unlearning framework that uses a control coefficient ε to tune the trade-off between unlearning and utility. Reformulate I2I unlearning as an ε-constrained optimization problem and solve it with a gradient-based method to locate unlearning boundaries. These boundaries define the valid ε range, within which all solutions are Pareto-optimal."}
{"id": "zjeHLSiNv1", "Context": "Transformer performance scales logarithmically with parameters and computational complexity. Techniques like Mixture of Experts (MoE) decouple parameter count from computation but incur high memory-access costs at inference, creating latency bottlenecks.", "Idea": "UltraMem augments Transformers with a large-scale, ultra-sparse memory layer. The memory is accessed sparsely and selectively to mitigate inference-time memory-access bottlenecks and latency."}
{"id": "hgwGi81ndj", "Context": "Exploration in reinforcement learning is challenging because predicting specific future states from low-level pixel observations and primitive actions is difficult, complicating planning over long horizons.", "Idea": "We propose a fully model-based algorithm that builds a hierarchical, object-centric abstraction in which items and their attributes define high-level states, and attribute changes operate at a higher temporal abstraction than primitive actions. The resulting discriminative world model simplifies transition dynamics. Using this abstract model, the agent plans exploration with count-based intrinsic reward, plans to reach discovered abstract states, learns low-level object-perturbing policies via reinforcement learning, and learns the object mapping via supervised learning."}
{"id": "CI4sCBMXjP", "Context": "Enhancing the adaptive capabilities of large language models is important, but current adaptation strategies are constrained. Traditional fine-tuning demands substantial data, computational resources, and specific capabilities, while in-context learning depends on suitable demonstrations and is limited by token budgets.", "Idea": "ELICIT is a two-module framework that externally stores task vectors capturing in-context learned capabilities and reuses them to adapt models to new tasks without additional training or inference tokens. One module manages storage and retrieval of task vectors, and the other applies retrieved vectors to condition the model."}
{"id": "hJVdwBpWjt", "Context": "Large language models prompted with text and audio have achieved state-of-the-art performance across speech, music, and general audio. Yet bioacoustics applications—detecting animal vocalizations in long recordings, classifying rare and endangered species, and labeling context and behavior—remain underexplored despite their importance for conservation, biodiversity monitoring, and animal behavior studies. Progress is further constrained by limited annotated data.", "Idea": "Introduce NatureLM-audio, an audio-language foundation model tailored for bioacoustics. It is trained on carefully curated text–audio pairs spanning bioacoustics, speech, and music to leverage cross-domain representations under scarce annotations."}
{"id": "4GSOESJrk6", "Context": "Personalized image generation shows promise for everyday work and life, but evaluation is difficult: automated metrics often misalign with human judgment, whereas human evaluations are slow and expensive.", "Idea": "DreamBench++ is a human-aligned evaluation benchmark automated by advanced multimodal GPT models. It uses systematically designed prompts with task reinforcement to make GPT both human- and self-aligned, and includes a comprehensive dataset of diverse images and prompts."}
{"id": "PkpNRmBZ32", "Context": "State-space models are widely used for sequence and raw audio processing, but many implementations rely on rigid depthwise-separable blocks that limit architectural flexibility. There is a need to expand the SSM design space while preserving memory and compute efficiency during training and inference, and to reduce reliance on recurrent units, explicit convolutions, or attention mechanisms.", "Idea": "Propose Centaurus, a network family built from generalized SSM blocks whose operations are cast as tensor contractions during training, allowing systematic selection of contraction order for training efficiency. The design extends beyond depthwise-separable SSMs by incorporating SSM analogs of group, full, and bottleneck convolutional blocks, and mixes these heterogeneous blocks to balance model size with training and inference efficiency in a fully state-space architecture that avoids LSTMs, explicit convolutions, and attention."}
{"id": "t8fu5m8R5m", "Context": "Robust anomaly detection under adversarial attacks remains challenging, undermining reliability in safety-critical applications. The difficulty stems from the AD setting where training uses only unlabeled normal samples, leaving detectors vulnerable to adversarial anomalies at test time. Without labels, adversarial training lacks a clear objective; ideally it should induce strong intra- and inter-group perturbations to maximize the margin between normal and anomalous distributions.", "Idea": "Create a pseudo-anomaly group derived from normal samples and adopt adversarial training with a contrastive loss that induces both inter- and intra-group perturbations. To address spurious negative pairs that misguide contrastive learning, define opposite pairs and adversarially pull them apart to strengthen inter-group perturbations."}
{"id": "fGhr39bqZa", "Context": "Causal discovery with latent variables is challenging. Many existing methods assume the presence of pure children—observed variables with strictly restricted parents—to identify latent variables and their causal relations, but this assumption is often unrealistic and limits applicability.", "Idea": "Introduce the concept of a homologous surrogate to eliminate the pure-child requirement in latent-variable causal discovery. Formulate two assumptions involving such surrogates and develop theory showing that, under a weaker assumption, each variable's ancestors can be determined and, under a stronger one, each variable's parents can be identified exactly. Build an algorithm that leverages these properties for causal graph recovery."}
{"id": "4ua4wyAQLm", "Context": "Video anomaly detection aims to identify novel actions or events unseen during training. Mainstream methods emphasize global patterns with redundant details and struggle to generalize to unseen samples.", "Idea": "We propose a framework that focuses on local patterns and their dynamics. It extracts spatial local, semantically relevant components via a two-stage image–text alignment and cross-modality attention, and introduces a State Machine Module (SMM) that uses earlier high-resolution textual tokens to guide caption generation for subsequent low-resolution observations. Temporal motion estimation complements the spatial local patterns to handle novel spatial distributions and distinctive dynamics."}
{"id": "xPxHQHDH2u", "Context": "Despite significant progress in novel view synthesis using NeRF- and 3DGS-based methods, reconstructing reflective objects remains challenging, with no solution that achieves real-time, high-quality rendering while accommodating inter-reflection.", "Idea": "We propose Reflective Gaussian splatting (Ref-Gaussian) with two components: (i) physically based deferred rendering that empowers the rendering equation with pixel-level material properties via a split-sum approximation, and (ii) Gaussian-grounded inter-reflection within the Gaussian splatting paradigm. The framework further improves geometry through material-aware normal propagation, an initial per-Gaussian shading stage, and 2D Gaussian primitives."}
{"id": "i3e92uSZCp", "Context": "Skill discovery methods enable agents to acquire diverse behaviors without explicit rewards, but downstream usefulness depends on achieving semantic diversity among learned skills. Prior work either enforces distinguishability via discriminators or increases state coverage, yet directly pursuing semantic diversity remains underexplored.", "Idea": "Language Guided Skill Discovery (LGSD) is a framework that leverages large language models to directly maximize semantic diversity between skills. It takes user prompts to constrain exploration to a desired semantic subspace and uses LLM-generated guidance to drive the agent toward semantically distinctive skills within that subspace."}
{"id": "ws5phQki00", "Context": "Stance detection can support moderation, summarization, and balanced discussion in online political forums, but typical transformer-based models require large labeled datasets. The breadth of debate topics hinders data collection, and while LLMs have revived the field, their online deployment is limited by inconsistent outputs, biases, and vulnerability to adversarial inputs.", "Idea": "Adopt an offline pipeline that prompts an LLM to generate synthetic stance data tailored to specific debate questions and fine-tunes a traditional stance detection model on this corpus. Use the synthetic set as a reference to identify the most informative unlabeled examples via model uncertainty, then further fine-tune using both synthetic data and selectively labeled real samples."}
{"id": "t8KLjiFNwn", "Context": "Transformer architectures capture long-range dependencies and global context, while State Space Models (SSMs) are strong contenders that use a selective mechanism for dynamic parameter adjustment. However, this mechanism increases computational complexity and bandwidth demands, hindering deployment on resource-constrained mobile devices.", "Idea": "We propose a sparse learning framework that integrates architecture-aware compiler optimizations with a C_4^n kernel sparsity scheme—pruning n elements from every four contiguous weights—and a compiler-based acceleration pipeline for mobile devices. The framework produces optimized sparse models for specified sparsity or latency targets, leverages pruned weights to compensate remaining weights, and applies C_4^n-specific optimizations with layout transformation elimination to mitigate inefficiencies from fine-grained pruning in linear layers and related operations."}
{"id": "Bp0HBaMNRl", "Context": "Discovering causal structures with latent variables from observational data is challenging. Existing methods commonly rely on constraint-based, iterative discrete searches that do not scale to many variables and often assume linearity or invertibility, limiting applicability in real-world settings.", "Idea": "Present identifiability results for non-linear latent hierarchical causal models that relax assumptions about deterministic latent variables and exogenous noise. Building on these results, develop a differentiable causal discovery algorithm to estimate the structure of such models."}
{"id": "2IoFFexvuw", "Context": "Reinforcement learning has successfully fine-tuned diffusion-based generative models, but fine-tuning continuous flow-based generative models to align with arbitrary user-defined rewards remains challenging due to policy collapse from overoptimization and the high computational cost of likelihoods in continuous-time flows.", "Idea": "ORW-CFM-W2 integrates RL into conditional flow matching to fine-tune generative models with arbitrary reward functions, without relying on reward gradients or filtered datasets. It uses online reward weighting to prioritize high-reward regions and adds Wasserstein-2 regularization, via a tractable upper bound within flow matching, to prevent collapse and balance exploration and exploitation."}
{"id": "izjNI5bcOV", "Context": "Weather data spans multiple modalities and supports diverse understanding tasks. Existing data-driven models are typically built for a single task (e.g., forecasting) and trained on limited real observations within a single scenario, which restricts performance and prevents a unified solution across tasks.", "Idea": "WeatherGFM is a generalist weather foundation model that unifies diverse weather understanding tasks by standardizing task representations and definitions. It introduces weather-specific prompt formats for single, multiple, and temporal modalities and trains all tasks via a visual prompting question-answering paradigm."}
{"id": "5IWJBStfU7", "Context": "As AI systems are deployed in high-stakes settings, interpretability is crucial. Mechanistic Interpretability seeks to reverse-engineer neural networks into human-understandable algorithms, raising a foundational question: for a fixed behavior and given criteria, does a unique explanation exist?", "Idea": "Formalize identifiability for mechanistic interpretability, treating explanation uniqueness as a property defined by explicit criteria. Characterize two approaches—where-then-what (locate a behavior-replicating circuit, then interpret it) and what-then-where (specify candidate algorithms and search activation subspaces for causally aligned implementations)—and discuss stricter unicity criteria and multi-criterion validation within the inner interpretability framework."}
{"id": "z8PcUSKXXN", "Context": "Generalizable deep image denoising has advanced with methods like Masked Training (MT), which trains a masked SwinIR solely on Gaussian noise (sigma=15) yet can handle multiple noise types. However, MT often produces over-smoothed images and requires careful mask-ratio tuning, hindering integration with other approaches. There is a need for simpler, more efficient models that remain robust to diverse and unseen noise.", "Idea": "RNINet is a streamlined encoder-decoder architecture first trained on individual noise types to characterize shifts in feature statistics (mean and variance) across noise conditions. It then integrates a noise injection block that randomly perturbs these statistics to enhance generalization to unseen noise types."}
{"id": "yitH9xAHQs", "Context": "Large language models benefit from diverse, high-quality task-specific data, but data synthesis often relies on human annotations or predefined templates, which can constrain coverage and miss critical edge cases or novel scenarios.", "Idea": "ReverseGen is an automatic data generation approach that trains a dedicated proposer to produce queries that elicit unsatisfactory responses from a target model. These failure-inducing queries are converted into training samples to directly address the model’s weaknesses."}
{"id": "PUnD86UEK5", "Context": "Adam often outperforms SGD in training language models, yet the theoretical reason is unclear. Existing non-convex convergence analyses for both mainly index progress by the number of steps T and achieve the same minimax-optimal rate ~T^{-1/4}, which does not explain Adam’s empirical edge.", "Idea": "Develop a convergence analysis for Adam under ℓ∞-smoothness assumptions, leveraging ℓ∞ rather than the conventional ℓ2 geometry. Extend the analysis to blockwise Adam using corresponding blockwise smoothness assumptions."}
{"id": "pPQPQ7Yd58", "Context": "In image-based control pipelines learned from behavior cloning, the visual representation space serves as the information channel from the vision encoder to the action decoder. Inspired by neural collapse in image classification, this space exhibits a law of clustering: in discrete control, features cluster by action labels; in continuous control, they cluster into control-oriented classes defined by relative pose orthants (REPO) based on object–target relationships or expert-induced object poses.", "Idea": "Pretrain the vision encoder with a neural-collapse-based regularization that encourages control-oriented clustering in the visual features. After this pretraining, finetune the encoder and action decoder end-to-end."}
{"id": "6qUUgw9bAZ", "Context": "Decoding procedures such as search, reranking, and self-critique can improve language model outputs in code, mathematics, and dialog, but they are computationally intensive. Input difficulty varies, yet a single fixed decoding procedure is typically applied to all inputs, wasting compute.", "Idea": "A computation-allocation framework that predicts, for each input and computation budget, the distribution of rewards and allocates additional decoding computation to inputs where it is predicted to be most useful. It is instantiated as (1) an adaptive best-of-k procedure that dynamically chooses how many samples to generate for reranking, and (2) a routing procedure that selects between an expensive but accurate decoding procedure and a cheaper, less capable one per query."}
{"id": "hXm0Wu2U9K", "Context": "Language model alignment methods such as RLHF optimize against an offline reward model but often suffer from overoptimization: continued training degrades response quality by overfitting reward-model inaccuracies and shifting away from preferred responses. KL-regularization is widely used to limit this distribution shift, yet is often too weak, motivating an efficient offline alignment approach that is robust to overoptimization.", "Idea": "Introduce χ^2-Preference Optimization (χPO), a minimal modification of Direct Preference Optimization (DPO) that replaces the logarithmic link function in the objective. This change induces χ^2-divergence regularization that implements pessimism in the face of uncertainty, providing a principled alternative to KL-based regularization for offline alignment."}
{"id": "d8hYXbxX71", "Context": "Improving social welfare requires optimizing objectives across multiple time horizons: policies that seem suboptimal in the short term may yield long-term gains. Policymakers often contrast Rawlsian policies, which prioritize the most disadvantaged, with utilitarian policies, which maximize average welfare, and these goals are commonly viewed as in tension. The core challenge is to assess these trade-offs when welfare evolves over time.", "Idea": "Develop a sequential decision-making model in which individuals' welfare stochastically decays over time and policymakers can intervene to prevent this decay. Within this framework, formally compare Rawlsian and utilitarian decision rules across horizons, and characterize the conditions that determine when each policy is favored."}
{"id": "G0dksFayVq", "Context": "LLM-based judges are increasingly used to assess and compare models, yet their reliability is rarely scrutinized. As models become more sophisticated, existing judge benchmarks overemphasize alignment with crowdsourced preferences and underrepresent tasks where such preferences are poor proxies for factual or logical correctness.", "Idea": "Propose an objective evaluation framework for LLM-based judges, instantiated as JudgeBench, a benchmark of challenging response pairs across knowledge, reasoning, math, and coding. Build these pairs via a pipeline that converts difficult datasets into paired responses with preference labels tied to objective correctness."}
{"id": "vJkktqyU8B", "Context": "Vision Transformer adapters often suffer slow inference due to inefficient memory access, particularly from standard normalization and frequent tensor reshaping, with the issue pronounced in dense prediction tasks that rely on local inductive biases.", "Idea": "META is a ViT adapter with a memory-efficient block that shares layer normalization between self-attention and feed-forward layers to reduce reliance on normalization. The block employs cross-shaped self-attention to reduce reshaping and adds a lightweight convolutional branch for local inductive bias, arranged in a cascaded manner to produce diverse head features."}
{"id": "SiH7DwNKZZ", "Context": "Transformers are widely used as generic backbones in computer vision despite originating in natural language processing. Recently, LSTM was extended to the scalable xLSTM with exponential gating and a parallelizable matrix memory that addresses longstanding LSTM limitations.", "Idea": "Introduce Vision-LSTM (ViL), which adapts xLSTM building blocks to computer vision by operating on sequences of image patch tokens. ViL stacks xLSTM blocks with alternating processing directions, where odd blocks traverse tokens from top to bottom and even blocks from bottom to top."}
{"id": "9NfHbWKqMF", "Context": "3D Gaussian Splatting enables high-fidelity, real-time photorealistic reconstruction, but quality deteriorates when test viewpoints deviate from the training camera poses. This out-of-distribution view issue hinders free-viewpoint rendering and navigation, and existing approaches with regularization or learned priors often struggle to generalize.", "Idea": "SplatFormer is a point transformer tailored to operate directly on 3D Gaussian splats. Given an initial 3DGS optimized from limited training views, it refines the splats in a single forward pass to reduce artifacts in out-of-distribution viewpoints."}
{"id": "84WmbzikPP", "Context": "Molecular structure elucidation is crucial across chemistry. We consider predicting a molecule’s all-atom 3D structure given only its molecular formula and rotational moments of inertia, which rotational spectroscopy measures with high precision. Existing conditional generative models enforce these moment constraints only softly, leaving much of that precision unused.", "Idea": "Show that the space of n-atom point clouds with fixed moments of inertia embeds in the Stiefel manifold St(n, 4). Introduce Stiefel Flow Matching, a generative model that operates on this manifold to enforce exact moment constraints. Obtain simpler, shorter flows by approximating equivariant optimal transport on the Stiefel manifold."}
{"id": "9FqARW7dwB", "Context": "Deep neural networks often use residual connections to enable training of very deep models. However, residual connection variants can exhibit a seesaw between vanishing gradients and representation collapse.", "Idea": "Introduce hyper-connections as a simple alternative to residual connections. They allow the network to adjust connection strengths between features at different depths and dynamically rearrange layers."}
{"id": "ho4mNiwr2n", "Context": "Anti-backdoor learning aims to train clean models directly from poisoned datasets. Existing defenses often fail to recover poisoned samples to their correct labels and generalize poorly to large pre-trained models due to non–end-to-end training, limiting protection for such models.", "Idea": "Revisit anti-backdoor learning from a causal perspective and introduce an end-to-end method (MCCI) that trains on both images and attack indicators. Leveraging these signals enables control over whether the model treats an input as clean or backdoored, e.g., by providing fake non-attack indicators."}
{"id": "WwmtcGr4lP", "Context": "Effective cancer treatment is challenging due to highly individualized patient responses arising from heterogeneous genomic mutations. Limited patient response data hinders training personalized treatment models from clinical genomic sequencing. Prior work leverages larger labeled preclinical cell line datasets via transfer learning to learn domain-invariant representations shared between cell line and patient domains, augmenting data in a common space but failing to capture patient-specific characteristics that influence drug response.", "Idea": "GANDALF is a generative, attention-based framework for data augmentation and drug response prediction that directly augments patient genomic profiles while modeling domain-specific characteristics. Rather than relying solely on a shared domain-invariant space, it employs generative modeling with attention to produce patient-specific representations for prediction."}
{"id": "d8cnezVcaW", "Context": "Direct Preference Optimization (DPO) is used in reinforcement learning from human feedback to fine-tune large language models, but it cannot characterize the diversity of human preferences across prompts.", "Idea": "MallowsPO, grounded in Mallows' theory of preference ranking, introduces a dispersion index that models the spread of human preferences for each prompt. This index unifies existing DPO formulations as special cases within a single preference-optimization framework."}
{"id": "MGKDBuyv4p", "Context": "Language models can memorize training data and regurgitate it verbatim, posing privacy risks when the data are sensitive. Mitigating such memorization without degrading utility or incurring high computational cost is challenging.", "Idea": "This work develops memorization-mitigation methods across regularizer-, fine-tuning-, and machine unlearning–based families. It introduces TinyMem, a suite of small, computationally efficient language models for rapid development and evaluation of such methods. It also proposes several new unlearning methods, including BalancedSubnet, to localize and remove memorized information from model weights before inference."}
{"id": "vmulbBDCan", "Context": "Electron-multiplying charge-coupled devices (EMCCDs) enable sensitive low-light imaging in astronomy, material science, and biology, yet residual noise degrades image quality, especially in fluorescence microscopy. Prior studies focus on theoretical noise statistics; physics-based models used to guide deep learning for conventional sensors do not transfer to EMCCDs, and there is a lack of EMCCD-specific practical resources and datasets.", "Idea": "Introduce a systematic calibration procedure for an EMCCD physics-based noise model that estimates the statistical features of observable noise components. Use the calibrated model to generate authentic training samples and to guide a recent neural network for EMCCD denoising."}
{"id": "iXCeQ2m6vT", "Context": "Humans readily understand visual relations, including judging whether previously unseen objects are the same or different, whereas current AI systems struggle. Active vision theories propose that learning such relations is grounded in eye movements, where low-dimensional spatial information supports representing relations between image parts.", "Idea": "We propose a Glimpse-based Active Perception (GAP) model that sequentially selects salient regions of an image to process at high resolution. It leverages the locations of these glimpse actions, together with surrounding visual content, to construct representations of relations between different parts of the image."}
{"id": "FoF5RaA3ug", "Context": "In dataset distillation, soft labels from pre-trained teacher models are beneficial, but models trained on synthetic datasets are highly sensitive to the loss used for soft-label utilization. This sensitivity highlights the need for a universal loss and fuller use of label information, with cross-optimizer generalization remaining underexplored.", "Idea": "We present GIFT, a plug-and-play approach that refines soft labels and applies a cosine similarity-based loss to leverage full label information in dataset distillation. GIFT is designed for seamless integration into existing distillation pipelines."}
{"id": "R4h5PXzUuU", "Context": "Foundation models trained on internet-scale multimodal data are widely adopted, yet their trustworthiness remains underexplored. In particular, the out-of-distribution detection capabilities of large vision-language models (LVLMs) and how they convey confidence through natural-language responses are not well understood, raising safety and reliability concerns.", "Idea": "We propose Reflexive Guidance (ReGuide), a self-guided prompting approach to enhance out-of-distribution detection (OoDD) in large vision-language models. It leverages self-generated, image-adaptive concept suggestions to refine the prompt and steer recognition."}
{"id": "gU4ZgQNsOC", "Context": "Pretraining large language models uses vast, heterogeneous corpora, yet standard pipelines weight all samples uniformly, overlooking how informative individual examples are as training progresses. Existing reweighting focuses on coarse group-level importance and lacks fine-grained, adaptive control at the instance level.", "Idea": "Propose dynamic, instance-level, loss-based reweighting that updates each example’s weight online according to its current loss, steering training toward informative samples at each stage. The framework systematically designs strategies that deprioritize redundant or uninformative data and provides theory characterizing how loss-based reweighting affects the convergence of gradient-based optimization."}
{"id": "f7KxfUrRSb", "Context": "Aligning language models with human preferences is important for meeting diverse user needs. Weak-to-strong generalization shows that strong models can learn from labels generated by weaker models; extending this paradigm to alignment raises the challenge of how to leverage a weak model’s alignment behavior for stronger models.", "Idea": "We propose Weak-to-Strong Preference Optimization (WSPO), which transfers alignment behavior from a weaker model to a stronger one. WSPO learns the distribution differences between the weak model’s pre- and post-alignment outputs and applies this learned transformation to align the stronger model."}
{"id": "oU3tpaR8fm", "Context": "Retrieval-augmented generation enables large language models to use external knowledge, and longer context windows encourage retrieving more passages under the assumption that higher recall improves outputs. However, for many long-context LLMs, quality initially improves but then declines as the number of retrieved passages grows, with retrieved hard negatives contributing to this degradation.", "Idea": "To mitigate this, we propose methods that make long-context RAG robust to hard negatives: a training-free retrieval reordering strategy and training-based approaches. The training-based methods include RAG-specific implicit LLM fine-tuning and RAG-oriented fine-tuning with intermediate reasoning."}
{"id": "iylpeTI0Ql", "Context": "Test-time adaptation handles distribution shifts using only target data, but in open-world settings the target stream contains noisy out-of-distribution samples outside the in-distribution label space. In Zero-Shot Noisy TTA (ZS-NTTA) with pre-trained vision-language models, existing TTA methods suffer severe degradation because the negative influence of unfiltered noisy data outweighs clean data during updates, and adapting a single classifier to perform both in-distribution classification and noise detection impairs both.", "Idea": "Propose ZS-NTTA with a decoupled design that freezes the classifier/backbone and learns a separate noise detector. Introduce an Adaptive Noise Detector (AdaND) trained with pseudo-labels from the frozen model to identify noisy samples, and inject Gaussian noise during adaptation to reduce false positives on clean data."}
{"id": "4rEI2JdHH6", "Context": "Grokking is a phenomenon where neural networks memorize training data for an extended period before abruptly achieving near-perfect generalization, undermining predictability and training efficiency. Ideally, models should generalize directly without delay.", "Idea": "GrokTransfer leverages the observation that data embedding influences whether generalization is delayed. It first trains a smaller, weaker model to attain nontrivial (but far from optimal) test performance, extracts its learned input embedding, and uses it to initialize the input embedding of a target, stronger model."}
{"id": "vQhn4wrQ6j", "Context": "Fine-tuning large language models for specialized tasks in non-English languages is difficult due to scarce task-specific data. This is particularly acute for mathematical reasoning, where in-language supervision is often unavailable, hindering cross-lingual transfer.", "Idea": "Start from a shared pretrained model and fine-tune two experts: one on English math instruction data and another on generic instruction data in the target language. Merge them by replacing the top and bottom transformer layers of the math expert with the corresponding layers from the language expert to compose language ability with mathematical reasoning without additional training."}
{"id": "uREg3OHjLL", "Context": "Depth-dependent expressiveness of ReLU networks is studied via the function F_n = max(0, x1, ..., xn). A conjecture asserts that any network exactly representing F_n requires at least ceil(log2(n+1)) hidden layers, confirmed so far only for integer-weight networks. How this depth requirement extends to networks with rational weights remains open.", "Idea": "Establish depth lower bounds for representing F_n in ReLU networks whose weights are decimal or, more generally, N-ary fractions by linking the radix of allowed weight fractions to the minimal depth. Specifically, prove that decimal-fraction weights require at least ceil(log3(n+1)) hidden layers, and N-ary fractional weights require at least Omega(ln n / ln ln N) layers."}
{"id": "vr1QdCNJmN", "Context": "Bregman divergence, generated from a convex function, is widely used as a pseudo-distance in continuous spaces. Defining an analog on discrete domains is nontrivial; prior work modeled it using submodular functions as discrete counterparts of convexity. Many tasks, such as clustering and set retrieval, need structure-preserving distance measures on discrete data.", "Idea": "Generalize discrete Bregman divergences by allowing generating functions that are neither submodular nor supermodular, via a difference-of-submodular decomposition, yielding the difference-of-submodular Bregman divergence. Also introduce a learnable version parameterized by permutation-invariant neural networks to adapt the divergence to data."}
{"id": "2e4ECh0ikn", "Context": "Audio foundation models offer new capabilities for conversational modeling, but there has been little comprehensive evaluation of how naturally and interactively they converse. Effective conversations require fluent turn management—speaking at appropriate times without overlap or prolonged silence—motivating evaluation of whether such models can understand, predict, and perform turn-taking events.", "Idea": "Propose an evaluation protocol for spoken dialog systems' turn-taking that uses a supervised model trained on human-human conversations to predict turn-taking events and serve as a judge. Provide an open-source evaluation platform implementing this protocol to assess audio foundation models' ability to manage conversational turns."}
{"id": "QG31By6S6w", "Context": "Recent advancements in medical vision-language pre-training have improved zero-shot disease recognition at the image level. However, transferring this knowledge to pixel-level tasks such as lesion segmentation in 3D CT scans is challenging due to the complexity and variability of pathological visual characteristics, and existing methods struggle to align fine-grained, unseen lesion features with disease-related textual representations.", "Idea": "Malenia is a multi-scale lesion-level mask-attribute alignment framework for 3D zero-shot lesion segmentation that improves compatibility between mask representations and their associated elemental attributes, explicitly linking visual features of unseen lesions with extensible knowledge learned from previously seen ones. It also includes a Cross-Modal Knowledge Injection module that enhances both visual and textual features with mutually beneficial information to guide segmentation."}
{"id": "X9OfMNNepI", "Context": "Scientific discovery drives societal progress, and recent work suggests large language models could catalyze it. However, it remains unclear whether they can automatically discover novel, valid chemistry hypotheses from a research question.", "Idea": "An LLM-based multi-agent framework grounded in the assumption that many chemistry hypotheses arise from a background question and several inspirations. It proceeds in three stages: retrieving relevant inspirations, generating candidate hypotheses using the background and inspirations, and evaluating and ranking the candidates."}
{"id": "keu6sxrPWn", "Context": "As large language models (LLMs) grow more capable, their trustworthiness is uncertain due to subversive misalignment that can introduce subtle, safety-bypassing errors. Individually minor mistakes can accumulate across long task sequences, increasing the chance of safety failures and forcing deployments to trade off safety against utility with untrusted models. This setting motivates Diffuse Risk Management: balancing average-case safety and usefulness over many tasks.", "Idea": "Introduce a two-level framework for deploying untrusted models. At the single-task level, micro-protocols use a less capable but trusted model to harness and monitor the untrusted model; at the whole-scenario level, a macro-protocol adaptively estimates the untrusted model’s risk and selects among micro-protocols over time."}
{"id": "2ZK8zyIt7o", "Context": "Text-to-image diffusion models have advanced rapidly, but aligning images with long, detailed prompts remains difficult. Common encoders such as CLIP are constrained by maximum input length and degrade on lengthy inputs, and CLIP-based preference fine-tuning often overfits during alignment.", "Idea": "LongAlign combines segment-level encoding—splitting long prompts into separately processed segments to overcome encoder length limits—with decomposed preference optimization. It decomposes CLIP-based preference scores into text-relevant and text-irrelevant components and reweights them during fine-tuning to reduce overfitting and guide text–image alignment."}
{"id": "RaR3ETzyKp", "Context": "In generative modeling with rectified flow and stable diffusion models, different architectures trained on the same dataset can produce similar outputs for the same input noise, implying sample-specific preferable noises. Visualizing noise–sample pairs in two-dimensional spaces shows that paths connecting preferable noises to samples are better organized with fewer crossings than random pairings; because path intersections are rare in high dimensions, such 2D crossings indicate shorter inter-path distances.", "Idea": "Distance-Aware Noise-Sample Matching (DANSM) increases inter-path distance by matching noises to samples within rectified flow models, using a closed-form computation of inter-path distance to guide the matching. To simplify optimization, it leverages a derived relationship between inter-path distance and path length and optimizes path length as a surrogate objective."}
{"id": "e8qXTxMgPg", "Context": "Dimensionality reduction for s-sparse vectors aims to preserve norms or pairwise distances in ℓp spaces using few dimensions. Prior work largely targets worst-case guarantees; beyond worst-case viewpoints consider average-case guarantees and structured data classes. A folklore birthday-paradox argument shows that a linear map to O(s^2) dimensions can exactly preserve the norms of most vectors in a collection, and known bounds for general sparse data can scale poorly with p and dataset size.", "Idea": "We establish tight average-case lower bounds showing that any oblivious linear or sufficiently smooth embedding—including encoder–decoder schemes—that preserves norms of s-sparse vectors must use dimensions quadratic in s. Building on this, we design a non-linear embedding for collections of non-negative s-sparse vectors that preserves all ℓp pairwise distances and exactly preserves ℓ∞, with dimension depending only on sparsity and logarithmic factors and independent of p."}
{"id": "Wvi8c0tgvt", "Context": "Realistic blur datasets lack diversity in scenes and blur patterns, and collecting broader data is time-consuming due to complex dual-camera setups. Existing augmentation methods typically model motion in 2D (e.g., non-uniform kernels), ignoring the inherently 3D nature of camera and object motion and leading to unrealistic blur.", "Idea": "We propose a 3D-aware blur synthesizer that estimates 3D camera positions over the motion blur interval, generates the corresponding scene images, and aggregates them to synthesize blur. It represents 3D transformation as a 2D image-plane transform plus a projected 3D residual estimated by a neural network, avoiding explicit depth measurements. The synthesizer supports controllable augmentation by adjusting blur magnitude, direction, and scenes."}
{"id": "c4OGMNyzPT", "Context": "Large Vision Language Models (LVLMs) exhibit strong multimodal understanding and reasoning, but prevailing evaluations based on Visual Question Answering and image captioning do not capture their full capabilities. These benchmarks inadequately assess fine-grained visual perception, risk data contamination, and underemphasize multi-turn reasoning.", "Idea": "LVLM-Playground is a game-based evaluation framework for LVLMs in structured environments. It uses a set of games to assess four core tasks—Perceiving, Question Answering, Rule Following, and End-to-End Playing—targeting abilities in visual perception, reasoning, and decision-making."}
{"id": "bc3sUsS6ck", "Context": "Large language models acquire substantial knowledge during pretraining but often require adaptation to new contexts, tasks, or domains. Common approaches—fine-tuning and prompting—incur significant training or inference costs, hindering rapid, scalable adaptation.", "Idea": "GenerativeAdapter augments a frozen pretrained LM with a lightweight adapter generator trained via self-supervised learning. Given test-time context, the generator produces parameter-efficient adapters and encodes them into the model’s parameters with a single forward pass. The generator is general-purpose, allowing one generator to adapt the base model across language processing scenarios."}
{"id": "rpouyo09V0", "Context": "Large language models are widely used for code generation, particularly in multi-turn interactions. However, existing benchmarks fail to capture the diversity and quality of feedback in these settings, limiting evaluation in realistic scenarios.", "Idea": "We present CONVCODEWORLD, a reproducible environment that simulates nine interactive code generation scenarios by systematically combining compilation feedback, execution feedback with varying test coverage, and GPT-4o-generated verbal feedback at different expertise levels. We also provide CONVCODEBENCH, a fast static variant with pre-generated feedback logs that removes the need for dynamic verbal feedback generation."}
{"id": "0mtz0pet1z", "Context": "In medical settings, treatment may be initiated at varying times, such as in preventive interventions like screening and vaccination or in chronic non-fatal conditions like HIV infection before AIDS onset. Traditional causal inference has focused on when to start treatment and how that timing depends on subject characteristics.", "Idea": "We introduce a framework targeting the incremental causal effect of interventions that modify the intensity of time to treatment initialization. We provide identification without the usual positivity assumption and an estimation framework using inverse probability weighting."}
{"id": "u3TL0qxLWf", "Context": "Large language models are costly to run, with inference bottlenecked by memory bandwidth and large parameter footprints, hindering scalable deployment. Reducing runtime and memory traffic without degrading model fidelity is a central challenge for post-training compression.", "Idea": "SeedLM is a post-training, data-free compression method that encodes each weight block via the seed of a pseudo-random generator. During inference, the seed feeds a Linear Feedback Shift Register to produce a random matrix, which is linearly combined with stored compressed coefficients to reconstruct the weight block, trading extra compute for fewer memory accesses."}
{"id": "4O0v4s3IzY", "Context": "There is substantial disagreement about LLMs’ reasoning abilities. Early optimism that scaling alone would yield robust reasoning has been tempered by failures on tasks like multiplication and simple planning. A prevailing view holds that verification is easier than generation, motivating expectations of iterative self-critique, but this assumption may not apply if LLMs operate via approximate retrieval.", "Idea": "Systematically evaluate iterative prompting for reasoning and planning by contrasting self-critique with verification by a sound external reasoner. Examine these setups across Game of 24, Graph Coloring, and STRIPS planning, analyzing whether critique content changes solutions and using ablations to identify necessary components. Additionally, include a streamlined variant that re-prompts candidates through a sound verifier."}
{"id": "P4XmKjXTrM", "Context": "Reproducibility is a persistent challenge in machine learning for healthcare because datasets, model pipelines, and task or cohort definitions are often private, creating barriers to sharing, iteration, and understanding of results on EHR datasets.", "Idea": "Automatic Cohort Extraction System (ACES) is a library for event-stream data that formalizes task and cohort specification and automates cohort extraction. It provides a domain-specific configuration language to define dataset-specific concepts and dataset-agnostic inclusion/exclusion criteria, and a pipeline that extracts patient records meeting those criteria. ACES operates on MEDS or ESGPT formats, or any dataset where task-specific predicates can be expressed as event streams."}
{"id": "SgymXhOEA5", "Context": "Person re-identification models exhibit camera-induced bias. Prior camera-aware methods are largely confined to the training domain, and the bias intensifies under distribution shifts to unseen domains. In unsupervised learning, models tend to overfit to camera labels, and camera-biased pseudo labels further degrade training.", "Idea": "Revisit feature normalization on embedding vectors as a simple test-time postprocessing to reduce camera bias in unseen domains, including factors tied to low-level image properties and body angle. Additionally, propose simple training strategies for unsupervised ReID to mitigate the effect of camera-biased pseudo labels during learning."}
