{"id": "nDvgHIBRxQ", "Context": "Evaluating the mathematical reasoning of large language models remains challenging because current benchmarks mainly emphasize problem solving, which risks overfitting and fails to reflect genuine reasoning ability or real-world user experience. A comprehensive assessment should capture task generalization and robustness across diverse mathematical scenarios.", "Idea": "Introduce MathCheck, a checklist-based evaluation framework that organizes mathematical reasoning into diverse task families and robustness tests to probe generalization and reasoning behavior. The approach includes an automatic checklist generator and instantiations for text-only and multimodal mathematics (MathCheck-GSM and MathCheck-GEO) built as extensions of established datasets."}
{"id": "ZsP3YbYeE9", "Context": "Language-model-based agents commonly solve tasks by iteratively prompting, reflecting on outputs, and updating prompts. Existing approaches suffer from limited exploration of the decision space due to repetitive reflections that generate redundant inputs, and they typically cannot reuse insights from previously solved tasks, operating in isolation for each task.", "Idea": "Introduce DoT (Diversity of Thoughts), a framework that explicitly enforces diverse reflections to reduce redundancy and broaden decision-space exploration. It also adds a task-agnostic memory that stores and retrieves knowledge from prior tasks to inform current problem-solving, and is designed to be modular for integration into existing agent pipelines."}
{"id": "I4e82CIDxv", "Context": "Interpretability work on language models frequently studies circuits built from units like attention heads or neurons. Because these units are often polysemantic and hard to interpret, such circuits can be difficult to analyze and manipulate, limiting detailed mechanistic understanding and their usefulness for downstream tasks.", "Idea": "Introduce methods to discover and apply sparse feature circuits—causally implicated subnetworks defined over human-interpretable, fine-grained features—to explain language model behaviors. Provide an unsupervised, scalable pipeline for automatically finding such circuits, and a procedure (SHIFT) that applies them by ablating human-identified task-irrelevant features during classification."}
{"id": "pHe4P1IVnb", "Context": "As large language models grow more capable, providing strong, detailed human oversight becomes difficult, making alignment rely on weak, noisy, and heterogeneous supervision. There is a need for methods that can train powerful models under such limited guidance, including settings that extend from classification to open-ended text generation.", "Idea": "Introduce WeakS-to-Strong, a framework that aggregates an ensemble of weak models to represent diverse supervisory signals, using Bayesian confidence estimates to weight and guide the supervision. The approach generalizes beyond classification to text generation with advanced supervision strategies and incorporates direct preference optimization to train the student model beyond standard teacher forcing."}
{"id": "Pj4Aid3XqL", "Context": "Large language models can gain vision-language capabilities by introducing image data after initial language pretraining, but the relative trade-offs between this two-stage approach and models that integrate images during pretraining remain unclear.", "Idea": "Develop a systematic pretraining framework that introduces visual tokens at different points in the LLM training trajectory. The approach varies image–text ratios, dataset composition, and model scale to enable a controlled comparison between delayed and early multimodal integration."}
{"id": "B2Fqu7Y2cd", "Context": "Instruction-following in audio synthesis and transformation requires models to respond to free-form text and optionally condition on audio. Unlike text corpora used by language models, audio datasets typically lack the explicit instructions that produced the sounds, making it difficult for audio-trained models to infer intent. Additionally, achieving compositional behavior over instructions—such as combining, interpolating, or negating prompts—remains challenging.", "Idea": "Introduce Fugatto, an instruction-following audio synthesis and transformation model that accepts free-form text with optional audio conditioning. The approach includes a tailored dataset generation pipeline that creates diverse audio–language pairs across generation and transformation tasks to expose clear correspondences between text and sound. At inference, it uses ComposableART, extending classifier-free guidance to compositional guidance, to flexibly compose instructions."}
{"id": "MWHIIWrWWu", "Context": "Controlling high-dimensional nonlinear systems—common in biological and robotic settings—is challenging due to large state and action spaces. While deep reinforcement learning has shown promise, it is computationally intensive, slow, and requires substantial manual reward tuning, limiting scalability across many tasks.", "Idea": "Introduce MPC^2, a hierarchical, model-based control approach for zero-shot and near-real-time control of high-dimensional dynamical systems. It couples a sampling-based model predictive controller for target posture planning with a morphology-aware proportional controller for actuator coordination. The framework also supports black-box optimization to tune reward functions."}
{"id": "cmYScmfu4Q", "Context": "In reinforcement learning from human feedback (RLHF) for fine-tuning large language models, reward inference from preferences is commonly used but suffers from distribution shift, overfitting, and misspecification. Direct policy optimization methods like DPO offer a simpler pipeline but rely on assumptions (e.g., bandit or deterministic settings) that limit applicability to general stochastic RL and broader preference models, motivating approaches that work without reward inference in more general scenarios.", "Idea": "Propose two RLHF algorithms that eliminate reward inference and operate in general stochastic RL settings with flexible preference models. The algorithms estimate local value function differences from human preferences and use these estimates to build a zeroth-order approximation of the policy gradient for updating the policy."}
{"id": "6HcnC3pPkp", "Context": "Test-time compute search strategies for improving LLM mathematical problem solving increasingly rely on verifiers, yet most existing verifiers were built for Best-of-N search and are ill-suited to tree-search settings. In tree search, these verifiers provide only indirect or coarse feedback on partial solutions and often under-value intermediate steps, leading to premature pruning of potentially promising paths.", "Idea": "Introduce token-supervised value models (TVMs), verifiers that assign each token a probability representing the likelihood of eventually reaching the correct final answer. This token-level supervision enables direct, explicit evaluation of partial solutions and more accurate discrimination between promising and incorrect intermediate steps during tree search."}
{"id": "BAelAyADqn", "Context": "Longitudinal modeling of human behavior from smartphone and wearable data is used to predict near-term health and well-being outcomes. Existing approaches often exhibit limited accuracy and overlook real-world constraints of ubiquitous health data, such as heterogeneous feature types, high rates of missingness, and resource limitations, raising concerns about practical deployment.", "Idea": "MuHBoost is a multi-label boosting framework that combines large language model prompting with multi-label classification to jointly predict multiple health and well-being outcomes from ubiquitous health data. It includes mechanisms for handling heterogeneous features and missing values, and introduces two variants that mitigate LLM hallucination when answering multiple queries simultaneously."}
{"id": "svp1EBA6hA", "Context": "Diffusion models are widely used generative models, and in downstream applications practitioners often need to impose additional controls when treating them as pre-trained backbones, typically using only offline input–label datasets. Existing conditioning techniques such as classifier guidance and classifier-free guidance can be sample-inefficient, burdensome in dataset construction, or require training classifiers on intermediate noised states.", "Idea": "Introduce CTRL, a method that frames the task of adding new controls to a pre-trained diffusion model as a reinforcement learning problem using an offline dataset. It learns a classifier from the offline labels to define a reward and incorporates a KL penalty to the pre-trained model, producing a soft-optimal policy that enables conditional sampling under the desired controls at inference."}
{"id": "l2zFn6TIQi", "Context": "As large generative models become more capable and widely used, concerns have grown about their reliability, safety, and potential misuse. Prior work has explored controlling generated outputs by steering internal activations to induce or suppress specific concepts or behaviors.", "Idea": "Introduce Activation Transport (AcT), a general activation-steering framework grounded in optimal transport that unifies and extends prior approaches. AcT operates across modalities and provides fine-grained control by adjusting model activations to regulate the emergence of targeted concepts or behaviors during generation."}
{"id": "FpiCLJrSW8", "Context": "Trustworthiness—spanning reliability, safety, and ethical alignment—has become a central concern for large language models alongside raw capability. While Reinforcement Learning from Human Feedback (RLHF) is widely used to align models to human preferences, its actual impact on trust-related dimensions such as toxicity, bias, machine ethics, truthfulness, and privacy has not been rigorously established.", "Idea": "Adapt efficient influence function–based data attribution to the RLHF pipeline to quantify how individual fine-tuning preference data affect model behavior on specific trustworthiness dimensions. The method traces contributions of training data through the alignment process to reveal data-level influences on downstream trustworthiness benchmarks."}
{"id": "5WEpbilssv", "Context": "High-content perturbation experiments enable fine-grained probing of biomolecular systems but are limited by high experimental and analytical costs. While machine learning could guide exploration and interpretation, current methods overlook the semantic richness of biological knowledge and often optimize objectives misaligned with downstream analyses. Existing benchmarks primarily test static factual recall rather than structured reasoning for open problems such as predicting differential expression and directionality for unseen perturbations and conducting gene set enrichment.", "Idea": "Introduce PerturbQA, a benchmark that formalizes structured reasoning over perturbation experiments through tasks including prediction of differential expression, direction changes for unseen perturbations, and gene set enrichment. Additionally, present Summer, a domain-informed LLM framework that summarizes context, retrieves relevant biological information, and produces structured answers for these tasks."}
{"id": "9OfKxKoYNw", "Context": "Text-guided diffusion models enable realistic image edits from simple prompts, raising concerns about misuse to create misleading or harmful content. Existing defenses that add imperceptible adversarial noise can induce failures but are often ineffective against sophisticated manipulations like masked editing, creating a need for stronger protection against unauthorized edits.", "Idea": "Introduce DiffusionGuard, a defense for diffusion-based image editors that defines a new objective to generate adversarial noise aimed at the early steps of the diffusion process. It also employs a mask-augmentation strategy to handle diverse edit masks and provides a benchmark for evaluating protection against privacy threats."}
{"id": "oZkqkkvdND", "Context": "Variational Autoencoders are increasingly deployed in safety-critical settings where models must remain reliable under adversarial perturbations. Delivering certified probabilistic guarantees for these generative models, particularly with respect to worst-case errors, is a challenging problem.", "Idea": "Introduce CIVET, a certified training framework for VAEs that hinges on bounding worst-case error via bounds on carefully selected support sets in the latent layer. Using this theoretical insight, it provides a training algorithm that enforces these bounds during optimization."}
{"id": "Pujt3ADZgI", "Context": "Reinforcement Learning with Human Feedback (RLHF) is widely used to align large language models with human preferences. Most existing methods are reward-based and rely on the Bradley-Terry assumption for pairwise comparisons, which may be too restrictive for complex human preferences, and they often require estimating per-response win rates, leading to significant computational and annotation costs.", "Idea": "Formulate RLHF under a general preference framework as a two-player game and introduce an online algorithm, Iterative Nash Policy Optimization (INPO). The policy trains via self-play with no-regret learning to approximate a Nash policy, using a new loss defined directly over the preference dataset that avoids per-response win-rate estimation."}
{"id": "9HK2rHNAhd", "Context": "Reducing the memory and computation cost of large language model inference often hinges on optimizing the key–value (KV) cache. Prior KV-cache compression methods primarily sparsify tokens based on token importance and commonly allocate the same KV budget to every transformer layer, despite layers differing in sensitivity to input tokens, which can make uniform budgeting inefficient.", "Idea": "Introduce a method that jointly optimizes the KV cache across sequence-wise and layer-wise dimensions. It estimates each attention layer's importance by computing the cosine similarity between representations before and after the self-attention layer, then groups layers by importance and dynamically assigns per-layer KV budgets. Given these budgets, it applies a chosen sequence-wise compression algorithm within each layer."}
{"id": "Mfnh1Sqdwf", "Context": "Predicting gene expression from DNA sequences requires identifying the regulatory elements that control expression levels. A central challenge is disentangling signals in genomic data, such as epigenomic marks and sequence features, to isolate the components that causally influence gene regulation.", "Idea": "Introduce Seq2Exp, a sequence-to-expression model designed to discover and extract regulatory elements that drive target gene expression while modeling causal relations among DNA sequences, epigenomic signals, and regulatory elements. It decomposes the epigenomic signals and DNA sequence conditioned on causal active regulatory elements and employs an information bottleneck with a Beta distribution to combine their effects while filtering out non-causal components."}
{"id": "pbre0HKsfE", "Context": "Large language models provide personalized responses, but this raises significant privacy concerns when user data is involved. Homomorphic encryption enables computation directly on encrypted data and is a promising approach for privacy-preserving machine learning, yet the heavy computational demands of transformer-based LLMs hinder its practical application, especially for personalized fine-tuning and inference.", "Idea": "Introduce an HE-friendly transformer architecture tailored for encrypted deployment, with an emphasis on inference after private, personalized fine-tuning. The method employs LoRA-based low-rank adapters and Gaussian-kernel operations to align with the arithmetic and operational constraints of homomorphic encryption."}
{"id": "WeJEidTzff", "Context": "Commuting origin-destination flows are vital for urban planning as they describe where residents live and work, but collecting such data is costly. To address data scarcity, researchers use models driven by readily available urban attributes; however, disparate techniques, datasets, and evaluation metrics across studies hinder fair and consistent comparison.", "Idea": "Introduce a large-scale dataset of commuting origin-destination flows covering 3,333 areas across diverse U.S. urban environments. Build a standardized benchmarking framework that unifies inputs and evaluation protocols to consistently compare commuting OD flow generation methods."}
{"id": "kiOxNsrpQy", "Context": "As Graph Neural Networks become widely used, there is a growing need for explanations that accurately reflect their decision-making. A central requirement is faithfulness, but there are multiple competing metrics, creating ambiguity about what faithfulness truly means and how to achieve it.", "Idea": "Provide a theoretical framework that analyzes and contrasts faithfulness metrics for GNN explanations, clarifying their non-equivalence and the properties they may overlook. Establish conditions under which optimizing for faithfulness is ill-posed—showing that perfectly faithful explanations can be uninformative for certain architectures—and delineate how modular designs avoid this pitfall. Formalize the link between faithfulness and out-of-distribution invariance by requiring that the domain-invariant subgraph identified by the model also be faithful."}
{"id": "Kpjvm2mB0K", "Context": "The work considers one-pass streaming for underdetermined l_p linear regression, where a minimum l_p-norm solution x must satisfy Ax = b with n much smaller than d and columns of A arriving sequentially. In the special case where A is a graph incidence matrix, this setting aligns with edge-insertion streams and models l_p flow problems such as transshipment (p=1), electrical flows (p=2), and max flow (p=∞) on undirected graphs. The challenge is to estimate the objective value or produce feasible solutions under stringent space constraints far smaller than the stream length.", "Idea": "Introduce one-pass streaming algorithms that maintain a compressed surrogate of the regression instance by selecting and reweighting a small subset of arriving columns so the l_p objective is preserved to a target accuracy; in graph settings, the same approach yields l_p flow sparsifiers. Additionally, develop streaming sketching schemes for outputting approximate solutions with tunable space–approximation trade-offs adapted to different p regimes."}
{"id": "eENHKMTOfW", "Context": "Industrial research labs have the compute, expertise, and infrastructure to fine-tune large language models, while individual developers and small organizations often cannot, due to limited resources and the complexity of navigating many training choices.", "Idea": "Conduct a comprehensive, systematic exploration of supervised instruction-tuning for small, accessible LLMs by varying key hyperparameters and training strategies across multiple open-source base models. Provide detailed, reproducible configurations—covering batch size, learning rate schedules, warmup, and curriculum choices such as phased versus stacked—and release accompanying code to enable practitioners to apply these setups."}
{"id": "TEkoMEjf7E", "Context": "Despite recent progress, generative 3D modeling remains ill-posed, making it difficult to consistently produce high-quality, controllable, and well-aligned 3D content. Methods often struggle to reconcile input cues with generated geometry and to learn effectively under limited supervision.", "Idea": "Introduce Phidias, a diffusion-based 3D generative framework that augments synthesis with retrieved or user-provided 3D reference models. It integrates a meta-ControlNet to adaptively modulate conditioning strength, dynamic reference routing to address mismatches between inputs and references, and self-reference augmentations for self-supervised learning with a progressive curriculum. The framework supports text, image, and 3D conditioning within a unified pipeline."}
{"id": "EV7FMBZxnx", "Context": "Detecting concealed objects, such as in vivo lesions or camouflage, often requires specialized imaging setups. Lensless cameras offer compact and flexible alternatives, but the absence of lenses produces measurements with weak visual semantics, making concealed object detection particularly challenging. This challenge is compounded by the lack of dedicated benchmark datasets for lensless scenarios.", "Idea": "Introduce a Region Gaze-Amplification Network (RGANet) that progressively extracts concealed objects from lensless imaging measurements. It integrates a Region Gaze Module to mine spatial-frequency cues inspired by biological and psychological mechanisms and a Region Amplifier to enhance object-region details. Additionally, provide the first benchmark dataset tailored to lensless concealed object detection."}
{"id": "21rSeWJHPF", "Context": "Ranking vertices in graphs is a fundamental task, yet traditional and centrality-based methods often yield unbalanced rankings when graphs contain community structure. This unbalancedness can lead to loss of information, polarized opinions, and reduced diversity, and persists in unsupervised settings with popular measures such as PageRank.", "Idea": "Introduce relative centrality, an iterative, graph-dependent local normalization of centrality scores that encourages balanced rankings while preserving the validity of the ordering. Additionally, propose the multi-core-periphery with communities (MCPC) graph structure to formalize and analyze the sources of unbalancedness in standard centrality measures."}
{"id": "l0gZS0sAlf", "Context": "Training and fine-tuning large language models on heterogeneous, multi-source data can produce conflicting gradient directions that hinder optimization and task specialization, undermining generalization and downstream performance. Prior work suggests that fine-tuning on carefully selected, task-specific subsets can match or exceed using the full dataset.", "Idea": "Propose ELREA, an ensemble framework that clusters training instructions by gradient direction to define distinct areas of expertise. Train a LoRA-based expert adapter for each cluster. At inference, select and combine outputs from the experts whose gradients are most similar to the input with respect to the training clusters."}
{"id": "mFY0tPDWK8", "Context": "Recent ML methods for MILP often predict an initial solution and fix a subset of variables to shrink the search space before solving the reduced problem. However, directly fixing variables based on imperfect predictions can degrade solution quality or render the reduced problem infeasible.", "Idea": "Introduce Apollo-MILP, an alternating prediction–correction neural framework that iteratively predicts values for unfixed variables and then refines them via a trust-region search to obtain a reference solution. It derives an Uncertainty-based Error upper Bound (UEBO) from the predicted and reference solutions to estimate confidence and fixes only high-confidence variables in each iteration."}
{"id": "mYgoNEsUDi", "Context": "Diffusion models have become prominent for graph generation in areas like drug design and knowledge discovery. However, existing graph diffusion models have difficulty holistically capturing intrinsic higher-order topological properties, which undermines their generalizability and suitability for downstream tasks. A core challenge is representing such topology consistently across multiple resolutions and evolving sequences of graphs.", "Idea": "Introduce a computationally efficient topological summary, zigzag spaghetti (ZS), that leverages zigzag persistence to extract latent, multi-resolution topological descriptors over sequences of graphs. Provide theoretical stability guarantees for ZS and integrate these dynamic topological features into graph diffusion models."}
{"id": "LBl7Hez0fF", "Context": "Large vision-language models face hallucination issues that hinder practical use; unlike pure language models, these errors often arise from misalignment between visual inputs and generated text. The architectural setup—where image encoders and text decoders are commonly pre-trained separately—can make the decoder overly sensitive to visual signals, contributing to hallucinations.", "Idea": "Introduce Visual and Textual Intervention (VTI), a task-agnostic test-time method that steers the latent representations of both modalities during inference to stabilize vision-conditioned features and reduce hallucinations. The approach adjusts internal activations without altering model weights or requiring additional training, enabling easy integration into existing LVLMs."}
{"id": "dQ2xiSIYzp", "Context": "Recovering a full 3D human body from a single image is an ill-posed problem, especially for inferring detailed appearance and geometry in occluded or unobserved regions. Ensuring realistic human pose and shape adds further ambiguity, and off-the-shelf body model estimates can be imprecise.", "Idea": "Introduce a single-view generalizable Human Gaussian Model that follows a generate-then-refine pipeline guided by human body and diffusion priors. The method predicts coarse human Gaussians, renders a back view that is refined via a ControlNet, and then reconstructs refined Gaussians using both the input and the refined back view; a dual branch leverages SMPL-X to propagate volumetric features to image-space Gaussians via sparse convolutions and attention, with the SMPL-X estimate iteratively refined."}
{"id": "uHLgDEgiS5", "Context": "Traditional influence estimation methods assume training algorithms are permutation-invariant with respect to the data. Modern large-scale training—stochastic, multi-stage, and often non-convergent—is sensitive to data order, breaking this assumption. As a result, existing influence functions cannot answer questions about how a data point’s effect varies across training stages or depends on the optimization trajectory.", "Idea": "We formalize trajectory-specific leave-one-out influence, which measures the effect of removing a particular data point at a specific training iteration while conditioning on the exact data order and optimization path. To make this tractable, we introduce data value embedding that aggregates the cumulative interactions between training data and evolving parameters, enabling efficient approximation of the trajectory-specific LOO via a dot product with the test example’s gradient."}
{"id": "lPJUQsSIxm", "Context": "Fully homomorphic encryption (FHE) enables computation on encrypted data, making it attractive for privacy-preserving machine learning inference. Yet FHE-based deep neural network implementations are hampered by heavy computational cost, high latency, and limited scalability, largely due to expensive non-linear activations and frequent homomorphic bootstrapping.", "Idea": "DCT-CryptoNets proposes conducting encrypted inference directly in the frequency domain by operating on discrete cosine transform (DCT) representations. Leveraging JPEG-style DCT coefficients, it restructures the network to reduce reliance on costly non-linear operations and bootstrapping within FHE, emphasizing models that learn from perceptually salient low-frequency components."}
{"id": "rfdblE10qm", "Context": "The Bradley–Terry model is widely used to convert pairwise response preferences into scalar rewards for aligning large language models, despite originating in game matching. Its suitability is unclear when only sparse pairwise comparisons are available and when the primary need is to derive rewards that support downstream optimization.", "Idea": "Establish a theoretical foundation for BT-based reward models by proving convergence rates when implemented with embedding-based deep neural networks. Formalize the notion of order consistency—requiring only monotonic rank preservation—and analyze the BT model through this lens. Introduce a simple upper-bound objective that enables order-consistent reward modeling using off-the-shelf binary classifiers as an alternative to BT."}
{"id": "W2Wkp9MQsF", "Context": "Large neural networks are challenging to deploy in resource-constrained environments. Many compression techniques rely on training data or fine-tuning, which may be unavailable, and existing data-free approaches often distort internal statistics, leading to issues like variance collapse or explosion.", "Idea": "Introduce model folding, a data-free compression method that merges structurally similar neurons across layers to reduce model size without fine-tuning or access to training data. It preserves data statistics via k-means clustering and includes data-free mechanisms to prevent variance collapse or explosion during compression."}
{"id": "sLKDbuyq99", "Context": "Large language model-based multi-agent systems have shown strong capabilities in automated planning and task execution, but real-time adaptation of agent workflows remains underexplored. In practical settings, initial plans must be adjusted to handle unforeseen challenges and changing conditions, particularly when dealing with complex dependencies and potential parallelism in tasks.", "Idea": "Represent workflows as an activity-on-vertex (AOV) graph, enabling LLM agents to continuously refine workflows by dynamically reallocating subtasks using historical performance and prior AOVs. Complement this with a modular workflow design that explicitly evaluates parallelism and dependency complexity to structure subtasks and their coordination within the multi-agent framework."}
{"id": "9OJflnNu6C", "Context": "Advances in generative models have intensified concerns about privacy breaches and biases, motivating machine unlearning to remove specific training data from models. In the context of image-to-image generative models, existing approaches typically cast unlearning as a single-objective problem that yields a single solution, failing to accommodate diverse user preferences in balancing complete unlearning against model utility.", "Idea": "Introduce a controllable unlearning framework that employs a control coefficient ε to tune the trade-off between unlearning and utility. Reformulate the task as an ε-constrained optimization problem and solve it via a gradient-based method to compute unlearning boundaries, which define the valid range for ε and yield Pareto-optimal solutions. Additionally, analyze the framework’s convergence under different control functions."}
{"id": "zjeHLSiNv1", "Context": "Transformer performance scales with model size and computational budget, but increasing parameters typically raises inference costs. Techniques like Mixture of Experts decouple parameter count from compute, yet they still incur substantial memory access overhead during inference, leading to latency and bandwidth bottlenecks.", "Idea": "Introduce UltraMem, a Transformer architecture that integrates a large-scale, ultra-sparse memory layer. The layer uses sparse addressing to retrieve and update only a small subset of numerous memory slots per step, preserving high parameter capacity while limiting active compute and memory traffic at inference."}
{"id": "hgwGi81ndj", "Context": "Efficient exploration in reinforcement learning remains challenging, particularly in sparse-reward, long-horizon environments. Working directly with pixel-level observations and primitive actions complicates transition modeling and makes predicting informative future states difficult, hindering planning and transfer.", "Idea": "Propose a hierarchical, fully model-based approach that represents environments as sets of items and attributes, modeling items at a higher state abstraction than pixels and attribute changes at a higher temporal abstraction than primitive actions to simplify dynamics. The method learns a discriminative world model over this abstract space, plans exploration with a count-based intrinsic reward, and then plans to reach any discovered abstract states. It also learns low-level object-perturbing controllers via reinforcement learning and acquires the object mapping through supervised learning."}
{"id": "CI4sCBMXjP", "Context": "Enhancing the adaptability of large language models is challenging: traditional fine-tuning demands substantial data, computation, and specialized capabilities, while in-context learning hinges on well-chosen demonstrations and is constrained by token budget.", "Idea": "Introduce ELICIT, a two-module framework that externalizes and manages task vectors encoding in-context learned capabilities. It stores these vectors as modular knowledge and reuses or composes them to adapt models on demand without additional training or inference tokens."}
{"id": "hJVdwBpWjt", "Context": "Large language models that process both text and audio have excelled on speech, music, and general audio tasks, exhibiting emergent abilities on unseen tasks. However, their potential remains underexplored in bioacoustics, where key challenges include detecting animal vocalizations in long recordings, classifying rare or endangered species, and labeling context and behavior—problems compounded by limited annotated data critical for conservation and biodiversity monitoring.", "Idea": "Introduce NatureLM-audio, an audio-language foundation model tailored to bioacoustics. It is trained on carefully curated text–audio pairs spanning bioacoustics, speech, and music to mitigate scarce bioacoustic annotations and enable cross-domain transfer of auditory representations."}
{"id": "4GSOESJrk6", "Context": "Personalized image generation is increasingly important for creating tailored visual content, but evaluating such systems is challenging: automated metrics often diverge from human judgment, while human assessments are costly and time-consuming.", "Idea": "Introduce DreamBench++, a human-aligned evaluation benchmark automated with advanced multimodal GPT models. It employs systematically designed, task-reinforced prompts to ensure both human alignment and self-alignment, and includes a comprehensive dataset of diverse images and prompts for standardized assessment."}
{"id": "PkpNRmBZ32", "Context": "State-space models are increasingly used for raw audio and sequence processing, but practical training and memory constraints have pushed implementations toward narrowly scoped, depthwise-separable blocks. The broader design space for SSM blocks and network-level composition remains underexplored, limiting flexibility. There is a need for architectures that balance model size, computational cost, and memory usage across both training and inference in applications like keyword spotting, speech denoising, and ASR.", "Idea": "Introduce Centaurus, a class of networks built from generalized SSM blocks whose computations are formulated as tensor contractions during training. For each block, the contraction order is optimized to improve training efficiency, enabling designs beyond depthwise-separable layouts. The architecture mixes SSM block types inspired by classical convolutional patterns—such as group, full, and bottleneck blocks—to balance model size with memory and compute efficiency during both training and inference."}
{"id": "t8fu5m8R5m", "Context": "Anomaly detection systems, despite advances, are vulnerable to adversarial attacks, threatening reliability in safety-critical domains like autonomous driving. This vulnerability stems from the standard setting where training uses only unlabeled normal data, leaving models exposed to adversarial anomalies at test time. Additionally, adversarial training is hard to apply without labels, and it is unclear how to define an objective that encourages strong intra- and inter-group perturbations to maximize the margin between normal and anomalous distributions.", "Idea": "Construct a pseudo-anomaly group derived from normal samples and adopt an adversarial contrastive training objective to induce both intra- and inter-group perturbations. Address the limitations of conventional contrastive loss by identifying spurious negative pairs and defining opposite pairs, which are adversarially pulled apart to steer inter-group perturbations. This yields a label-free adversarial training formulation tailored for robust anomaly detection."}
{"id": "fGhr39bqZa", "Context": "Causal discovery with latent variables is challenging because it requires identifying hidden factors and their causal relations. Many existing approaches rely on the assumption that latent variables have pure children, an assumption that can be restrictive in practice and is not theoretically necessary.", "Idea": "Introduce the concept of a homologous surrogate, which accommodates more flexible parent sets than pure children. Formalize two assumptions built on homologous surrogates and develop a theoretical framework, then design an algorithm that leverages these properties to recover the causal graph."}
{"id": "4ua4wyAQLm", "Context": "Video anomaly detection aims to identify actions or events that were not observed during training. Many existing approaches emphasize global patterns with redundant details, which hampers generalization to unseen samples.", "Idea": "Propose a framework that learns generalizable local patterns and their dynamics via a two-stage process combining image–text alignment with cross-modal attention to extract spatially local, semantically relevant components that can be recombined. Introduce a State Machine Module that uses earlier high-resolution textual tokens to guide caption generation for later low-resolution observations, and integrate temporal motion estimation to capture distinctive dynamics and novel spatial distributions."}
{"id": "xPxHQHDH2u", "Context": "Recent advances in novel view synthesis using NeRF and 3D Gaussian Splatting still struggle with reconstructing reflective objects. Existing approaches lack a practical solution for real-time, high-quality rendering that correctly accounts for inter-reflections.", "Idea": "Propose Reflective Gaussian Splatting (Ref-Gaussian) comprising: (I) a physically based deferred rendering formulation that injects pixel-level material properties via a split-sum approximation; and (II) a Gaussian-grounded inter-reflection mechanism implemented within the Gaussian splatting paradigm. The framework further augments geometry and shading with material-aware normal propagation, an initial per-Gaussian shading stage, and 2D Gaussian primitives."}
{"id": "i3e92uSZCp", "Context": "Skill discovery methods can learn behaviors without explicit rewards, but for downstream usefulness it is essential to obtain a repertoire of semantically diverse skills. Existing approaches often rely on discriminators to make skills distinguishable or aim to increase state coverage, leaving the direct pursuit of semantic diversity underexplored.", "Idea": "Introduce Language Guided Skill Discovery (LGSD), a framework that directly maximizes semantic diversity between skills using guidance derived from large language models. It accepts user prompts to constrain exploration to a desired semantic subspace and employs LLM outputs to steer the agent toward semantically diverse states, yielding a set of distinct skills."}
{"id": "ws5phQki00", "Context": "Stance detection is valuable for moderating and summarizing political discussions, but current transformer-based approaches require large labeled datasets. The diversity of online debate topics makes data collection difficult, and directly deploying LLMs poses risks due to inconsistent outputs, biases, and susceptibility to adversarial inputs.", "Idea": "Adopt a hybrid pipeline that uses a reliable, traditional stance detection model for deployment while leveraging an LLM offline to generate topic-specific synthetic stance data for fine-tuning. Treat the synthetic set as a reference to drive uncertainty-based selection of the most informative unlabeled examples, and fine-tune the detector on both the synthetic and selected real samples."}
{"id": "t8KLjiFNwn", "Context": "Transformer models are widely used across domains for handling long-range dependencies and global context. State Space Models (SSMs) have emerged as strong alternatives by using a selective mechanism that dynamically adjusts parameters based on input, but this increases computational complexity and bandwidth, making deployment on resource-constrained mobile devices challenging.", "Idea": "Introduce a sparse learning framework that integrates architecture-aware compiler optimizations. It proposes an end-to-end C4^n kernel sparsity scheme that prunes n elements from every four contiguous weights and includes a compiler-based acceleration path tailored to this sparsity on mobile hardware. The framework targets specified sparsity or latency, compensates remaining weights using pruned-weight information, and adds C4^n-specific optimizations with layout-transformation elimination to mitigate fine-grained pruning inefficiencies in linear layers and related operations."}
{"id": "Bp0HBaMNRl", "Context": "Discovering causal structures when latent variables are present using only observational data is a longstanding challenge. Prevailing approaches often use constraint-based, iterative discrete searches that scale poorly and impose linearity or invertibility assumptions, limiting their applicability in complex real-world settings.", "Idea": "Provide new identifiability results for non-linear latent hierarchical causal models that relax assumptions about deterministic latent variables and exogenous noise. Building on these theoretical insights, introduce a differentiable causal discovery algorithm that estimates model structure via gradient-based optimization. The method targets non-linear, hierarchical latent structures and avoids discrete, constraint-based search procedures."}
{"id": "2IoFFexvuw", "Context": "Reinforcement learning has recently been effective for fine-tuning diffusion-based generative models, but aligning continuous flow-based generative models with arbitrary reward functions remains difficult. Key obstacles include policy collapse from over-optimization and the high computational cost of likelihoods in continuous-time flows.", "Idea": "Introduce an RL-based fine-tuning approach within the flow-matching framework that can optimize against arbitrary reward functions without requiring reward gradients or curated filtered datasets. Use an online reward-weighting scheme to steer training toward high-reward regions, and incorporate Wasserstein-2 distance regularization with a tractable upper bound to prevent collapse and maintain diversity while balancing exploration and exploitation."}
{"id": "izjNI5bcOV", "Context": "Weather analysis involves complex, heterogeneous data modalities and a broad spectrum of tasks vital to human activities. Existing data-driven approaches are typically tailored to single tasks and specific scenarios, lacking a unified solution and being constrained by reliance on limited real observations.", "Idea": "Introduce WeatherGFM, a generalist foundation model that addresses multiple weather understanding tasks within a single framework. The method standardizes task definitions and representations, designs modality-aware weather prompts for single, multiple, and temporal inputs, and formulates training as a visual prompting question-answering paradigm."}
{"id": "5IWJBStfU7", "Context": "As AI systems are increasingly used in high-stakes settings, interpretability has become crucial. Mechanistic interpretability seeks to reverse-engineer neural networks into human-understandable algorithms, raising a fundamental question about whether a fixed behavior admits a single, unambiguous explanation within such frameworks.", "Idea": "Introduce a formal notion of identifiability for mechanistic explanations, paralleling statistical identifiability, to specify when a unique explanation is determined by a behavior under stated assumptions. Structure mechanistic interpretability into two workflows—where-then-what and what-then-where (leveraging causal alignment in activation subspaces)—and propose stricter unicity requirements alongside complementary validation criteria to assess explanations."}
{"id": "z8PcUSKXXN", "Context": "Generalizable deep image denoising seeks robust performance across diverse noise types using a single model. A leading approach, Masked Training with a masked SwinIR trained on Gaussian noise, can transfer to other noise distributions but tends to over-smooth images, requires sensitive mask-ratio tuning, and adds architectural complexity that hinders integration and efficient deployment.", "Idea": "Introduce RNINet, a streamlined encoder–decoder denoising architecture. Building on the observation that feature statistics shift across noise conditions, augment the network with a noise injection block that perturbs feature statistics (e.g., mean and variance) to encourage robustness and generalization to unseen noise types."}
{"id": "yitH9xAHQs", "Context": "Large language models rely on diverse, high-quality task-specific data to perform well across applications. Common data synthesis pipelines depend on human annotations or manually designed templates to steer data generation. This manual dependence can constrain coverage and miss challenging edge cases or novel scenarios that reveal model weaknesses.", "Idea": "Introduce ReverseGen, which automatically generates training samples by training a dedicated proposer to craft queries that provoke unsatisfactory responses from a target model. These failure-inducing queries are then transformed into training data to directly address the model’s shortcomings, and the procedure is applicable across different model scales."}
{"id": "PUnD86UEK5", "Context": "In training language models, Adam often outperforms SGD, yet the theoretical reasons for this advantage remain unclear. Prior convergence analyses mainly characterize both methods by their dependence on the number of optimization steps and, in non-convex settings, yield similar minimax-optimal rates, which does not explain Adam's empirical edge.", "Idea": "Develop a new convergence analysis for Adam that leverages l_infty geometry by assuming the loss is smooth under l_infty rather than the usual l2 geometry. Extend this analysis to blockwise Adam under corresponding blockwise smoothness assumptions."}
{"id": "pPQPQ7Yd58", "Context": "In image-based control pipelines trained via behavior cloning, a vision encoder produces features that are consumed by an action decoder, yet the geometry of this intermediate representation space is poorly understood. Although neural collapse in image classification reveals structured, class-wise clustering, it is unclear whether analogous geometric regularities exist in control settings or how such structure could be systematically exploited.", "Idea": "Define control-oriented classes to structure the visual representation space—using discrete action labels for discrete control and relative-pose-based orthants (REPO) for continuous control. Pretrain the vision encoder with a neural-collapse-inspired regularization that encourages these control-oriented clusters, then finetune the entire encoder–decoder policy."}
{"id": "6qUUgw9bAZ", "Context": "Computationally intensive decoding techniques such as search, reranking, and self-critique can improve language model outputs across tasks like code generation, numerical reasoning, and dialog, but they incur substantial cost. Conventional systems typically apply the same decoding procedure to every input, even though inputs vary in difficulty and do not all require equal computational effort. This creates a need to allocate limited decoding computation more efficiently across inputs.", "Idea": "Propose a computation-allocation framework that predicts the distribution of expected reward conditioned on the input and a computation budget, then uses these predictions to allocate additional decoding effort to inputs with the highest expected benefit. The approach is instantiated in two procedures: an adaptive best-of-k method that dynamically selects how many samples to generate for reranking, and a routing mechanism that chooses between an accurate but expensive decoding procedure and a cheaper, less capable one."}
{"id": "hXm0Wu2U9K", "Context": "Language model alignment methods such as RLHF often suffer from overoptimization, where models overfit to imperfections in offline reward models and drift from preferred responses. KL regularization is commonly used to discourage distribution shift, yet it frequently fails to prevent this degradation, motivating a search for sample-efficient offline alignment methods that are robust to overoptimization.", "Idea": "Introduce χ^2-Preference Optimization (χPO), a minimal change to Direct Preference Optimization that replaces the logarithmic link function in the objective. This modification induces χ^2-divergence regularization, implementing pessimism in the face of uncertainty for offline alignment."}
{"id": "d8hYXbxX71", "Context": "Policymakers face the challenge of designing welfare policies that must balance short-term outcomes with long-term effects across populations. Short-run evaluations can misrepresent policies that yield delayed benefits, and debate persists between Rawlsian approaches that prioritize the worst-off and utilitarian approaches that maximize immediate average welfare, which are often viewed as conflicting.", "Idea": "Develop a formal sequential decision-making model in which individuals' welfare levels stochastically decay over time and policymakers can intervene to mitigate this decay. Within this framework, precisely define Rawlsian and utilitarian policies and analyze their long-run dynamics, deriving conditions that delineate when each policy is favored."}
{"id": "G0dksFayVq", "Context": "LLM-based judges are increasingly used as a scalable alternative to human evaluation, but their own reliability is seldom scrutinized. As LLM outputs become more sophisticated, evaluating them requires stronger judges. Existing benchmarks emphasize alignment with human preferences and often neglect tasks where crowdsourced preferences poorly indicate factual or logical correctness.", "Idea": "Introduce an objective evaluation framework tailored to LLM-based judges. Instantiate it as JudgeBench, a benchmark of challenging response pairs across knowledge, reasoning, math, and coding, built via a pipeline that converts difficult datasets into pairs with preference labels reflecting objective correctness."}
{"id": "vJkktqyU8B", "Context": "Existing Vision Transformer adapter approaches achieve strong accuracy but experience slow inference due to inefficient memory access patterns, notably from standard normalization and frequent tensor reshaping. There is a need for adapters that alleviate these bottlenecks while remaining suitable for dense prediction tasks.", "Idea": "Introduce META, a ViT adapter built around a memory-efficient block that shares a single layer normalization between self-attention and feed-forward layers and employs cross-shaped self-attention to reduce reshape-heavy operations. The block is further equipped with a lightweight convolutional branch to inject local inductive bias and is organized in a cascaded manner to produce diverse head features."}
{"id": "SiH7DwNKZZ", "Context": "Transformers have become the prevalent generic backbone in computer vision, even though they originated in natural language processing. In parallel, the LSTM family has been extended to the scalable xLSTM, which addresses long-standing LSTM limitations through exponential gating and a parallelizable matrix-memory structure.", "Idea": "Introduce Vision-LSTM (ViL), an adaptation of xLSTM building blocks for computer vision. ViL stacks xLSTM blocks that process sequences of patch tokens in alternating directions, with odd blocks traversing top-to-bottom and even blocks bottom-to-top."}
{"id": "9NfHbWKqMF", "Context": "3D Gaussian Splatting enables photorealistic, real-time reconstruction but suffers when rendering viewpoints that deviate from the training cameras, limiting free-viewpoint navigation. Comprehensive evaluations on synthetic and real datasets indicate that existing novel view synthesis methods, including those using regularization and data-driven priors, generalize poorly to out-of-distribution views.", "Idea": "Introduce SplatFormer, a point transformer architecture that operates directly on sets of 3D Gaussian splats. It takes an initial 3DGS optimized from limited training views and refines the splats in a single forward pass, adjusting their parameters to handle out-of-distribution viewpoints."}
{"id": "84WmbzikPP", "Context": "Molecular structure elucidation is crucial across chemistry, including identifying molecules in natural products, laboratory syntheses, forensic samples, and the interstellar medium. The task considered is predicting a molecule’s all-atom 3D structure from its molecular formula and moments of inertia measured by rotational spectroscopy. Existing conditional generative models only approximate these moments, failing to fully exploit the high precision of such measurements.", "Idea": "Characterize the set of n-atom point clouds with fixed moments of inertia as embedded in the Stiefel manifold St(n,4). Build on this by introducing Stiefel Flow Matching, a manifold-based generative model that enforces exact moment constraints during structure generation. Further simplify and shorten the flows by approximating equivariant optimal transport on the Stiefel manifold."}
{"id": "9FqARW7dwB", "Context": "Residual connections are a standard component in deep neural networks, but many variants suffer from a trade-off between gradient vanishing and representation collapse, complicating stable optimization in deep and large models.", "Idea": "Introduce hyper-connections as an alternative to residual connections. This mechanism learns to modulate the strength of connections between features at different depths and allows dynamic reordering of layers to control information flow."}
{"id": "ho4mNiwr2n", "Context": "Anti-backdoor learning aims to obtain clean models directly from poisoned datasets. However, existing methods often fail to restore poisoned samples to their correct labels and generalize poorly to large pre-trained models due to non–end-to-end training, making them ill-suited for protecting modern large models.", "Idea": "Revisit anti-backdoor learning from a causal perspective and introduce an end-to-end method, Mind Control through Causal Inference (MCCI). The approach conditions training on both the image and an explicit attack indicator, enabling control over whether the model treats an input as clean or backdoored. At inference, providing non-attack indicators directs the model to process inputs as clean."}
{"id": "WwmtcGr4lP", "Context": "Cancer treatment is difficult to personalize because patients exhibit highly variable drug responses driven by heterogeneous genomic mutations. Limited patient response data hampers training robust models from clinical sequencing alone. Existing transfer learning approaches leverage large pre-clinical cell line datasets to learn a shared, domain-invariant representation for drug response prediction, but this overlooks patient-specific characteristics that strongly influence outcomes.", "Idea": "Introduce GANDALF, a generative attention-based framework that performs data augmentation and predictive modeling tailored to patients. It directly augments patient genomic profiles while explicitly modeling domain-specific characteristics, integrating these augmentations into a downstream drug response predictor."}
{"id": "d8cnezVcaW", "Context": "Direct Preference Optimization (DPO) is widely used in reinforcement learning from human feedback to fine-tune large language models, but it struggles to capture the diversity and heterogeneity of human preferences.", "Idea": "Introduce MallowsPO, a preference-optimization framework grounded in Mallows' ranking theory that explicitly models preference variability via a dispersion index across prompts. The formulation uses this index to parameterize preference dispersion and subsumes existing DPO variants as special cases."}
{"id": "MGKDBuyv4p", "Context": "Language models can memorize training data and reproduce it verbatim at inference, which poses privacy and security risks when the data are sensitive. This creates a need for practical techniques to reduce or prevent memorization without compromising model usefulness.", "Idea": "Introduce TinyMem, a suite of small, compute-efficient language models designed for rapidly developing and assessing memorization-mitigation techniques. Propose a collection of mitigation approaches across regularization, fine-tuning, and new machine-unlearning methods, including BalancedSubnet, which aims to localize and remove memorized information from model weights prior to inference."}
{"id": "vmulbBDCan", "Context": "Electron-multiplying CCDs are widely used for low-light imaging in fields such as astronomy, materials science, and biology, yet their images still suffer from residual noise that can compromise analyses, especially in fluorescence microscopy. Prior work has largely treated EMCCD noise theoretically, and established physics-based noise models from conventional sensors do not directly transfer to EMCCDs, leaving a gap in practical, tailored denoising approaches.", "Idea": "Develop a physics-based calibration procedure that experimentally estimates EMCCD-specific noise statistics for all observable components. Leverage the calibrated noise model to synthesize realistic training data and train a modern neural denoising network specialized for EMCCD imagery. Additionally, provide a real-world EMCCD test dataset covering everyday scenes and microscopic content."}
{"id": "iXCeQ2m6vT", "Context": "AI systems lag behind humans in understanding visual relations, especially for previously unseen objects, and often struggle with judgments like whether two objects are visually the same or different. There is a need to capture relationships between distinct parts of an image that go beyond what immediate pixel-level content conveys.", "Idea": "Propose a Glimpse-based Active Perception mechanism that sequentially focuses on the most salient regions of an image and processes them at high resolution. The approach uses the spatial locations of these glimpses, together with the surrounding visual content, to explicitly encode relations between different image parts."}
{"id": "FoF5RaA3ug", "Context": "Dataset distillation increasingly leverages soft labels from pre-trained teacher models, but training on synthetic data is highly sensitive to the choice of loss used to consume these soft labels. This sensitivity exposes the need for a robust, universally applicable loss formulation that fully exploits label information in distilled datasets.", "Idea": "Propose GIFT, a simple plug-and-play method that refines soft labels and uses a cosine similarity–based loss to exploit the full label information during dataset distillation. The approach integrates into existing pipelines to standardize how soft labels are utilized."}
{"id": "R4h5PXzUuU", "Context": "Foundation models trained on internet-scale multimodal data are being rapidly adopted across domains, yet their trustworthiness remains underexplored. In particular, the out-of-distribution detection capabilities of large vision-language models have not been sufficiently characterized, creating uncertainty about their practical reliability and safe deployment.", "Idea": "Introduce an evaluation and analysis framework that probes LVLMs’ out-of-distribution behavior by extracting and interpreting confidence signals from their free-form natural language responses. Additionally, propose a self-guided prompting method, Reflexive Guidance (ReGuide), which generates image-adaptive concept suggestions and feeds them back into the prompt to guide the model’s reasoning for OoDD and image classification."}
{"id": "gU4ZgQNsOC", "Context": "Pretraining large language models relies on vast, heterogeneous datasets, yet common practice treats all training samples uniformly. Existing reweighting methods emphasize group-level importance and do not capture fine-grained, evolving relevance of individual samples during training.", "Idea": "Introduce dynamic, instance-level data reweighting that updates each sample’s weight online based on its current loss. Provide a systematic framework to craft loss-based strategies that deprioritize redundant or uninformative data, and develop a theoretical analysis that characterizes how such reweighting influences the convergence of gradient-based optimization."}
{"id": "f7KxfUrRSb", "Context": "Aligning language models with human preferences has become central to better serving diverse user needs. In related work on weak-to-strong generalization, stronger models fine-tuned on labels produced by weaker models can surpass their weak supervisors.", "Idea": "Introduce Weak-to-Strong Preference Optimization (WSPO), a method that achieves strong-model alignment by modeling and learning the distribution difference between a weak model before and after it is aligned. The strong model is optimized to reproduce this alignment-induced shift, thereby transferring the weak model’s alignment behavior."}
{"id": "oU3tpaR8fm", "Context": "Retrieval-augmented generation lets large language models draw on external knowledge, and longer context windows make it tempting to supply more retrieved passages for higher recall. Contrary to expectations, many long-context models show performance that initially improves but then degrades as more passages are added, with the decline linked to the presence of retrieved hard negatives.", "Idea": "Mitigate degradation from hard negatives using both training-free and training-based strategies: a retrieval reordering scheme, RAG-specific implicit LLM fine-tuning, and RAG-oriented fine-tuning that incorporates intermediate reasoning. Additionally, specify design choices for the training-based setups, including data distribution, retriever selection, and training context length."}
{"id": "iylpeTI0Ql", "Context": "Test-time adaptation seeks to cope with source-target distribution shifts using only target data, but in open-world settings the target stream often includes out-of-distribution, noisy samples outside the in-distribution label space. In zero-shot scenarios with vision-language models, existing TTA approaches can degrade severely because updating on unfiltered noisy data overwhelms the signal from clean data and because using a single adapting classifier for both in-distribution recognition and noise detection compromises both tasks.", "Idea": "Introduce a zero-shot test-time adaptation framework that separates in-distribution classification from noise detection by freezing the classifier/backbone and developing a dedicated detector. The detector, termed Adaptive Noise Detector, is trained using the frozen model's outputs as pseudo-labels to identify noisy samples, and Gaussian noise is injected during adaptation to discourage misclassifying clean samples as noise."}
{"id": "4rEI2JdHH6", "Context": "Neural networks can exhibit 'grokking,' where they initially memorize training data and only later transition to strong generalization after extensive training. This delayed generalization reduces predictability and efficiency, motivating methods that enable prompt generalization.", "Idea": "Propose GrokTransfer, a procedure that exploits the role of input embeddings in shaping training dynamics. It trains a smaller, weaker model to reach modest performance, extracts its learned input embedding, and uses that embedding to initialize the target, stronger model."}
{"id": "vQhn4wrQ6j", "Context": "Fine-tuning large language models for specialized tasks in non-English languages is hampered by a lack of task-specific data, making cross-lingual transfer of skills like mathematical reasoning particularly difficult. There is a need to combine target-language proficiency with math reasoning learned elsewhere without relying on in-language math data.", "Idea": "Start from the same pretrained model and fine-tune two experts: one on English math instruction data and another on generic instruction data in the target language, then merge them by swapping the top and bottom transformer layers of the math expert with those from the language expert. The layer choices are informed by an analysis of which parameters change most during each fine-tuning, enabling post-hoc composition of language and reasoning capabilities."}
{"id": "uREg3OHjLL", "Context": "Research on the expressive power of ReLU networks often examines how required depth scales with problem size using the function F_n = max(0, x1, ..., xn). A central conjecture states that any ReLU network that exactly represents this function needs at least ceil(log2(n+1)) hidden layers, a claim previously confirmed when network weights are restricted to integers.", "Idea": "Study exact representation of F_n in ReLU networks whose weights are limited to finite-precision rational values, focusing on decimal fractions and, more generally, N-ary fractions. Develop an analysis that ties the radix of the permissible weights to the minimal depth needed, clarifying how finite-precision constraints shape depth requirements."}
{"id": "vr1QdCNJmN", "Context": "Bregman divergences, derived from convex functions, are widely used to compare objects in continuous spaces, but extending them meaningfully to discrete domains is challenging. Prior work approached this by using submodular functions—discrete analogs of convex functions—as generators, which limits flexibility. There remains a need for expressive, structure-preserving divergences tailored to discrete data.", "Idea": "Define a discrete Bregman divergence generated by functions that can be expressed as a difference of submodular functions, thus moving beyond strictly submodular or supermodular generators. Additionally, provide a learnable formulation using permutation-invariant neural networks to parameterize the divergence."}
{"id": "2e4ECh0ikn", "Context": "Recent audio foundation models promise new capabilities for conversational AI, yet their ability to sustain natural, interactive dialogue remains unclear. Natural conversation requires well-timed turn-taking—minimizing overlaps and long silences—so systems must manage when to hold, yield, or take the floor. However, comprehensive assessment of these behaviors across current audio-based systems is lacking.", "Idea": "Propose a formal evaluation protocol for turn-taking in spoken dialogue systems. The protocol employs a supervised judge model trained to predict turn-taking events from human-human conversations to assess whether systems can understand, anticipate, and execute turn transitions."}
{"id": "QG31By6S6w", "Context": "Recent advances in medical vision–language pretraining have improved zero-shot disease recognition, but transferring image-level knowledge to pixel-level tasks like 3D CT lesion segmentation remains difficult. The fine-grained, variable appearance of pathological structures and the gap between unseen lesion features and disease-related text make existing methods ineffective at precise segmentation.", "Idea": "Introduce Malenia, a multi-scale lesion-level mask–attribute alignment framework tailored for 3D zero-shot lesion segmentation. It aligns mask representations with elemental attributes to connect visual features of unseen lesions to knowledge learned from seen cases, and includes a Cross-Modal Knowledge Injection module that jointly enriches visual and textual features to guide segmentation."}
{"id": "X9OfMNNepI", "Context": "Scientific discovery is central to societal progress, and while large language models show promise in aiding research, it remains unclear whether they can autonomously generate novel and valid chemistry hypotheses when provided only with a research question.", "Idea": "Assume that many chemistry hypotheses can be derived from a research background question combined with a set of inspirations, and decompose the task into three stages: retrieving relevant inspirations, synthesizing hypotheses from the background and inspirations, and ranking the resulting hypotheses. Build an LLM-based multi-agent framework that implements these stages end-to-end."}
{"id": "keu6sxrPWn", "Context": "As large language models become more capable, their behavior is harder to trust due to subtle, safety-evading errors that can accumulate risk across long task sequences. Deployers must balance leveraging these models’ capabilities with maintaining safety when the models are untrusted, motivating a need to manage average-case safety and usefulness over many tasks.", "Idea": "Introduce a two-level framework for managing diffuse risk. At the single-task level, define micro-protocols that use a trusted but less capable model to harness and monitor an untrusted model. At the whole-scenario level, employ a macro-protocol that adaptively estimates the untrusted model’s risk to select among micro-protocols."}
{"id": "2ZK8zyIt7o", "Context": "Text-to-image diffusion models have advanced markedly, yet aligning generated images with long textual inputs remains difficult. Existing encoders like CLIP have maximum input length limitations, and CLIP-based preference models used for fine-tuning often entangle text-image relevance with unrelated visual factors, which can lead to overfitting.", "Idea": "Introduce LongAlign with two components: a segment-level encoding scheme that splits long texts into segments processed independently to circumvent encoder length constraints, and a decomposed CLIP-based preference optimization. The optimization separates preference scores into text-relevant and text-irrelevant components and applies a reweighting scheme to these components during fine-tuning."}
{"id": "RaR3ETzyKp", "Context": "Recent work shows that different diffusion and rectified-flow-style models trained on the same dataset tend to produce similar outputs for the same input noise, suggesting that samples are associated with preferable noise inputs. Visualizing noise–sample pairs in two dimensions reveals that paths from preferable noises to their samples are more orderly, with far fewer crossings than paths from random noises; since paths rarely intersect in high-dimensional spaces, observed 2D crossings imply small inter-path distances in the original space.", "Idea": "Introduce Distance-Aware Noise-Sample Matching (DANSM), which matches noise–sample pairs to explicitly increase inter-path distances during training. Built on rectified flow models to permit closed-form computation of inter-path distances, it further simplifies optimization by replacing distance with a surrogate objective based on path length via a derived relationship."}
{"id": "e8qXTxMgPg", "Context": "Dimensionality reduction for s-sparse vectors seeks to preserve norms or pairwise ℓp distances while mapping high-dimensional data to fewer dimensions. Most theoretical work emphasizes worst-case guarantees, often for oblivious linear or otherwise smooth mappings, whereas practical settings motivate average-case and dataset-dependent analyses. Although folklore suggests stronger reductions may be achievable for most vectors, the precise limits across mapping models and assumptions remain unclear.", "Idea": "Develop a beyond-worst-case analysis that establishes tight average-case lower bounds for embedding s-sparse vectors, covering oblivious linear maps and a broad class of smooth encoder–decoder schemes. Complement this with a nonlinear embedding tailored to datasets of non-negative s-sparse vectors that preserves pairwise ℓp distances in substantially fewer dimensions."}
{"id": "Wvi8c0tgvt", "Context": "Realistic blur datasets lack sufficient diversity in scenes and motion patterns for training. Expanding data diversity with dual-camera capture setups is costly and complex. Moreover, common augmentation techniques model motion in 2D, ignoring the inherently 3D nature of camera and object motion, which yields unrealistic blur patterns.", "Idea": "Introduce a 3D-aware blur synthesizer that generates realistic motion blur by estimating 3D camera positions over the exposure interval, rendering intermediate scene images, and aggregating them. It models 3D transformations as a combination of a 2D transform and a projected 3D residual predicted by a neural network, avoiding explicit depth measurement. The synthesizer supports controllable augmentation by adjusting blur magnitude, direction, and scene content."}
{"id": "c4OGMNyzPT", "Context": "Large Vision Language Models can process and reason over visual and textual inputs, yet common evaluations centered on VQA and image captioning fail to reflect their full capabilities. These benchmarks suffer from limited assessment of fine-grained visual perception, potential data contamination, and insufficient emphasis on multi-turn reasoning.", "Idea": "Introduce LVLM-Playground, a game-based evaluation framework that assesses LVLMs' cognitive and reasoning skills in structured environments. It employs a suite of games spanning Perceiving, Question Answering, Rule Following, and End-to-End Playing to probe abilities such as visual perception, reasoning, and decision-making."}
{"id": "bc3sUsS6ck", "Context": "Large language models learn broad knowledge during pretraining but must be adapted to new contexts, tasks, or domains. Prevailing approaches—fine-tuning and prompting—either incur substantial training cost or add inference-time overhead, motivating a more efficient adaptation mechanism.", "Idea": "Introduce GenerativeAdapter, a fast-weight-inspired approach that encodes test-time context into a model’s parameters with a single forward pass. It augments a frozen pretrained language model with a lightweight, self-supervised adapter generator that produces parameter-efficient adapters on demand. The generator is general-purpose, enabling the same module to adapt the base model across diverse language processing scenarios."}
{"id": "rpouyo09V0", "Context": "Large language models are widely used for interactive code generation, but current benchmarks do not capture the diversity and quality of feedback found in multi-turn workflows. This gap limits accurate evaluation of model behavior under different feedback conditions.", "Idea": "Introduce CONVCODEWORLD, a reproducible interactive benchmarking environment that simulates nine code-generation scenarios by systematically combining three feedback types: compilation signals, execution feedback with controlled test coverage, and GPT-4o-generated verbal guidance at varying expertise levels. Also introduce CONVCODEBENCH, a fast static counterpart that uses pre-generated feedback logs to evaluate models without the cost of dynamic verbal feedback while maintaining the same feedback structure."}
{"id": "0mtz0pet1z", "Context": "In many clinical and public health settings, treatment is initiated at variable times, such as in screening, vaccination, or managing chronic conditions like HIV. A central causal inference question is how the timing of initiation influences outcomes, and standard approaches typically formulate policies for 'when to treat' based on patient characteristics.", "Idea": "Reframe the target as an incremental intervention that adjusts the intensity (hazard) of the time-to-treatment-initiation process. Provide identification for the corresponding incremental causal effect without relying on the standard positivity assumption, and develop an inverse-probability-weighting estimation framework for this target."}
{"id": "u3TL0qxLWf", "Context": "Large language models have significantly advanced NLP but are difficult to deploy widely due to high inference-time costs, especially from memory-bound weight accesses. These bottlenecks often leave compute underutilized, and many existing compression approaches depend on calibration data and may not generalize across tasks.", "Idea": "Introduce SeedLM, a post-training, data-free compression technique that encodes each weight block using the seed of a pseudo-random generator. During inference, a seed is fed to a Linear Feedback Shift Register to generate a random matrix that is linearly combined with stored compressed coefficients to reconstruct the weight block."}
{"id": "4O0v4s3IzY", "Context": "There is ongoing debate about the reasoning abilities of large language models, with early optimism tempered by counterexamples in tasks like arithmetic and planning. A widespread belief holds that models can iteratively self-critique to improve their solutions, grounded in the assumption that verifying correctness is easier than generating solutions—an assumption that may not align with how such models operate.", "Idea": "Introduce a principled empirical framework to study iterative prompting for reasoning and planning by contrasting self-critique with external, sound verification. The approach analyzes the role of critique content and performs ablations to identify which components of the augmented prompting pipeline are necessary."}
{"id": "P4XmKjXTrM", "Context": "Reproducibility in machine learning for healthcare is hindered by the privatization of datasets, model pipelines, and even task or cohort definitions, creating barriers to sharing, iteration, and understanding results on electronic health record data.", "Idea": "Introduce ACES, an Automatic Cohort Extraction System for event-stream data. It provides a domain-specific configuration language to define dataset-specific concepts and dataset-agnostic inclusion/exclusion criteria, along with a pipeline that automatically extracts patient records that satisfy these criteria from real-world data. The system works with MEDS and ESGPT formats, as well as any dataset where task-specific predicates can be represented as an event stream."}
{"id": "SgymXhOEA5", "Context": "Person re-identification models are prone to camera-specific bias, which intensifies under domain shifts to unseen cameras or environments. Existing camera-aware techniques largely operate within the training domain and do not generalize well to new settings. In unsupervised learning, reliance on pseudo labels can further entrench camera bias, leaving models overly sensitive to camera labels.", "Idea": "Apply feature normalization on embedding vectors as a simple test-time postprocessing technique to reduce camera-induced bias, with analysis of how it addresses bias sources such as low-level image properties and body angle. Additionally, introduce straightforward training strategies for unsupervised ReID that limit the influence of camera-biased pseudo labels."}
