{"id": "nDvgHIBRxQ", "Context": "Evaluating large language models’ mathematical reasoning is hindered by benchmarks that focus narrowly on problem-solving, risk overfitting, and fail to capture robustness, task generalization, and real-world user-oriented behaviors.", "Idea": "Introduce MathCheck, a checklist-based evaluation framework with an automatic checklist generator to test task generalization and reasoning robustness across textual and multimodal mathematics. Provide MathCheck-GSM and MathCheck-GEO as upgraded benchmark suites and enable systematic behavior testing, with a design that extends to other reasoning tasks."}
{"id": "ZsP3YbYeE9", "Context": "Language-model-based agents often iterate prompting and self-reflection to solve tasks, but they suffer from redundant reflections that restrict exploration and from a lack of cross-task knowledge reuse.", "Idea": "Introduce Diversity of Thoughts (DoT), a modular framework that enforces diverse, non-redundant reflections to broaden decision-space exploration and adds a task-agnostic memory for retrieving insights from previously solved tasks, compatible with existing reflective and tree-based reasoning methods."}
{"id": "I4e82CIDxv", "Context": "Prior interpretability work on circuits typically analyzes coarse, polysemantic units like attention heads or neurons, which hinders clear mechanistic understanding and limits usefulness for downstream control. There is a need for methods that isolate causally relevant, human-interpretable structures at a finer feature level.", "Idea": "Define and extract sparse feature circuits—causally implicated subnetworks composed of human-interpretable features—and provide methods to apply them. This includes a human-in-the-loop procedure (SHIFT) that ablates features deemed task-irrelevant during classification, and an unsupervised, scalable pipeline for discovering sparse feature circuits for automatically identified model behaviors."}
{"id": "pHe4P1IVnb", "Context": "As language models grow more capable, humans can often provide only weak supervision. Prior Weak-to-Strong approaches use a single weak model to guide a stronger student, primarily in classification settings and with teacher-forcing-style training, which limits diversity of supervision signals and robustness.", "Idea": "Extend Weak-to-Strong to WeakS-to-Strong by using an ensemble of weak models to capture diverse supervisory signals, employ Bayesian confidence estimates to weight and guide supervision, generalize the framework from classification to text generation with richer supervision strategies, and adopt direct preference optimization to train the strong student beyond teacher forcing."}
{"id": "Pj4Aid3XqL", "Context": "Pre-trained language models can be extended to handle vision-language tasks by introducing image data in a later training phase, but the trade-offs versus integrating images earlier during pretraining are unclear—especially how dataset composition, model scale, image–text ratio, and timing of introducing visual tokens affect multimodal and text-only capabilities.", "Idea": "Define a training design space that varies when visual tokens are introduced during pretraining and the image–text mix, enabling systematic conversion of LLMs into VLMs while preserving text skills; adopt curricula that integrate vision tokens at configurable stages with controllable image–text ratios, followed by standard fine-tuning."}
{"id": "B2Fqu7Y2cd", "Context": "Instruction-following audio generation requires aligning free-form text with audio, but audio-only training data lacks explicit instruction labels, preventing models from learning how to follow or compose instructions (combine, interpolate, negate). There is a need for data and inference methods that expose meaningful audio–language relationships and enable compositional control.", "Idea": "Introduce Fugatto, an audio synthesis and transformation model conditioned on text with optional audio inputs; develop a specialized dataset generation approach that explicitly encodes instruction–audio correspondences across diverse tasks; and propose ComposableART, an inference-time extension of classifier-free guidance that provides compositional guidance over instructions for flexible control."}
{"id": "MWHIIWrWWu", "Context": "Controlling high-dimensional nonlinear systems (e.g., in biology and robotics) is difficult due to large state/action spaces. While deep RL can handle such tasks, it is computationally expensive, slow to train, and often requires extensive manual reward tuning, limiting scalability across many tasks.", "Idea": "Propose MPC^2, a hierarchical model-based control framework combining a sampling-based model predictive controller for target posture planning with a morphology-aware proportional controller for coordinated actuation. The method supports zero-shot, near-real-time control and uses black-box optimization to tune the reward function, reducing reliance on hand-crafted reward engineering."}
{"id": "cmYScmfu4Q", "Context": "RLHF commonly learns a reward model from human preferences, but this step is vulnerable to distribution shift, overfitting, and misspecification. Direct methods like DPO bypass reward modeling yet rely on a closed-form link between the optimal policy and reward that only holds in bandit or deterministic MDP settings, limiting applicability to general RL and broader preference models.", "Idea": "Introduce RLHF algorithms that avoid reward inference in general (including stochastic) RL by estimating local value-function differences directly from human preferences and updating the policy via a zeroth-order policy gradient approximation, removing reliance on closed-form reward–policy relations and accommodating flexible preference models."}
{"id": "6HcnC3pPkp", "Context": "As test-time tree-search strategies are increasingly used to enhance LLM mathematical reasoning, existing verifiers—originally designed for Best-of-N—provide only indirect, sequence-level feedback. They struggle to assess partial solutions and may undervalue promising intermediate steps, causing premature pruning during search.", "Idea": "Introduce token-supervised value models (TVMs) that assign each token a probability of eventually reaching the correct final answer, enabling explicit, token-level evaluation of partial solutions to more effectively guide branching and pruning decisions in tree search."}
{"id": "BAelAyADqn", "Context": "Longitudinal health behavior modeling uses smartphone and wearable data to predict near-term well-being outcomes. Real-world ubiquitous health data are heterogeneous across feature types, have high missingness, and must be processed under practical resource constraints, which many existing models overlook.", "Idea": "Introduce MuHBoost, a multi-label boosting framework that jointly predicts multiple health outcomes by combining multi-label classification with LLM prompting. The method incorporates mechanisms to handle heterogeneous features and missing data while accounting for compute/time/cost constraints, and includes two variants designed to reduce LLM hallucination when answering multiple queries simultaneously."}
{"id": "svp1EBA6hA", "Context": "Large pre-trained diffusion models often require additional conditioning signals during downstream use. Existing methods pose practical challenges: classifier guidance needs training noise-level classifiers over intermediate states, while classifier-free guidance depends on paired data and guidance schedules, which can be restrictive when only an offline dataset of inputs and labels is available.", "Idea": "Formulate conditioning of a pre-trained diffusion model as reinforcement learning (CTRL): learn a policy over the generation trajectory using an offline dataset, with rewards combining a learned classifier over the desired control and a KL regularizer to the base diffusion model. This yields a soft-optimal policy that enables sampling from the conditional distribution at inference, without training intermediate-state classifiers and while decoupling controls from inputs under a conditional independence assumption."}
{"id": "l2zFn6TIQi", "Context": "As large generative models become more capable and widely deployed, there is a need to reliably control their behaviors. Prior approaches steer model activations to induce or suppress concepts, but lack a unified, general framework across modalities.", "Idea": "Introduce Activation Transport (AcT), a modality-agnostic activation-steering framework grounded in optimal transport. AcT maps internal activations from source to target distributions via learned transport plans, unifying and generalizing prior steering methods to enable fine-grained induction or negation of concepts during generation."}
{"id": "FpiCLJrSW8", "Context": "Trustworthiness of LLMs—encompassing reliability, safety, and ethical alignment—has become a core concern alongside capability. While RLHF is widely used to align models with human preferences, its specific effect on different trust dimensions remains insufficiently understood, and the influence of fine-tuning data on trust-related behaviors is opaque.", "Idea": "Establish a principled framework to analyze how RLHF relates to multiple trustworthiness verticals (toxicity, bias, machine ethics, truthfulness, privacy), and adapt efficient influence function–based data attribution methods to the RLHF setting to trace how individual fine-tuning data points shape trust-related outcomes, informing more nuanced alignment strategies."}
{"id": "5WEpbilssv", "Context": "High-content perturbation experiments yield rich molecular readouts but are costly, and existing machine learning approaches often miss the semantic depth of biological knowledge and use objectives misaligned with downstream analyses. Large language models offer a natural medium to represent complex biological relationships and to provide structured rationales about experimental outcomes.", "Idea": "Introduce PerturbQA, a benchmark for structured reasoning over perturbation experiments centered on tasks such as predicting differential expression and direction changes for unseen perturbations and performing gene set enrichment, and propose Summer (SUMMarize, retrievE, answeR), a domain-informed LLM framework that summarizes evidence, retrieves relevant knowledge, and answers structured queries."}
{"id": "9OfKxKoYNw", "Context": "Text-guided diffusion models enable realistic image edits from prompts, raising misuse concerns. Existing defenses add imperceptible adversarial noise to induce model failures but are brittle, especially under masked editing and across varied editing setups, motivating more robust protections.", "Idea": "Introduce DiffusionGuard, which crafts input-specific adversarial perturbations by optimizing a new objective that targets early diffusion timesteps to preempt editing, and incorporates mask-augmentation during perturbation generation to handle diverse edit masks; additionally, provide a benchmark for evaluating defenses against unauthorized diffusion-based image edits."}
{"id": "oZkqkkvdND", "Context": "Variational Autoencoders are increasingly used in safety-critical settings where models must provide certified probabilistic guarantees against adversarial perturbations. However, obtaining such certifications for VAEs is challenging due to their latent-variable structure and stochastic decoding.", "Idea": "Introduce CIVET, a certified training approach for VAEs that upper-bounds worst-case error by constraining errors on carefully constructed support sets in the latent space, with a corresponding training algorithm that leverages these bounds to enforce robustness."}
{"id": "Pujt3ADZgI", "Context": "Prevailing RLHF methods are reward-based under the Bradley–Terry assumption, which can oversimplify human preferences and often requires costly estimation of per-response win rates.", "Idea": "Formulate RLHF within a general preference framework as a two-player game and introduce Iterative Nash Policy Optimization (INPO), where the policy plays against itself via no-regret learning to approximate a Nash policy, bypassing per-response win-rate estimation by directly minimizing a new loss over preference data."}
{"id": "9HK2rHNAhd", "Context": "For efficient LLM inference, the KV cache is often compressed by sparsifying tokens along the sequence. However, most methods allocate an equal KV budget to every layer, ignoring that layers differ in their sensitivity to input tokens, which can lead to suboptimal memory use and compute allocation.", "Idea": "Jointly optimize KV-cache compression across sequence and layer dimensions by dynamically allocating per-layer KV budgets based on online layer-importance estimates. Estimate each layer’s importance via cosine similarity between representations before and after self-attention, categorize layers accordingly, assign tailored KV budgets, and apply existing sequence-wise compression within each layer under its allocated budget."}
{"id": "Mfnh1Sqdwf", "Context": "Predicting gene expression from DNA sequences is challenging because it requires identifying the active regulatory elements that causally link sequence and epigenomic signals to expression, while disentangling informative features from non-causal noise.", "Idea": "Introduce Seq2Exp, a sequence-to-expression model that explicitly targets causal regulatory elements by decomposing DNA and epigenomic inputs conditioned on putative active regulators, and using an information bottleneck parameterized with a Beta distribution to fuse their contributions while filtering non-causal components, thereby extracting regulatory elements during prediction."}
{"id": "pbre0HKsfE", "Context": "Personalized LLM interactions raise privacy risks because user data may be exposed during fine-tuning and inference. Homomorphic encryption enables computation over encrypted data but is computationally burdensome for standard Transformer operations (e.g., softmax-based attention and nonlinearities), making direct application to LLMs impractical without architectural changes.", "Idea": "Design an HE-friendly Transformer that supports private fine-tuning and inference by restructuring components to be compatible with homomorphic arithmetic. Use LoRA to confine parameter updates to low-rank adapters, and replace non-HE-friendly attention and activation steps with HE-compatible formulations (e.g., Gaussian kernel-based attention and polynomial operations), enabling efficient encrypted computation end-to-end."}
{"id": "WeJEidTzff", "Context": "Commuting origin-destination flows are vital for urban planning, but collecting them is expensive. While models can infer flows from readily available urban attributes, inconsistent datasets, metrics, and evaluation protocols across studies prevent fair comparison and hinder methodological standardization.", "Idea": "Release a large-scale, standardized dataset of commuting OD flows for 3,333 U.S. areas and provide a unified benchmarking framework—with consistent data splits and evaluation criteria—to enable fair, comparable assessment of commuting OD flow generation methods from urban attributes."}
{"id": "kiOxNsrpQy", "Context": "As Graph Neural Networks become widespread, the community seeks explanations that are faithful to a model’s reasoning. Yet multiple, non-equivalent faithfulness metrics coexist, potentially overlooking key properties of explanations, and it is unclear how model architecture and out-of-distribution behavior interact with faithfulness.", "Idea": "Clarify the notion of faithfulness by analyzing the non-interchangeability and blind spots of existing metrics; show that in injective regular GNNs perfectly faithful explanations can be uninformative; contrast with modular architectures (e.g., self-explainable or domain-invariant) where faithfulness can be informative; and establish a formal link between faithfulness and out-of-distribution generalization, highlighting that recognizing a domain-invariant subgraph is insufficient without faithfulness."}
{"id": "Kpjvm2mB0K", "Context": "The problem is one-pass streaming for underdetermined ℓp regression min ||x||p subject to Ax=b with n≪d, where columns of A arrive sequentially. In graph-incidence settings, this captures ℓp flows (e.g., transshipment, electrical, and max flow). The challenge is to estimate the objective value and recover feasible solutions using memory far smaller than the stream length.", "Idea": "Develop column-arrival streaming methods that maintain a compact, input-adaptive sparse representation of A by selecting and reweighting columns to preserve the ℓp objective (interpretable as ℓp flow sparsifiers on graphs). Use sketching- and sparsification-based constructions to support both cost estimation and approximate solution recovery from the maintained summaries within sublinear space."}
{"id": "eENHKMTOfW", "Context": "Fine-tuning large language models is accessible to well-resourced labs but challenging for smaller teams due to limited compute and the complexity of choosing effective training configurations. Practitioners lack consolidated, reproducible guidance for supervised instruction-tuning of small models across diverse tasks and datasets.", "Idea": "Define and release an open, standardized methodology and configuration suite for supervised instruction-tuning of 3B–7B LLMs across diverse instruction datasets, specifying choices such as batch sizing, learning rate schedules, warmup, and data organization (phased vs. stacked), along with code and detailed documentation."}
{"id": "TEkoMEjf7E", "Context": "Generative 3D modeling has progressed but remains ill-posed, making it hard to achieve consistent quality and controllability. In practice, creators often consult existing 3D assets as references when designing new models.", "Idea": "Introduce Phidias, a reference-augmented diffusion framework for 3D generation that leverages retrieved or user-provided 3D models to guide synthesis. It features: (1) a meta-ControlNet to dynamically modulate conditioning strength, (2) dynamic reference routing to address misalignment between inputs and references, and (3) self-reference augmentations for self-supervised training with a progressive curriculum, unified across text, image, and 3D conditioning."}
{"id": "EV7FMBZxnx", "Context": "Concealed object detection typically relies on specialized imaging systems. While lensless cameras are compact and flexible, their measurements lack conventional visual semantics, creating substantial challenges for detecting concealed objects.", "Idea": "Propose RGANet, a lensless-imaging framework that progressively exposes concealed objects using a Region Gaze Module to mine biologically/psychologically inspired spatial–frequency cues and a Region Amplifier to enhance object-region details; also provide the first benchmark dataset for lensless concealed object detection."}
{"id": "21rSeWJHPF", "Context": "Graph vertex ranking often relies on centrality measures (e.g., PageRank). In graphs with community structure, these methods can yield unbalanced rankings that overrepresent certain communities, reducing diversity and obscuring information in unsupervised settings.", "Idea": "Introduce relative centrality: an iterative, graph-dependent local normalization of centrality scores that promotes balance across communities while preserving ranking validity, and analyze sources of unbalancedness via a multi-core-periphery-with-communities (MCPC) graph model."}
{"id": "l0gZS0sAlf", "Context": "Fine-tuning large language models on heterogeneous data from multiple sources can induce conflicting gradient directions, complicating optimization, limiting specialization, and weakening generalization across tasks. Prior findings suggest that task-specific data selection can mitigate these issues, motivating mechanisms that explicitly manage gradient conflicts while maintaining efficiency.", "Idea": "Propose ELREA, an ensemble framework that clusters training instructions by gradient direction to define distinct expertise regions, trains a LoRA-based expert adapter for each cluster, and at inference selects and combines the most relevant experts based on the input’s gradient similarity to these clusters. This modular, parameter-efficient design targets gradient conflict reduction and input-adaptive specialization."}
{"id": "mFY0tPDWK8", "Context": "ML methods for accelerating MILP often predict an initial solution and fix a subset of variables to shrink the search space. However, fixing variables directly based on imperfect predictions can induce infeasibility or degrade solution quality, highlighting the need for a reliability-aware mechanism to decide which variables to fix.", "Idea": "Propose Apollo-MILP, an alternating prediction–correction neural framework that iteratively predicts values for unfixed variables and refines them via a trust-region search to obtain a reference solution. Using both predicted and reference solutions, it computes an Uncertainty-based Error upper BOund (UEBO) to quantify per-variable confidence and fixes only high-confidence variables, progressively reducing the problem while avoiding premature or erroneous fixings."}
{"id": "mYgoNEsUDi", "Context": "Graph diffusion models are emerging for generative tasks on graphs but struggle to capture higher-order, multi-scale, and dynamically evolving topological structures. Existing approaches lack holistic descriptors that summarize intrinsic topology across resolutions and over sequences of graphs, limiting generalizability and applicability.", "Idea": "Leverage zigzag persistence to extract latent, multi-resolution topological descriptors over graph sequences and introduce an efficient summary, zigzag spaghetti (ZS), that jointly encodes inherent topology across scales and time. Provide stability guarantees for ZS and integrate these dynamic topological summaries into graph diffusion models as a principled topological prior."}
{"id": "LBl7Hez0fF", "Context": "Large vision-language models can hallucinate due to misalignment between visual inputs and textual outputs. This issue is exacerbated by separately pre-trained image encoders and text decoders, making decoders overly sensitive to unstable or shifted vision features. A practical need is to mitigate this sensitivity at inference without retraining.", "Idea": "Introduce Visual and Textual Intervention (VTI), a task-agnostic, training-free method that steers latent representations of both visual and textual streams during inference to stabilize vision features and thereby curb hallucination in LVLMs."}
{"id": "dQ2xiSIYzp", "Context": "Recovering a detailed 3D human from a single image is highly underconstrained, as large regions (like the back) are unobserved. Pure image-based reconstructions can yield implausible poses and shapes, and body-model priors (e.g., SMPL-X) may be inaccurate without refinement.", "Idea": "Introduce a single-view generalizable Human Gaussian Model that represents humans with Gaussian primitives and follows a generate-then-refine pipeline: predict coarse human Gaussians, render a back view, refine that back image using a diffusion-guided ControlNet, then reconstruct refined Gaussians from the input and refined back view. Incorporate a SMPL-X prior via a dual branch that propagates volumetric body features into the Gaussian representation using sparse convolutions and attention, while iteratively refining the SMPL-X estimate within the model."}
{"id": "uHLgDEgiS5", "Context": "Classical influence estimation methods assume permutation-invariant training, which breaks under modern stochastic, curriculum-based, and multi-stage procedures where data order shapes the optimization path. This makes it hard to attribute how the same example affects learning when seen at different training times.", "Idea": "Formalize trajectory-specific leave-one-out influence that conditions on the exact data sequence and optimization trajectory, and introduce data value embedding—an embedding that accumulates example–parameter interaction over training—to efficiently approximate trajectory-specific LOO via a dot product with a test example’s gradient."}
{"id": "lPJUQsSIxm", "Context": "Fully homomorphic encryption enables private inference by allowing computation on encrypted data, but FHE-based deep networks face high computational cost, latency, and scalability challenges due to expensive non-linear activations and frequent bootstrapping. Many images are stored and transmitted in JPEG form, suggesting a frequency-domain representation that could better align with FHE constraints.", "Idea": "Perform private inference directly on DCT-domain image coefficients, designing an architecture that emphasizes linear operations compatible with FHE and reduces reliance on costly non-linearities and bootstrapping. Leverage the JPEG-aligned DCT representation to avoid unnecessary domain conversions, and learn to prioritize perceptually salient low-frequency components to maintain robust features under homomorphic noise, improving efficiency and scalability for high-resolution images."}
{"id": "rfdblE10qm", "Context": "In LLM alignment, reward models often convert pairwise preference data into scalar rewards, with the Bradley–Terry (BT) model being a common choice despite originating from competitive match modeling. There is uncertainty about why BT is appropriate for sparse pairwise comparisons and whether recovering absolute reward values is necessary when downstream objectives primarily depend on correct ranking.", "Idea": "Provide a theoretical foundation for BT-based reward models with deep embeddings by establishing convergence guarantees; introduce order consistency as the key requirement for reward modeling (preservation of ranking up to monotonic transforms); show that BT satisfies order consistency; and propose a simple upper-bound objective compatible with standard binary classifiers as an alternative order-consistent reward modeling approach."}
{"id": "W2Wkp9MQsF", "Context": "Many model compression techniques rely on access to training data and fine-tuning to maintain performance. Data-free approaches exist but often fail to preserve internal data statistics and can suffer from instability issues such as variance collapse or explosion. Moreover, they typically do not exploit structural similarity across layers to remove redundancy.", "Idea": "Introduce model folding, a data-free compression method that merges structurally similar neurons across layers to reduce model size without fine-tuning or training data. It preserves data statistics via k-means–based clustering of neuron parameters and employs data-free mechanisms to stabilize variance during merging, enabling post-hoc compression as a drop-in procedure."}
{"id": "sLKDbuyq99", "Context": "LLM-based multi-agent systems can plan and execute tasks, but they lack robust mechanisms for real-time workflow adjustment when conditions change. A representation that supports iterative refinement and modular decomposition is needed to adapt during execution.", "Idea": "Model workflows as activity-on-vertex (AOV) graphs and let LLM agents continuously refine them by dynamically reallocating subtasks based on historical performance and prior graph states; emphasize modular workflow design by evaluating parallelism and dependency complexity to enable flexible, concurrent, and resilient task orchestration."}
{"id": "9OJflnNu6C", "Context": "Image-to-Image generative models can embed private or biased data, motivating machine unlearning to remove specific training information. Prior I2I unlearning methods typically pose a single-objective problem that yields one solution, overlooking users’ diverse preferences over the trade-off between thorough unlearning and model utility.", "Idea": "Introduce a controllable unlearning framework with a control coefficient ε that tunes the unlearning–utility trade-off. Reformulate unlearning as an ε-constrained optimization problem and use a gradient-based method to compute unlearning boundaries that define the valid ε range, guaranteeing Pareto-optimal solutions within this range, along with convergence analysis under different control functions."}
{"id": "zjeHLSiNv1", "Context": "Transformer quality scales with parameters and compute, but larger models strain inference efficiency. Mixture-of-Experts increases capacity while limiting FLOPs, yet suffers from inference-time memory access and bandwidth overhead due to scattered expert routing.", "Idea": "Introduce UltraMem: a large, ultra-sparse, addressable memory layer that augments or replaces experts. Tokens interact with only a small, learned subset of memory slots via sparse routing, enabling high capacity with bounded compute and more locality-friendly memory access. The module integrates into Transformers as a drop-in layer, decoupling capacity from compute by activating few slots per token and structuring accesses to reduce inference-time memory overhead."}
{"id": "hgwGi81ndj", "Context": "Exploration in reinforcement learning is difficult when agents operate directly on pixel-level observations and primitive actions, because the resulting dynamics are complex and sparse-reward learning is inefficient. Object-centric, structured representations with state and temporal abstraction can simplify dynamics and enable more targeted planning.", "Idea": "Adopt an object-centric, hierarchical approach that represents environments as sets of items and attributes, modeling items at a higher state abstraction than pixels and attribute changes at a higher temporal abstraction than primitive actions. Build a fully model-based framework that learns a discriminative world model over the abstract state space, plans exploration using a count-based intrinsic reward to discover new abstract states, and then plans to reach arbitrary discovered abstract states. Implement abstract actions via learned low-level object-perturbing policies using reinforcement learning, and obtain the object mapping through supervised learning."}
{"id": "CI4sCBMXjP", "Context": "Adapting large language models typically relies on resource-intensive fine-tuning or on in-context learning that consumes prompt space and requires carefully chosen demonstrations. While task vectors suggest that capabilities can be modularized, there is no standardized mechanism to externalize, store, and systematically reuse such capability representations across tasks and settings without extra inference overhead.", "Idea": "Propose ELICIT, a two-module framework that externalizes in-context learned capabilities as task vectors: (1) a storage module that extracts and maintains vectors representing specific tasks or skills, and (2) a reuse module that retrieves and composes these vectors to activate capabilities in a base model without additional training or inference tokens, enabling modular capability management across inputs, tasks, and architectures."}
{"id": "hJVdwBpWjt", "Context": "Multimodal language models that process text and audio have advanced on speech, music, and general audio, but bioacoustics applications—such as detecting animal vocalizations, classifying rare species, and labeling context or behavior—remain underexplored due to scarce annotations and the absence of domain-specific models and benchmarks.", "Idea": "Develop NatureLM-audio, an audio-language foundation model tailored to bioacoustics, trained on carefully curated text–audio pairs spanning bioacoustics, speech, and music to enable cross-domain transfer; introduce a dedicated benchmark (BEANS-Zero) to standardize and assess performance on core bioacoustics tasks."}
{"id": "4GSOESJrk6", "Context": "Personalized image generation needs reliable evaluation. Existing automated metrics often diverge from human judgments, while human evaluations are slow and costly.", "Idea": "Create DreamBench++, a human-aligned, automated benchmark powered by advanced multimodal GPT evaluators. The approach uses systematically designed prompts to induce both human-aligned and self-aligned criteria with task reinforcement, and provides a comprehensive dataset of diverse images and prompts to enable consistent, scalable assessment of personalized image generation."}
{"id": "PkpNRmBZ32", "Context": "State-space models (SSMs) are attractive for sequence modeling but are typically implemented with depthwise-separable blocks and fixed computation patterns, limiting architectural flexibility and efficient training/inference. There is a need for a systematic way to design diverse SSM blocks and optimize their computation without relying on recurrent, convolutional, or attention mechanisms.", "Idea": "Represent SSM operations as tensor contractions and optimize the contraction order per block to improve computational structure. Build a heterogeneous network (Centaurus) that mixes generalized SSM blocks inspired by convolutional motifs (e.g., group, full, bottleneck), enabling flexible design and a fully SSM-based architecture that avoids nonlinear recurrence, explicit convolutions, and attention."}
{"id": "t8fu5m8R5m", "Context": "Anomaly detection commonly trains on unlabeled normal data, leaving models vulnerable to adversarial anomalies at test time. Designing effective adversarial training is hard without labels, and standard contrastive losses can be misled by spurious negative pairs—samples that should be close but are pushed apart—hindering margin maximization between normal and anomalous distributions.", "Idea": "Create a pseudo-anomaly set from normal data and adopt adversarial training with a contrastive objective that induces both intra- and inter-group perturbations to enlarge the normal–anomaly margin. Mitigate spurious negatives by defining opposite pairs and adversarially separating them, guiding inter-group perturbations in a principled way."}
{"id": "fGhr39bqZa", "Context": "Causal discovery with latent variables often relies on the restrictive pure-child assumption, where some observed variables are influenced by exactly one latent cause. This limits applicability in real-world settings where observed variables can have more complex parentage.", "Idea": "Introduce homologous surrogates—observed variables that need not be pure children but share structured relationships enabling identification—and formalize assumptions around them to support latent variable identification and causal structure inference; develop an algorithm that exploits these surrogate properties for causal graph recovery without requiring pure children."}
{"id": "4ua4wyAQLm", "Context": "Video anomaly detection must flag novel, unseen events, but prevailing methods emphasize global visual patterns laden with redundant details, limiting generalization. They often overlook fine-grained local semantics and their temporal evolution, making it hard to capture the compositional cues that characterize previously unseen anomalies.", "Idea": "Focus on discovering and modeling local patterns and their dynamics. Use a two-stage pipeline—image–text alignment followed by cross-modality attention—to extract semantically grounded spatial local patterns that can be recombined for novel anomalies. Introduce a State Machine Module that leverages earlier high-resolution textual tokens to guide precise captioning of later low-resolution observations, injecting temporal structure. Complement this with temporal motion estimation to model dynamics and identify anomalies arising from unusual spatial configurations or distinctive motion."}
{"id": "xPxHQHDH2u", "Context": "Novel view synthesis has progressed with NeRF and 3D Gaussian Splatting, but reconstructing reflective objects remains difficult, especially when modeling inter-reflections and maintaining real-time, high-quality rendering. Existing pipelines also struggle to integrate accurate material properties and robust geometry handling for reflective surfaces.", "Idea": "Introduce Reflective Gaussian Splatting (Ref-Gaussian), combining: (1) a physically based deferred rendering pipeline that injects pixel-level material properties into the rendering equation via a split-sum approximation; and (2) a Gaussian-grounded inter-reflection formulation that models view- and light-dependent inter-reflections within the Gaussian splatting framework. The design further includes material-aware normal propagation, an initial per-Gaussian shading stage, and 2D Gaussian primitives to strengthen geometry and shading fidelity."}
{"id": "i3e92uSZCp", "Context": "In reinforcement learning, unsupervised skill discovery aims to learn diverse behaviors without explicit rewards. Existing methods often prioritize discriminability or broad state coverage, but they do not directly target high-level semantic diversity, limiting the usefulness of learned skills for downstream tasks.", "Idea": "Introduce Language Guided Skill Discovery (LGSD), which leverages large language models to steer skill discovery toward semantically diverse behaviors. Natural-language prompts constrain the search to a desired semantic subspace, and LLM-derived guidance shapes objectives that explicitly maximize semantic separation between skills, yielding a repertoire of distinct, language-addressable skills."}
{"id": "ws5phQki00", "Context": "Stance detection for online political discussions faces scarce and diverse labeled data needs, while directly deploying large language models can introduce inconsistency, bias, and adversarial vulnerabilities. Conventional transformer-based classifiers are more stable for deployment but require task- and topic-specific supervision that is costly to collect.", "Idea": "Adopt an offline–online split: use an LLM offline to synthesize topic-specific stance data and train a conventional, deployable stance detector; then use the synthetic set as a reference to drive selective sampling on unlabeled data (e.g., via uncertainty/disagreement) to identify the most informative instances for limited annotation. Fine-tune the deployable model with a mix of synthetic data and selected labeled samples, keeping the LLM out of the production path while addressing data scarcity across diverse debate topics."}
{"id": "t8KLjiFNwn", "Context": "Transformers dominate long-range sequence modeling, while State Space Models offer competitive selective mechanisms. However, the selective mechanism raises computational and bandwidth costs, making deployment on resource-constrained mobile devices challenging.", "Idea": "Propose a sparse learning framework with architecture-aware compiler optimizations for mobile deployment. It introduces C4^n kernel sparsity (pruning n of every four contiguous weights), provides a compiler-accelerated execution path, generates models tailored to sparsity or latency targets with compensation of remaining weights, and applies C4^n-specific optimizations plus layout transformation elimination to reduce fine-grained pruning overhead in linear and related operations."}
{"id": "Bp0HBaMNRl", "Context": "Discovering causal structures with latent variables from observational data is difficult. Many existing approaches are constraint-based and rely on iterative discrete searches, which scale poorly with many variables. They also commonly assume linearity or invertibility and often treat latent variables or exogenous noise deterministically, limiting applicability to realistic non-linear settings.", "Idea": "Establish identifiability results for non-linear latent hierarchical causal models that relax deterministic assumptions about latent variables and exogenous noise, and leverage these results to design a differentiable causal discovery algorithm that efficiently estimates the structure of such models."}
{"id": "2IoFFexvuw", "Context": "While RL-based fine-tuning is established for diffusion models, extending it to continuous flow-based generative models is difficult due to policy collapse from overoptimization, high computational cost of continuous-time likelihoods, and reliance on reward gradients or curated datasets. There is a need to align flows with arbitrary reward functions while preserving diversity and balancing exploration and exploitation.", "Idea": "Introduce ORW-CFM-W2, an RL fine-tuning method for flow matching that applies online reward-weighted updates to bias training toward high-reward regions without requiring reward gradients, and incorporates Wasserstein-2 regularization with a tractable upper bound to prevent collapse and maintain diversity; the framework connects to soft RL with KL-regularized policy optimization."}
{"id": "izjNI5bcOV", "Context": "Weather understanding spans diverse modalities and tasks (e.g., forecasting, translation, post-processing), yet existing data-driven models are typically single-task and scenario-specific, relying on limited real observations and lacking a unified framework to handle heterogeneous inputs and objectives.", "Idea": "Introduce a generalist weather foundation model (WeatherGFM) that unifies task representations and definitions, designs weather-specific prompt formats for single, multi, and temporal modalities, and frames training/inference as a visual prompting question–answering paradigm to support in-context handling of multiple weather tasks within one model."}
{"id": "5IWJBStfU7", "Context": "As AI systems are deployed in high-stakes settings, interpretability is crucial. Mechanistic Interpretability (MI) seeks human-understandable algorithms within networks to explain behavior, raising a core question: for a fixed behavior, is there a unique explanation? This motivates a formal notion of identifiability for MI explanations.", "Idea": "Formalize identifiability of MI explanations by analogy to statistical identifiability, and delineate two strategies: (i) where-then-what—first isolate a behavior-replicating circuit, then interpret it; (ii) what-then-where—start from candidate algorithms and locate causally aligned activation subspaces. Specify evaluation criteria spanning pragmatic standards (predictive accuracy and manipulability) and stricter unicity requirements, and advocate an inner interpretability framework that validates explanations through multiple, complementary criteria."}
{"id": "z8PcUSKXXN", "Context": "Generalizable image denoising remains challenging: methods like Masked Training (MT) train on specific noise (e.g., Gaussian) yet can produce over-smoothed outputs, require careful mask-ratio tuning, and are cumbersome to integrate with other approaches. A simpler architecture that can natively handle diverse noise types without delicate hyperparameter coupling is desirable.", "Idea": "Introduce RNINet, a streamlined encoder–decoder denoiser that leverages the observation that feature statistics (e.g., mean and variance) shift with different noise conditions. Augment the backbone with a noise injection block that perturbs feature statistics with randomized noise during training, encouraging robustness to diverse and unseen noise types while avoiding masking mechanisms and minimizing architectural complexity."}
{"id": "yitH9xAHQs", "Context": "LLMs are commonly fine-tuned using human-annotated or template-driven synthetic datasets, which can narrow coverage and overlook challenging edge cases, leaving task-specific weaknesses undiscovered.", "Idea": "ReverseGen trains a dedicated proposer to generate queries that elicit unsatisfactory responses from a target model, automatically surfacing failure-inducing prompts. These prompts are then converted into training samples in an iterative loop, focusing data synthesis on the model’s uncovered weaknesses without relying on hand-crafted templates."}
{"id": "PUnD86UEK5", "Context": "Despite widespread use of Adam for training language models, existing non-convex optimization theory—typically built under l2-geometry smoothness assumptions and focusing on iteration complexity—offers similar worst-case rates for Adam and SGD, leaving Adam’s practical advantage theoretically underexplained.", "Idea": "Explain Adam’s advantage via its exploitation of l_infty geometry by introducing a convergence analysis under l_infty-based smoothness assumptions, and extend this framework to blockwise Adam using corresponding blockwise smoothness assumptions."}
{"id": "pPQPQ7Yd58", "Context": "In vision-based control pipelines learned via behavior cloning, the geometry of the visual representation space between the vision encoder and action decoder is poorly characterized, making it unclear how to structure features that align with control objectives. Observations from neural collapse in classification suggest that clustered representations may emerge in related settings and provide a basis for principled feature shaping.", "Idea": "Characterize a law of clustering in the visual representation space: in discrete control, features align with action labels; in continuous control, features form control-oriented clusters defined by relative pose orthants (REPO). Leverage this by pretraining the vision encoder with a neural-collapse-inspired regularizer that encourages control-oriented clustering, followed by end-to-end finetuning with the action decoder."}
{"id": "6qUUgw9bAZ", "Context": "Computationally intensive decoding methods—such as search, reranking, and self-critique—can improve language model outputs but are costly. Existing approaches typically apply a uniform decoding budget to all inputs, despite varying difficulty and potential benefit from additional computation.", "Idea": "Learn to predict the distribution of rewards conditioned on the input and a computation budget, then allocate decoding compute adaptively. Concretely, use the predictions to (1) choose the number of samples to generate for reranking in an adaptive best-of-k scheme, and (2) route each query to either a more expensive, accurate decoding procedure or a cheaper alternative."}
{"id": "hXm0Wu2U9K", "Context": "Offline alignment methods for language models, such as RLHF and DPO, can suffer from overoptimization: the policy overfits to inaccuracies in a learned reward model and drifts from the data distribution. KL-regularization is commonly used to mitigate this but can be too weak, motivating a need for a more principled approach that accounts for uncertainty and limits distribution shift during optimization.", "Idea": "Introduce chi^2-Preference Optimization (chiPO), a minimal modification to Direct Preference Optimization that replaces the logarithmic link with a chi^2-based link, inducing chi^2-divergence regularization. This implements pessimism-in-the-face-of-uncertainty, explicitly accounting for reward-model uncertainty to constrain updates during offline alignment."}
{"id": "d8hYXbxX71", "Context": "Designing welfare policy involves optimizing across short- and long-term horizons, where actions that appear suboptimal immediately may influence future welfare trajectories. Policymakers face a perceived tension between Rawlsian approaches that prioritize the worst-off and utilitarian approaches that maximize immediate aggregate gains, complicating principled evaluation and choice of interventions.", "Idea": "Model welfare policy as a sequential decision process in which individuals’ welfare levels stochastically decay and interventions can alter these dynamics. Within this framework, formalize Rawlsian and utilitarian policies, analyze their long-run behavior, and derive conditions linking decay processes, intervention effects, and objectives to long-horizon outcomes, yielding criteria for evaluating policies beyond short-term metrics."}
{"id": "G0dksFayVq", "Context": "LLM-based judges are increasingly used to assess and compare model outputs, yet their own reliability is insufficiently examined. Existing evaluations largely emphasize alignment with human preferences, which can be a poor proxy for factual and logical correctness on challenging tasks. As model outputs grow more sophisticated, judges require objective, rigorous assessments beyond crowdsourced preferences.", "Idea": "Introduce an objective evaluation framework and the JudgeBench benchmark that tests LLM-based judges on challenging response pairs across knowledge, reasoning, math, and coding. Use a pipeline that converts difficult datasets into response pairs with preference labels grounded in objective correctness, enabling standardized evaluation of diverse judge types (prompted, fine-tuned, multi-agent, and reward models)."}
{"id": "vJkktqyU8B", "Context": "Vision Transformer adapters can be accurate but often suffer from slow inference due to memory-bound inefficiencies, such as redundant normalization operations and frequent tensor reshaping.", "Idea": "Introduce META, a memory-efficient ViT adapter featuring: a shared LayerNorm between self-attention and feed-forward layers to reduce normalization overhead; cross-shaped self-attention to minimize reshaping; a lightweight convolutional branch to inject local inductive bias; and a cascaded block design to generate diverse head features, collectively reducing inefficient memory access operations."}
{"id": "SiH7DwNKZZ", "Context": "Transformers have become the default backbone in computer vision, even though they originated in NLP. Classic LSTMs struggled with long-range dependencies and limited parallelism. The xLSTM architecture addresses these issues via exponential gating and a parallelizable matrix memory, motivating exploration of scalable recurrent alternatives for image patch-token sequences.", "Idea": "Introduce Vision-LSTM (ViL), which adapts xLSTM blocks to vision by operating on sequences of image patch tokens with a stack of xLSTM layers. Odd-numbered blocks process tokens top-to-bottom and even-numbered blocks bottom-to-top, providing bidirectional context while leveraging xLSTM’s exponential gating and matrix memory as a generic vision backbone."}
{"id": "9NfHbWKqMF", "Context": "3D Gaussian Splatting enables photorealistic, real‑time rendering but tends to degrade when test camera poses fall outside the training distribution, limiting free‑viewpoint use. Existing remedies—regularization, data‑driven priors, and multi‑scene models—struggle to generalize to such out‑of‑distribution views.", "Idea": "Introduce SplatFormer, a point transformer that operates directly on Gaussian splats. Given an initial 3DGS built from limited training views, it performs a single‑pass, input‑conditioned refinement of the splat set to address out‑of‑distribution viewpoints by restructuring and adjusting splat parameters. This applies point transformers natively to 3DGS, enabling scene‑specific refinement without reliance on multi‑scene inference."}
{"id": "84WmbzikPP", "Context": "Molecular structure elucidation often relies on reconstructing a molecule’s 3D geometry from limited measurements. Rotational spectroscopy provides highly precise moments of inertia, yet existing conditional generative models only soft-condition on these moments, failing to enforce exact constraints or fully exploit their precision.", "Idea": "Characterize the set of n-atom point clouds with fixed moments of inertia as embedded in the Stiefel manifold St(n,4), and introduce Stiefel Flow Matching—a manifold-based generative approach that enforces exact moment constraints during synthesis. Further, learn simpler, shorter flows by leveraging approximate equivariant optimal transport on the Stiefel manifold."}
{"id": "9FqARW7dwB", "Context": "Residual connections are the de facto mechanism for training very deep networks, including large language models and vision architectures. However, common residual variants can induce a trade-off between vanishing gradients and representation collapse, and they enforce a largely fixed skip topology with limited adaptability in how information is routed across depths.", "Idea": "Replace standard residuals with hyper-connections that learn input- and depth-dependent connection strengths between features at different layers, enabling dynamic gating and rearrangement of layer interactions. This provides a flexible, configurable pathway that composes signals across depths to mitigate the gradient-collapse seesaw and adapt information flow without relying on rigid skip patterns."}
{"id": "ho4mNiwr2n", "Context": "Anti-backdoor learning seeks to obtain clean models from poisoned datasets, but many methods struggle to recover true labels for backdoored samples and do not generalize well to large pre-trained models due to non end-to-end training, limiting their practicality for modern architectures.", "Idea": "Reframe anti-backdoor learning from a causal perspective and incorporate both the input image and an explicit attack indicator during training to preserve model integrity. Introduce an end-to-end method (MCCI) that conditions the model on the attack indicator, enabling control over whether the model attends to backdoor or clean features; at inference, providing a non-attack indicator steers the model to behave as if inputs are clean."}
{"id": "WwmtcGr4lP", "Context": "Personalized cancer treatment is hindered by heterogeneous patient mutations and scarce labeled patient drug-response data. Existing transfer-learning methods leverage larger cell-line datasets by enforcing shared, domain-invariant representations, but this can suppress patient-specific characteristics that are critical for accurate drug response prediction.", "Idea": "Introduce GANDALF, a generative attention-based framework that directly augments patient genomic data while explicitly modeling patient-domain characteristics. It couples data augmentation with predictive modeling to capture patient-specific patterns rather than relying solely on a shared, domain-invariant representation between cell lines and patients."}
{"id": "d8cnezVcaW", "Context": "Direct Preference Optimization (DPO) is a common approach for aligning language models via human comparisons, but it typically assumes a fixed or homogeneous preference noise model and does not explicitly capture how diverse or concentrated human preferences can be across prompts.", "Idea": "Introduce MallowsPO, a preference optimization framework grounded in Mallows’ ranking theory that augments DPO with a dispersion index to model the concentration or spread of human preferences per prompt, unifying existing DPO variants as special cases and enabling dispersion-aware weighting within standard offline preference optimization pipelines."}
{"id": "MGKDBuyv4p", "Context": "Language models can memorize and regurgitate training data, raising privacy and safety concerns. Mitigating such memorization spans multiple technique families—regularization, fine-tuning, and machine unlearning—where practitioners face trade-offs between reducing leakage and preserving utility without clear guidance.", "Idea": "Provide a systematic mitigation framework that develops and organizes methods across regularizer-based, fine-tuning-based, and machine unlearning approaches; introduce TinyMem, a suite of small models for rapid method development; and propose several new unlearning techniques, including BalancedSubnet, aimed at precisely localizing and removing memorized information from model weights prior to inference."}
{"id": "vmulbBDCan", "Context": "Electron-multiplying CCDs enable low-light imaging but still exhibit significant noise that degrades image quality, notably in fluorescence microscopy. Existing EMCCD noise studies are largely theoretical, while physics-based noise models that effectively guide deep learning for conventional sensors do not directly transfer to EMCCDs due to their distinct noise processes.", "Idea": "Establish a physics-based EMCCD denoising pipeline by calibrating a comprehensive noise model via systematic procedures to estimate the statistics of observable noise components, and use the calibrated model to generate realistic training data for a modern neural denoiser tailored to EMCCD characteristics."}
{"id": "iXCeQ2m6vT", "Context": "Understanding visual relations, especially for novel objects, remains challenging for current vision models. Passive, fixed-resolution pipelines lack mechanisms to actively select informative regions and to exploit the low-dimensional spatial information provided by viewing actions, whereas human perception leverages eye movements to encode relations between parts.", "Idea": "Introduce a Glimpse-based Active Perception (GAP) system that sequentially selects salient regions for high-resolution processing and uses the coordinates of these glimpse actions, together with local visual features, to construct relational representations between image parts; jointly learn the glimpse policy and the integration of content and locations to capture relations beyond immediate local appearance."}
{"id": "FoF5RaA3ug", "Context": "Dataset distillation increasingly leverages soft labels from teacher models, but training on synthetic datasets is sensitive to how these labels are utilized. Variation across loss functions exposes the lack of a principled, universal objective for soft-label usage, and aspects like cross-optimizer generalization have received limited attention.", "Idea": "Propose GIFT, a plug-and-play approach that fully utilizes soft labels by combining soft-label refinement with a cosine-similarity loss, offering a universal objective for training on synthetic data and integrating with existing dataset distillation pipelines while explicitly addressing cross-optimizer generalization."}
{"id": "R4h5PXzUuU", "Context": "Foundation vision-language models trained on internet-scale multimodal data are rapidly proliferating, but their trustworthiness—particularly out-of-distribution (OoD) detection—remains underexplored. These models often convey uncertainty implicitly through natural-language responses rather than calibrated scores, making confidence interpretation and reliability assessment challenging.", "Idea": "Introduce Reflexive Guidance (ReGuide), a self-guided prompting approach that elicits image-adaptive concept suggestions from the model and feeds them back to steer subsequent reasoning and decisions. Complement this with methods to analyze and standardize how models express confidence in natural-language outputs to support OoD-aware classification."}
{"id": "gU4ZgQNsOC", "Context": "LLM pretraining typically treats all samples uniformly, ignoring per-example importance that may change over time. Existing reweighting methods emphasize coarse, group-level adjustments and lack dynamic, instance-level adaptation, with limited theoretical grounding on how such reweighting interacts with optimization.", "Idea": "Develop online, instance-level loss-based reweighting algorithms that adjust each sample’s weight based on its current loss, including strategies to deprioritize redundant or uninformative data, and provide a theoretical framework that characterizes how loss-based reweighting influences convergence in gradient-based optimization."}
{"id": "f7KxfUrRSb", "Context": "Aligning language models with human preferences often relies on costly human feedback. Weak-to-strong generalization suggests that strong models can benefit from supervision produced by weaker ones, motivating the transfer of alignment behavior from a weak model to a stronger model.", "Idea": "Weak-to-Strong Preference Optimization (WSPO) learns the distributional shift induced by aligning a weak model—capturing the difference between its pre- and post-alignment outputs—and uses this learned preference shift to guide optimization of a stronger model, transferring alignment behavior without direct human labels."}
{"id": "oU3tpaR8fm", "Context": "Retrieval-augmented generation with long-context LLMs encourages supplying more retrieved passages under the assumption that greater recall improves outputs. In practice, larger retrieval sets can introduce misleading yet plausible content (hard negatives), which can distract the model and degrade generation quality.", "Idea": "Identify hard negatives as a core failure mode in long-context RAG and propose mitigations: (1) a training-free retrieval reordering strategy to prioritize likely-relevant content and demote distractors, and (2) training-based methods, including RAG-specific implicit fine-tuning and RAG-oriented fine-tuning with intermediate reasoning. Additionally, examine design choices such as data distribution, retriever selection, and training context length for building robust long-context RAG systems."}
{"id": "iylpeTI0Ql", "Context": "Test-time adaptation seeks to handle distribution shift using only target data, but in open-world settings target streams often include out-of-distribution \"noisy\" samples. In zero-shot scenarios with vision-language models, existing TTA methods degrade because they update on unfiltered noisy data and entangle the roles of classification and noise detection, causing mutual interference.", "Idea": "Introduce a zero-shot noisy TTA framework that decouples classification from noise detection: keep the classifier (and backbone) frozen while training a separate Adaptive Noise Detector (AdaND) using the frozen model’s outputs as pseudo-labels to identify noisy samples. During adaptation, inject Gaussian noise to improve the detector’s robustness and reduce misclassification of clean samples, enabling reliable zero-shot handling of both in-distribution classification and out-of-distribution detection."}
{"id": "4rEI2JdHH6", "Context": "Grokking is a training pattern where a model initially memorizes data and only later transitions to generalization, causing delayed generalization. This behavior complicates predictability and efficiency, and is influenced by the choice of input embeddings.", "Idea": "Introduce GrokTransfer: train a smaller auxiliary model to learn an input embedding, extract that embedding, and use it to initialize the input embedding of a larger target model, leveraging embedding initialization to influence training dynamics related to grokking."}
{"id": "vQhn4wrQ6j", "Context": "Fine-tuning large language models for non-English tasks is challenging due to limited task-specific data. Model merging (e.g., souping) combines models with the same architecture without further training, offering a route to compose complementary abilities like language proficiency and mathematical reasoning.", "Idea": "Start from a shared pretrained model and fine-tune two experts: one on English math instruction data and one on generic instruction data in the target language. Merge them by swapping the top and bottom Transformer layers of the math expert with the corresponding layers from the language expert, composing language and math capabilities post hoc. Select layers based on interpretive analysis of parameter changes during fine-tuning, enabling a simple, modular approach to cross-lingual recomposition of expertise."}
{"id": "uREg3OHjLL", "Context": "Understanding how depth affects the expressivity of ReLU networks is often studied via the canonical function F_n = max(0, x1, ..., xn). Prior analyses have focused mainly on integer-weight networks, leaving the practically relevant case of rational (e.g., decimal or N-ary fractional) weights not well characterized.", "Idea": "Develop a proof framework that links the numeral base of rational weights to the network’s attainable polyhedral/linear-region complexity, and use base-dependent combinatorial and geometric arguments to reason about the depth needed to exactly represent F_n, extending integer-weight analyses to decimal and general N-ary fractional weights."}
{"id": "vr1QdCNJmN", "Context": "In continuous spaces, Bregman divergences are generated by convex functions, but creating meaningful analogs for discrete domains is challenging. Prior discrete formulations leveraged submodular functions as generators—the discrete counterparts of convexity—thereby limiting flexibility to submodular or supermodular cases.", "Idea": "Introduce a discrete Bregman divergence generated by difference-of-submodular functions, extending beyond purely sub/supermodular generators, and provide a learnable, permutation-invariant neural parameterization to model structure-aware divergences over sets."}
{"id": "2e4ECh0ikn", "Context": "Audio foundation models promise richer conversational abilities, yet there is no comprehensive way to assess whether they handle spoken turn-taking—timely speaking, avoiding overlaps, minimizing silences, and backchanneling—crucial for natural dialogue.", "Idea": "Create an evaluation protocol for spoken turn-taking that employs a supervised model trained on human-human conversations to predict turn-taking events and serve as an automated judge, accompanied by curated benchmarks (e.g., from Switchboard) and an open-source platform to assess understanding, prediction, and execution of turn-taking in audio FMs and dialog systems."}
{"id": "QG31By6S6w", "Context": "Recent advances in medical vision–language pretraining have enabled zero-shot disease recognition at the image level, but transferring this knowledge to pixel-level lesion segmentation in 3D CT remains difficult. Complex and variable pathological appearances make it hard to align fine-grained, unseen lesion features with disease-related textual representations.", "Idea": "Introduce Malenia, a multi-scale lesion-level mask–attribute alignment framework for 3D zero-shot lesion segmentation. It links mask representations to elemental attribute embeddings to connect unseen lesion visuals with extensible text knowledge from seen cases, and employs a Cross-Modal Knowledge Injection module to jointly enrich visual and textual features for segmentation guidance."}
{"id": "X9OfMNNepI", "Context": "Whether large language models can autonomously formulate novel, valid chemistry hypotheses remains unclear. Existing approaches lack a structured decomposition of the hypothesis-generation process and suitable benchmarks to study it. A key insight from expert practice is that many hypotheses emerge from combining a research background question with targeted inspirations from prior literature, followed by selection among candidates.", "Idea": "Adopt an assumption-driven decomposition of hypothesis discovery into three stages—(1) retrieve literature-derived inspirations given a background question, (2) synthesize hypotheses from the background and inspirations, and (3) assess and rank candidate hypotheses. Implement this as an LLM-based multi-agent framework mirroring the stages, and curate an expert-annotated benchmark of recent chemistry papers split into background, inspirations, and hypothesis to support systematic study of the pipeline."}
{"id": "keu6sxrPWn", "Context": "As large language models gain capability, they become harder to trust: subtle, hard-to-detect misalignment can introduce low-level errors that accumulate risk across many tasks. Deployers must balance average-case safety and usefulness when relying on untrusted models, especially over long sequences of tasks where small failures can compound.", "Idea": "Define the Diffuse Risk Management problem and introduce a two-level deployment framework: (1) micro-protocols that, per task, use a trusted but less capable model to harness, monitor, or gate an untrusted model; and (2) a macro-protocol that maintains an adaptive estimate of the untrusted model’s risk and switches among micro-protocols to manage the safety–utility tradeoff over time."}
{"id": "2ZK8zyIt7o", "Context": "Text-to-image diffusion models struggle to align images with long, detailed prompts because common encoders like CLIP have input length limits and degrade with long texts. Moreover, CLIP-based preference signals used for alignment conflate true text-image alignment with unrelated visual qualities, encouraging overfitting during fine-tuning.", "Idea": "Introduce LongAlign, which (1) uses segment-level encoding to split long prompts into segments processed independently and then aggregated, bypassing encoder length constraints, and (2) applies decomposed preference optimization that separates CLIP-derived scores into text-relevant alignment and text-irrelevant visual components, reweighting them during training to prioritize alignment and reduce overfitting."}
{"id": "RaR3ETzyKp", "Context": "Different diffusion methods and architectures trained on the same dataset tend to produce similar outputs for the same input noise, suggesting sample-specific preferable noises. Visualizing noise–sample pairs reveals that preferable paths between noises and samples are more organized (fewer crossings) than random paths; in high-dimensional spaces, path crossings are rare, so 2D crossings indicate small inter-path distances.", "Idea": "Propose Distance-Aware Noise-Sample Matching (DANSM), which matches noises to samples to enlarge inter-path distances between their generation trajectories. The method is derived from rectified flow models to enable closed-form inter-path distance computation, establishes a relationship between inter-path distance and path length, and optimizes a path-length surrogate. It applies to both image and latent spaces and is compatible with rectified flow and diffusion training regimes."}
{"id": "e8qXTxMgPg", "Context": "Dimensionality reduction for s-sparse vectors typically focuses on worst-case guarantees and often relies on oblivious linear (or smooth) mappings to preserve norms or distances in ℓp spaces. These approaches face inherent limitations due to collisions and rank constraints, and they do not fully exploit distributional assumptions (average-case) or structural properties like non-negativity that arise in practical datasets.", "Idea": "Develop a beyond–worst-case framework with two components: (1) an average-case analysis that delineates the fundamental limits of oblivious linear and broader smooth embedding schemes for s-sparse vectors when preserving ℓp norms; and (2) specialized, non-linear embeddings tailored to non-negative s-sparse data that preserve ℓp distances with compact dimensional representations, including constructions targeting exactness for ℓ∞. Provide separation arguments highlighting the necessity of non-linearity and non-negativity, and outline algorithmic applications enabled by these embeddings."}
{"id": "Wvi8c0tgvt", "Context": "Realistic blur datasets lack diversity in scenes and motion patterns, and expanding them with complex capture setups is costly. Existing augmentation methods typically rely on 2D blur models that ignore inherently 3D camera and object motions, yielding unrealistic blur.", "Idea": "Create a 3D-aware blur synthesizer that samples 3D camera positions over the exposure interval, generates corresponding intermediate views, and aggregates them to form realistic motion blur. Represent 3D transformations as a combination of a 2D transform and a learned projected 3D residual, avoiding explicit depth estimation. Provide controllable augmentation by adjusting blur magnitude, direction, and scene content."}
{"id": "c4OGMNyzPT", "Context": "Existing evaluations for Large Vision-Language Models (e.g., VQA, captioning) are limited: they insufficiently test fine-grained visual perception, risk data contamination, and overlook multi-turn, structured reasoning, leaving key capabilities underassessed.", "Idea": "Propose LVLM-Playground, a game-based evaluation framework in structured environments that uses a suite of games to assess Perceiving, Question Answering, Rule Following, and End-to-End Playing, targeting abilities such as detailed visual perception, reasoning, decision-making, and multi-turn interaction."}
{"id": "bc3sUsS6ck", "Context": "Large language models learn broad knowledge during pretraining but must be adapted to new contexts, tasks, or domains. Conventional approaches either fine-tune the model—incurring substantial training cost and parameter updates—or rely on prompting, which increases inference-time computation and memory overhead.", "Idea": "Augment a frozen pretrained language model with a lightweight, general-purpose adapter generator that encodes test-time context into parameter-efficient adapters in a single forward pass. Train this generator with self-supervised learning, enabling it to produce input-conditioned adapter parameters (fast-weight style) that plug into the base model without full fine-tuning or long prompts."}
{"id": "rpouyo09V0", "Context": "Existing code generation benchmarks do not capture the diversity and quality of feedback encountered in multi-turn, interactive programming, making it difficult to evaluate LLMs’ ability to use compilation messages, partial test results, and verbal guidance.", "Idea": "Provide standardized benchmarks for interactive code generation: (1) CONVCODEWORLD, a reproducible environment that simulates nine scenarios by systematically combining compilation feedback, execution feedback with varying test coverage, and GPT-4o-generated verbal feedback at different expertise levels; and (2) CONVCODEBENCH, a fast static variant that uses pre-generated feedback logs to evaluate models without dynamic feedback generation, with all resources publicly available."}
{"id": "0mtz0pet1z", "Context": "In many health settings, treatment can begin at varying times (e.g., screening, vaccination, or managing chronic infections). Traditional causal analyses emphasize choosing a specific treatment time and often rely on strong positivity assumptions, which can be unrealistic when initiation timing is stochastic or constrained.", "Idea": "Define and study incremental interventions that modulate the intensity (hazard) of treatment initiation over time, derive identification results for the resulting incremental causal effect without requiring positivity, and provide an inverse probability weighting framework for estimation."}
{"id": "u3TL0qxLWf", "Context": "Large language models are expensive to deploy because their large weight matrices make inference memory-bound. Even with conventional compression (e.g., quantization), frequent memory accesses to fetch parameters dominate runtime, and many methods rely on calibration data or task-specific tuning.", "Idea": "Encode weights using seeds of a pseudo-random generator in a data-free, post-training scheme. For each weight block, select a seed that drives a lightweight LFSR to generate a deterministic random matrix at inference, and store compact coefficients that linearly combine this matrix to reconstruct the block. This trades memory traffic for inexpensive on-the-fly computation, reduces parameter storage and access, and serves as a drop-in compression approach without calibration data."}
{"id": "4O0v4s3IzY", "Context": "There is substantial disagreement about the reasoning capabilities of large language models. A common belief is that models can iteratively self-critique to improve their answers, grounded in the classical notion that verification is easier than generation—an assumption that may not hold for LLMs that function as approximate retrievers.", "Idea": "Develop a principled framework to analyze iterative prompting for reasoning and planning by contrasting self-critique with sound external verification, isolating the role of critique content and the necessity of auxiliary components through systematic decomposition, and reexamining the verification-versus-generation assumption in the LLM setting."}
{"id": "P4XmKjXTrM", "Context": "Reproducibility in ML for healthcare is hindered by private datasets, opaque pipelines, and non-standardized task and cohort definitions, especially when working with electronic health record event-stream data.", "Idea": "Provide ACES, a library for event-stream EHR data that offers a domain-specific configuration language to define dataset-specific concepts and dataset-agnostic inclusion/exclusion criteria, alongside an automated pipeline that extracts patient cohorts from real-world data; compatible with MEDS, ESGPT, and any dataset expressible via event-stream predicates."}
{"id": "SgymXhOEA5", "Context": "Person re-identification models exhibit camera-specific bias, which is exacerbated under distribution shifts. Prior camera-aware methods are largely tied to training domains, limiting generalization. Unsupervised ReID is particularly susceptible, as pseudo labels can entrench camera-related correlations.", "Idea": "Use feature normalization on embedding vectors as a simple, test-time postprocessing to mitigate camera bias, analyze why it reduces sensitivity to nuisance factors, extend it to address fine-grained contributors (e.g., low-level image properties and body angle), and introduce lightweight training strategies that curb camera-biased pseudo labels in unsupervised settings."}
