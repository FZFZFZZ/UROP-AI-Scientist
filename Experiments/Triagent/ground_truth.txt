We propose AlphaEdit, a novel model editing approach that addresses the persistent challenge of preserving knowledge in large language models (LLMs) during sequential edits. AlphaEdit introduces a new solution by removing the e₀ constraint entirely during optimization, allowing full focus on minimizing e₁. To prevent overfitting and preserve existing knowledge implicitly, we apply a null-space projection: the computed parameter perturbation is projected onto the null space of the preserved knowledge before being applied. This projection ensures that the perturbation does not interfere with the preserved knowledge’s representation space. Our method maintains the distributional structure of hidden activations post-edit, ensuring semantic stability and mitigating the accumulation of harmful effects across edits.
